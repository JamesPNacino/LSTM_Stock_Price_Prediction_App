{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09220305-7373-4de1-bca2-96696f041e27",
   "metadata": {},
   "source": [
    "# Agenda - Data Analytics Life Cycle\n",
    "\n",
    "\n",
    "There are five relevant phases of the data analytics life cycle that are pertinent to this performance assessment.\n",
    "\n",
    "1. Discovery Phase\n",
    "2. Data Acquisition\n",
    "3. Data Cleaning & Exploratory Data Analysis\n",
    "4. Data Mining / Machine Learning\n",
    "5. Reporting\n",
    "   \n",
    "Each of these phases will be talked about in detail in this document.\n",
    "\n",
    "Please note that _**bolded and italicized letters**_ correspond to the WGU grading rubric.\n",
    "\n",
    "\n",
    "# Discovery Phase\n",
    "\n",
    "### Research Question - _**A**_\n",
    "\n",
    "Using historical market stock prices and technical indicators (RSI, MACD, MFI), how accurately can a neural network model, specifically an LSTM-based Recurrent Neural Network, predict stock price movements after the occurrence of a bullish candlestick pattern (e.g., 1 day, 3 days, 5 days, 10 days, and 15 days afterwards)? Additionally, how does the performance differ when using binary classification versus regression for price prediction?\n",
    "\n",
    "Note: I will only be identifying **bullish candlestick** patterns for this project, as these patterns are typically used to signal potential upward price movements. I am not identifying bearish candlestick patterns to save resources as well as I am personally more interested in upward price movement. These candlestick patterns that I will be identifying are shown in the \"Data Definitions\" section of this project.\n",
    "\n",
    "### Short Summary: Benefits to Stock Traders\n",
    "\n",
    "Using a neural network model like LSTM to predict stock price movements can benefit traders by providing more accurate forecasts based on historical stock price data and technical indicators like RSI, MACD, and MFI. By combining bullish candlestick patterns with these additional indicators, traders can make better-informed decisions instead of relying solely on pattern analysis. LSTM models excel at capturing long-term trends, making them ideal for stock price predictions. By using an LSTM, this method should enhance prediction reliability, improving investor confidence in anticipating price movements and make more profitable trades. From our data analysis we should also be able to recognize which specific candlestick patterns yield more accurate stock price predictions.\n",
    "\n",
    "### Long Summary: Benefits to Stock Traders\n",
    "\n",
    "My research question involves using a neural network model, specifically an LSTM-based Recurrent Neural Network (RNN), to predict stock price movements after a bullish candlestick pattern by analyzing historical market data and technical indicators like the Relative Strength Index (RSI), Moving Average Convergence Divergence (MACD), and Money Flow Index (MFI). This question benefits from data analysis because financial markets are complex and influenced by many factors that interact in unpredictable ways. Stock prices are impacted by a mix of past price movements, investor behavior, market trends, and technical indicators, making it difficult to predict future movements with simple models. By using data analysis and machine learning, we can uncover patterns in large amounts of historical data and understand how these different factors interact with one another, potentially leading to more accurate predictions.\n",
    "\n",
    "Candlestick patterns are widely used by traders to identify trends and predict future price movements. However, analyzing candlestick patterns in isolation may not provide the most reliable predictions. By incorporating additional data, such as historical stock prices and technical indicators like RSI, MACD, and MFI, we can potentially strengthen the accuracy of these predictions. Data analysis allows us to test how well these combined factors—candlestick patterns along with RSI, MACD, and MFI—help forecast future price changes. This data-driven approach goes beyond subjective interpretation, enabling the model to detect patterns and relationships in the data that may not be obvious to human analysts. By isolating specific candlestick patterns and training an LSTM on each of my chosen candlestick patterns, we can determine which of these candlestick patterns yield the best stock price predictions.\n",
    "\n",
    "Stock price prediction is a time-series problem, and LSTMs are well-suited for handling such data because they are designed to track long-term trends over time. In my case, I have a specific time-series problem that can be considered as a “pattern-based prediction problem” where I’m identifying specific events (candlestick patterns) and then predicting the immediate future based on these events. Data analysis helps fine-tune the LSTM model to improve its performance, ensuring it can make accurate predictions on new, unseen data. Additionally, comparing different approaches—such as binary classification (predicting whether the price will go up or down) and regression (predicting the exact price change)—requires rigorous analysis. By evaluating model performance through metrics like accuracy for classification or mean squared error for regression, data analysis enables an objective comparison of which approach provides more reliable predictions. \n",
    "\n",
    "In summary, data analysis is essential in this research because it allows us to better understand how candlestick patterns, when combined with historical stock prices and technical indicators like RSI, MACD, and MFI, can help predict stock price movements. By leveraging machine learning models like LSTMs, we can uncover complex patterns in the data, leading to more informed and reliable predictions. This data-driven approach provides a more objective and accurate way to forecast price movements than relying on intuition or subjective judgment.\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "After performing our data analysis, we should be able to conclude either the null or alternative hypothesis. The null hypothesis is the default assumption, stating that our independent variables (past stock price [low, high, open, close], RSI, MACD, MFI) have no effect, no relationship, or cause no change, to our dependent variable (future stock price).\n",
    "\n",
    "**Null Hypothesis**: The LSTM-based Recurrent Neural Network model does not significantly predict stock price movements (up or down) better than random chance when using historical market stock prices and technical indicators (RSI, MACD, MFI) for prediction.\n",
    "\n",
    "**Alternative Hypothesis**: The LSTM-based Recurrent Neural Network model significantly predicts stock price movements (up or down) better than random chance when using historical market stock prices and technical indicators (RSI, MACD, MFI) for prediction. \n",
    "\n",
    "### Data Definitions\n",
    "\n",
    "**1) Candlestick Pattern** \n",
    "\n",
    "Charting technique used in technical analysis which helps traders identify bullish (belief that the price of a stock will rise) or bearish (belief that the price of a stock will decrease) patterns. Candlestick patterns are known to show the favored direction of a stock's price, but it is not guaranteed.\n",
    "\n",
    "In the case of this project, it represents price movements of a stock over a specific time period. For example, in this project we will use daily candlesticks, this means each candlestick will provide the following information:\n",
    "\n",
    "* Low: The lowest stock price reached during this day\n",
    "* High: The highest stock price reached during this day\n",
    "* Open: The stock price at the beginning of the day\n",
    "* Close: The stock price at the close of the day\n",
    "\n",
    "Below is an example of a bearish candle (left) and bullish candle (right) and how to interpet them:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/candle_example.png\">\n",
    "</div>\n",
    "\n",
    "There are many types of candlestick patterns, however as mentioned earlier in my project I will only identify bullish candlestick patterns. Specifically, I will identify five of the most popular candlestick patterns to save resources, specifically time. The following are the candlestick patterns that I will use for my data analysis and exactly how I will identify each of them:\n",
    "\n",
    "\n",
    "1. Hammer\n",
    "    + Description: A single candlestick with a small body at the top and a long lower shadow. It appears at the bottom of a downtrend.\n",
    "    + Significance: Shows that despite strong selling pressure, buyers stepped in, potentially signaling a reversal.\n",
    "    + How I'm identifying this pattern: Looking for a bullish or bearish candlestick with a small body (body is less than 30% of the total candlestick length; candlestick length is the distance between low and high), with the lower shadow (the distance between the low and the open for a bullish candle, or the low and the close for a bearish candle) being at least two times the length of the body. There also must be little to no upper shadow (upper shadow will be less than 10% of the total candle length). This pattern must occur during a downtrend; to confirm a downtrend, I will fit a regression line (line of best fit) through the closing prices for the previous five candles-if the slope is negative or equal to zero, this means that a downtrend is present. It doesn't matter if the single candlestick is a bearish or bullish candle, they both can display the hammer pattern. The images below are visual representations of exactly how I am going to identify the hammer pattern as highlighted with blue dots; it doesn't matter if the single candlestick is a bearish or bullish candle, they both display the hammer pattern. In the images below, although it shows that there is a decently sized upper shadow for the hammer pattern, this is incorrect as it should be less than 10% of the candle's total length.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Hammer_wtih_bearish_candle.png\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Hammer_wtih_bullish_candle.png\">\n",
    "</div>\n",
    "\n",
    "2. Inverted Hammer\n",
    "    + Description: A single candlestick with a small body near the bottom, a long upper shadow, and little to no lower shadow. This pattern appears at the bottom of a downtrend.\n",
    "    + Significance: Shows that bulls may be gaining control, though confirmation from the next candle is needed.\n",
    "    + How I'm identifying this pattern: Looking for a candlestick (bullish or bearish) with a small body (less than 30% of the total candlestick length; candlestick length is the distance between low and high) at the bottom, a long upper shadow (at least twice the length of the body), and little to no lower shadow (lower shadow will be less than 10% of the total candle length). This pattern must occur during a downtrend; to confirm a downtrend, I will fit a regression line (line of best fit) through the closing prices for the previous five candles-if the slope is negative or equal to zero, this means that a downtrend is present. The images below are visual representations of exactly how I am going to identify the inverted hammer pattern as highlighted with blue dots; it doesn't matter if the single candlestick is a bearish or bullish candle, they both display the inverted hammer pattern.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Inverted_Hammer_wtih_bearish_candle.png\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Inverted_Hammer_wtih_bullish_candle.png\">\n",
    "</div>\n",
    "\n",
    "3. Bullish Engulfing Pattern\n",
    "    + Description: A two-candle pattern where a small bearish candle is followed by a larger bullish candle that completely engulfs the previous one.\n",
    "    + Significance: A strong signal of a shift from bearish to bullish sentiment, often indicating a reversal.\n",
    "    + How I'm identifying this pattern: Looking for a small bearish candle followed by a large bullish candle that completely engulfs the range (high and low prices) of the first candle (two-candle pattern). The second candle's body (open and close price) must be larger by at least 2 times the body of the first candle and fully engulf the body of the first candle. This pattern must occur during a downtrend; to confirm a downtrend, I will fit a regression line (line of best fit) through the closing prices for the previous five candles-if the slope is negative or equal to zero, this means that a downtrend is present. Note that the first candle (the bearish candle) in the identified pattern will be treated as the fifth candle in the slope calculation for confirming the downtrend. The image below is a visual representation of exactly how I am going to identify the bullish engulfing pattern as highlighted with blue dots.\n",
    "      \n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Bullish_engulfing.png\">\n",
    "</div>\n",
    "\n",
    "4. Bullish Harami\n",
    "    + Description: A two-candle pattern where a small bullish candle is contained entirely within the range of the previous large bearish candle.\n",
    "    + Significance: A sign of potential reversal, suggesting that selling pressure is weakening and buyers are starting to take control.\n",
    "    + How I'm identifying this pattern: Looking for a large bearish candle followed by a small bullish candle that is entirely within the range of the first candle; this means that the small bullish candle should be fully contained within the previous candle's high and low. The large bearish candle will be at least twice the entire length of the following bullish candle. The body of the large bearish candle will also completely engulf the body of the small bullish candle. This pattern must occur during a downtrend; to confirm a downtrend, I will fit a regression line (line of best fit) through the closing prices for the previous five candles-if the slope is negative or equal to zero, this means that a downtrend is present. Note that the first candle (the bearish candle) in the identified pattern will be treated as the fifth candle in the slope calculation for confirming the downtrend. The image below is a visual representation of exactly how I am going to identify the bullish harami pattern as highlighted with blue dots.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Bullish_harami.png\">\n",
    "</div>\n",
    "\n",
    "5. Three White Soldiers\n",
    "    + Description: A three-candle pattern consisting of three consecutive long bullish candles that close progressively higher.\n",
    "    + Significance: A strong bullish signal, indicating a powerful upward trend and a continuation of the previous bullish move.\n",
    "    + How I'm identifying this pattern: Looking for three consecutive bullish candles with each one closing higher than the previous candle. The candles should show a steady upward movement without large wicks. The upper and lower wicks should each be no more than 20% of the total candle length. Unlike the other patterns, this pattern does not need to occur during a downtrend. The visual below is a representation of how I am going to identify the three white soliders pattern as highlighted with blue dots.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Three_white_soldiers.png\">\n",
    "</div>\n",
    "\n",
    "\n",
    "(Note: The way I am identifying these candlestick patterns is highly specific. This approach ensures consistency and a systematic method for recognizing patterns, which leads to more reliable and repeatable results when analyzing trends. While the specifications may differ in certain details, they still encompass the core definition of each candlestick pattern. Some examples of these adjustments include:\n",
    "\n",
    "* The requirement for identifying a downtrend, using the slope of the 5 previous candles' closing prices. If the slope is negative, it confirms a downtrend.\n",
    "* For example, just looking at the hammer pattern, the lower shadow (the distance between the low and the open for a bullish candle, or the low and the close for a bearish candle) must be at least twice the length of the body.\n",
    "* Various other specific calculations for each pattern, ensuring that all conditions for pattern identification are met with precision.\n",
    "  \n",
    "These modifications are designed to provide a consistent, clear, and quantifiable framework for candlestick pattern identification, which enhances the accuracy of trend analysis.)\n",
    "\n",
    "\n",
    "**2) Stock Price** \n",
    "\n",
    "Stock price is the current market value or price of a single share of a company's stock. Each stock has it's own ticker symbol, for example, Microsoft's ticker symbol is \"MSFT\".\n",
    "\n",
    "I will be using four stock price associated independent variables for my analysis. My independent variables for stock price are daily variables, meaning they are recorded once daily. These variables are as follows:\n",
    "\n",
    "1. Low: The lowest stock price reached during this day\n",
    "2. High: The highest stock price reached during this day\n",
    "3. Open: The stock price at the beginning of the day\n",
    "4. Close: The stock price at the close of the day\n",
    "\n",
    "My sole dependent variable for this analysis is also a stock price variable. It can be explained two different ways depending on the problem I am trying to solve:\n",
    "\n",
    "1. Binary Classification: Predicting if the closing price will go 'up' or 'down' for multiple future time periods (1 day, 3 days, 5 days, 10 days, and 15 days), compared to the closing price from the last candle of the identified candlestick pattern.\n",
    "2. Regression: Predicting the exact closing price (a continuous value) for multiple future time periods (1 day, 3 days, 5 days, 10 days, and 15 days), after the identified candlestick pattern.\n",
    "\n",
    "\n",
    "**3) Relative Strength Index (RSI)** \n",
    "\n",
    "RSI will be another of my independent variables for this analysis. RSI is a momentum oscillator; a momentum oscillator is a type of technical indicator that reflects the rate at which a stock's price is moving. It helps traders determine whether a price movement is strengthening or weakening.\n",
    "\n",
    "RSI is calculated on a scale of 0 to 100 and helps identify potential overbought or oversold conditions in the market. When the RSI rises above 70, it indicates that an asset may be overbought, suggesting a potential reversal or pullback. Conversely, when the RSI falls below 30, it suggests the asset may be oversold and due for a rebound.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Fidelity_RSI_70_30.png\"><p style=\"text-align: right;\">(Fidelity, n.d., RSI: Relative Strength Index)</p>\n",
    "</div>\n",
    "\n",
    "RSI is valuable not only for indicating overbought or oversold conditions but also for gauging the strength of a trend. A reading above 50 generally signals bullish momentum, while a reading below 50 suggests bearish momentum. \n",
    "\n",
    "Divergences between price and RSI can also provide important insights; for example, if stock price is making new highs but RSI is not, it could indicate weakening momentum and a potential reversal. Traders often use RSI to confirm entry and exit points, helping them make more informed decisions based on current market conditions and trends.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Fidelity_RSI_divergence.png\"><p style=\"text-align: right;\">(Fidelity, n.d., RSI: Relative Strength Index)</p>\n",
    "</div>\n",
    "\n",
    "Here is how RSI will be calculated in my analysis:\n",
    "\n",
    "I will use a 14-day lookback period as it is the standard for calculating RSI, as originally proposed by J. Welles Wilder (he developed RSI) in his 1978 book _New Concepts in Technical Trading Systems_. This 14-day period is widely accepted in technical analysis and provides a balanced approach to evaluating price momentum over a short timeframe. It helps traders capture short- to medium-term trends, providing signals about the asset's momentum while still maintaining a reasonable level of reliability.\n",
    "\n",
    "The following table is just an example illustration for 14 days, to help visualize how RSI is calculated.\n",
    "\n",
    "| Day | Closing Price | Change | Gain | Loss |\n",
    "|-----|---------------|--------|------|------|\n",
    "| 1   | 100           | -      | -    | -    |\n",
    "| 2   | 102           | +2     | 2    | 0    |\n",
    "| 3   | 101           | -1     | 0    | 1    |\n",
    "| 4   | 103           | +2     | 2    | 0    |\n",
    "| 5   | 105           | +2     | 2    | 0    |\n",
    "| 6   | 104           | -1     | 0    | 1    |\n",
    "| 7   | 107           | +3     | 3    | 0    |\n",
    "| 8   | 110           | +3     | 3    | 0    |\n",
    "| 9   | 109           | -1     | 0    | 1    |\n",
    "| 10  | 112           | +3     | 3    | 0    |\n",
    "| 11  | 113           | +1     | 1    | 0    |\n",
    "| 12  | 111           | -2     | 0    | 2    |\n",
    "| 13  | 115           | +4     | 4    | 0    |\n",
    "| 14  | 116           | +1     | 1    | 0    |\n",
    "\n",
    "**Step 1)** Calculate average gain and average loss\n",
    "\n",
    "* Sum the gains for the first 14 days = 2 + 0 + 2 + 2 + 0 + 3 + 3 + 0 + 3 + 1 + 0 + 4 + 1 = 21\n",
    "* Sum the losses for the first 14 days = 0 + 1 + 0 + 0 + 1 + 0 + 0 + 1 + 0 + 0 + 2 + 0 + 0 = 5\n",
    "\n",
    "* Average gain = 21 / 14 = 1.5\n",
    "* Average loss = 5 / 14 = 0.36\n",
    "  \n",
    "<br>\n",
    "\n",
    "**Step 2)** Calculate Relative Strength (RS)\n",
    "\n",
    "* RS = Average gain / Average loss = 1.5 / 0.36 = 4.17\n",
    "\n",
    "<br>\n",
    "\n",
    "**Step 3)** Calculate RSI\n",
    "\n",
    "* RSI = 100 - 100 / (1 + RS) = 100 - 100 / 5.17 = 80.65\n",
    "\n",
    "Note: This (80.65) is the RSI value on the 14th day as it uses price data from day 1 to day 14. If I wanted the RSI value for the 15th day, it will be based on price data from day 2 to day 15.\n",
    "<br>\n",
    "\n",
    "**4) Money Flow Index (MFI)** \n",
    "\n",
    "In addition to the previously mentioned technical indicators, I will also incorporate the Money Flow Index (MFI) as another important independent variable in my analysis.\n",
    "\n",
    "MFI is a momentum indicator that measures the flow of money into and out of an asset over a specific period of time, typically 14 days. The MFI combines both price and volume, which helps identify overbought or oversold conditions in the market. It is calculated by comparing the typical price (average of high, low, and close) of each period to the volume of trades during that period. When the MFI is above 80, it indicates that the asset is overbought, and when it is below 20, it indicates that the asset is oversold. Traders use the MFI to confirm price trends or spot potential reversals, as extreme values of MFI can signal that an asset is about to experience a trend change.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Fidelity_MFI.png\"><p style=\"text-align: right;\">(Fidelity, n.d., Money Flow Index)</p>\n",
    "</div>\n",
    "\n",
    "For the purposes of my analysis, I will be calculating MFI using a 14-day period, which is the standard lookback period. MFI will help me capture the relationship between price movements and volume flow, similar to Money Flow Index (MFI), but with the added complexity of considering both price and volume for identifying buying or selling pressure. \n",
    "\n",
    "Below is an example of how MFI might be calculated, starting with determining the typical price for each day (High + Low + Close) / 3, then multiplying by volume, and finally applying the formula to get the MFI over a 14-day period:\n",
    "\n",
    "\n",
    "| Day | High | Low | Close | Volume | Typical Price | Money Flow | MFI Calculation |\n",
    "|-----|------|-----|-------|--------|---------------|------------|-----------------|\n",
    "| 1   | 105  | 98  | 102   | 2000   | (105 + 98 + 102) / 3 = 101.67 | Positive   | N/A (First day) |\n",
    "| 2   | 107  | 100 | 104   | 2500   | (107 + 100 + 104) / 3 = 103.67 | Positive   | N/A (First 14 days) |\n",
    "| 3   | 106  | 99  | 103   | 2200   | (106 + 99 + 103) / 3 = 102.67 | Negative   | N/A (First 14 days) |\n",
    "| 4   | 108  | 101 | 106   | 2400   | (108 + 101 + 106) / 3 = 105.00 | Positive   | N/A (First 14 days) |\n",
    "| 5   | 110  | 104 | 107   | 2300   | (110 + 104 + 107) / 3 = 107.00 | Positive   | N/A (First 14 days) |\n",
    "| 6   | 111  | 105 | 109   | 2500   | (111 + 105 + 109) / 3 = 108.33 | Positive   | N/A (First 14 days) |\n",
    "| 7   | 113  | 106 | 110   | 2600   | (113 + 106 + 110) / 3 = 109.67 | Positive   | N/A (First 14 days) |\n",
    "| 8   | 115  | 108 | 112   | 2700   | (115 + 108 + 112) / 3 = 111.67 | Positive   | N/A (First 14 days) |\n",
    "| 9   | 116  | 109 | 113   | 2800   | (116 + 109 + 113) / 3 = 112.67 | Positive   | N/A (First 14 days) |\n",
    "| 10  | 118  | 110 | 114   | 2900   | (118 + 110 + 114) / 3 = 114.00 | Positive   | N/A (First 14 days) |\n",
    "| 11  | 120  | 112 | 116   | 3000   | (120 + 112 + 116) / 3 = 116.00 | Positive   | N/A (First 14 days) |\n",
    "| 12  | 122  | 113 | 118   | 3100   | (122 + 113 + 118) / 3 = 117.67 | Positive   | N/A (First 14 days) |\n",
    "| 13  | 124  | 115 | 119   | 3200   | (124 + 115 + 119) / 3 = 119.33 | Positive   | N/A (First 14 days) |\n",
    "| 14  | 126  | 116 | 121   | 3300   | (126 + 116 + 121) / 3 = 121.00 | Positive   | N/A (First 14 days) |\n",
    "| 15  | 125  | 118 | 120   | 3400   | (125 + 118 + 120) / 3 = 121.00 | Negative   | MFI = (Positive Money Flow / Negative Money Flow) * 100 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**5) Moving Average Convergence Divergence (MACD)** \n",
    "\n",
    "MACD will be associated with two more independent variables for my analysis, MACD line and signal line.\n",
    "\n",
    "MACD is a trend-following momentum indicator that shows the relationship between two moving averages of a stock’s price. First, we need to understand what moving averages are in relationship to stock price. In simple terms, a moving average calculation computes the average of a stock's prices over a specific period. This helps to smooth out short-term price fluctuations, making it easier to identify long-term trends.\n",
    "\n",
    "We have different types of moving averages: \n",
    "\n",
    "1. Simple Moving Average (SMA): This is the average of a stock's price over a specific period of time. For example, a 10-day SMA is the average of the last 10 days of closing prices. It gives equal weight to each price point in the calculation.\n",
    "   \n",
    "2. Exponential Moving Average (EMA): The EMA is a variation of the moving average that gives more weight to recent prices, making it more sensitive to new information. This is important for capturing recent price movements and trends more quickly than the SMA, which treats all price data equally.\n",
    "\n",
    "Now that we understand moving averages, MACD is calculated by subtracting the 26-day exponential moving average (EMA) from the 12-day EMA. The resulting value is the MACD line. \n",
    "The 26-day EMA reflects long term price trends which smooths out price data over a longer period while the 12-day EMA captures short term price trends. The subtraction between them resulting in the MACD line is important as it represents the difference between short and long term price trends.\n",
    "\n",
    "Along with the MACD line, a signal line is also calculated. This is a 9-day EMA of the MACD line, and it helps traders identify buy and sell signals. Specifically, the signal line is calculated by taking the MACD line values for the past 9 days and applying the standard EMA formula to smooth out fluctuations in the MACD line over this period.\n",
    "\n",
    "When the MACD line crosses above the signal line, it is generally considered a bullish signal, suggesting a potential upward movement in the stock price. Conversely, when the MACD line crosses below the signal line, it is viewed as a bearish signal, indicating a potential downward price movement.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Fidelity_MACD.png\"><p style=\"text-align: right;\">(Fidelity, n.d., MACD)</p>\n",
    "</div>\n",
    "\n",
    "The MACD line also reports bullish signals when it turns up from below zero. Conversely, while it crosses below zero, it is considered bearish.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/Fidelity_MACD_above_below_zero.png\"><p style=\"text-align: right;\">(Fidelity, n.d., MACD)</p>\n",
    "</div>\n",
    "\n",
    "Here is how MACD will be calculated in my analysis, starting with the following formula to calculate EMA:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/MACD_EMA_formula.png\">\n",
    "</div>\n",
    "\n",
    "To calculate the 12-day EMA, we need to start out by calculating the 12-day SMA (simple moving average).\n",
    "\n",
    "| Day | Price |\n",
    "|-----|-------|\n",
    "| 1   | 100   |\n",
    "| 2   | 102   |\n",
    "| 3   | 105   |\n",
    "| 4   | 107   |\n",
    "| 5   | 110   |\n",
    "| 6   | 108   |\n",
    "| 7   | 111   |\n",
    "| 8   | 113   |\n",
    "| 9   | 112   |\n",
    "| 10  | 115   |\n",
    "| 11  | 118   |\n",
    "| 12  | 120   |\n",
    "\n",
    "**Step 1)** Calculate SMA\n",
    "\n",
    "12-day SMA = sum of stock prices / 12 days = (100 + 102 + 105 + 107 + 110 + 108 + 111 + 113 + 112 + 115 + 118 + 120) / 12 = 100.08\n",
    "\n",
    "Although 100.08 is the SMA of those 12 days, it is also called EMA(1) or EMA1.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Step 2)** Calculate the EMA for subsequent days using the formula\n",
    "\n",
    "* For Day 2\n",
    "\n",
    "EMA(2) = (2 / (12 + 1)) × (102−100.08) + 100.08 = 0.1538 × 1.92 + 100.08 = 100.3753\n",
    "\n",
    "* For Day 3\n",
    "\n",
    "EMA(3) = (2 / (12 + 1)) × (105−100.3753) + 100.3753 = 0.1538 × 4.6247 + 100.3753 = 101.0866\n",
    "\n",
    "* For Day 4\n",
    "\n",
    "EMA(4) = (2 / (12 + 1)) × (107−101.0866) + 101.0866 = 0.1538 × 5.9134 + 101.0866 = 101.9961\n",
    "\n",
    "Keep repeating until you get to day 12 or EMA(12); the value on this day is the 12-day EMA. When calculating 26-day EMA, the calculation is the same except the calculation will use a 26 day period. \n",
    "\n",
    "Then as mentioned previously, to get the MACD value (or MACD line), just subtract the 26-day EMA from the 12-day EMA.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Now, here is how the signal line will be calculated in my analysis, the calculation for the signal line is similar as it uses a similar EMA formula. To calculate the signal line, we have to use the following formula:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"C:/Users/james/Documents/WGU/Course-D214-MSDA Capstone/Screenshots/MACD_EMA_formula_signal_line.png\">\n",
    "</div>\n",
    "\n",
    "(Example data)\n",
    "| Day | 26-Day EMA | 12-Day EMA | MACD (12-Day EMA - 26-Day EMA) |\n",
    "|-----|------------|------------|--------------------------------|\n",
    "| 1   | 0.5        | 0.5        | 0                              |\n",
    "| 2   | 0.515      | 0.531      | 0.016                          |\n",
    "| 3   | 0.520      | 0.537      | 0.017                          |\n",
    "| 4   | 0.531      | 0.555      | 0.024                          |\n",
    "| 5   | 0.541      | 0.580      | 0.039                          |\n",
    "| 6   | 0.563      | 0.601      | 0.038                          |\n",
    "| 7   | 0.584      | 0.620      | 0.036                          |\n",
    "| 8   | 0.602      | 0.634      | 0.032                          |\n",
    "| 9   | 0.620      | 0.646      | 0.026                          |\n",
    "\n",
    "**Step 1)** Calculate the 9-day SMA of MACD\n",
    "\n",
    "9-day SMA = 0 + 0.016 + 0.017 + 0.024 + 0.039 + 0.038 + 0.036 + 0.032 + 0.026 / 9 = 0.0253\n",
    "\n",
    "Although 0.0253 is the SMA of those 9 days, it is also called EMA(1) or EMA1 of the signal line.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Step 2)** Apply EMA formula until we reach Day 9 which gives us the value of the 9-day EMA of the MACD Line\n",
    "\n",
    "* For Day 2\n",
    "\n",
    "EMA(2) = (2 / (9 + 1)) × (0.016−0.0253) + 0.0253 = 0.2 × (-0.0093) + 0.0253 = 0.02344\n",
    "\n",
    "* For Day 3\n",
    "\n",
    "EMA(3) = (2 / (9 + 1)) × (0.017−0.02344) + 0.02344 = 0.2 × (-0.00644\n",
    ") + 0.02344 = 0.0222\n",
    "\n",
    "* Repeat until Day 9 to get EMA(9) or EMA 9; this is the 9-day EMA of the MACD line, or in other words the value of the signal line.\n",
    "\n",
    "<br>\n",
    "To summarize, MACD (or MACD Line) will be calculated using a 12-day and 26-day lookback period in my analysis by subtracting the 26-day EMA from the 12-day EMA. The signal line will be calculated as the 9-day EMA of the MACD Line. These periods are standard and widely accepted for calculating the MACD and signal line.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "**6) RNN (Recurrent Neural Network)** \n",
    "\n",
    "An RNN (Recurrent Neural Network) is a type of neural network designed for processing sequences of data, such as time series, speech, or text. Unlike traditional feedforward neural networks, RNNs have connections that loop back on themselves, allowing information to persist across steps in the sequence.\n",
    "\n",
    "The key feature of an RNN is its ability to maintain a hidden state that acts as memory, enabling the network to remember past information and use it to influence predictions for future inputs. This makes RNNs suitable for tasks where the order and context of data are important.\n",
    "\n",
    "For example, in addition to an RNN's ability to retain and process long-term dependencies from past information, it is also capable of understanding the context and meaning of a sentence based on the order of words. This ability allows the network to distinguish between different sentence structures that might use the same words but convey entirely different meanings, such as \"the mouse ate the cat\" versus \"the cat ate the mouse.\"\n",
    "\n",
    "While both sentences consist of the same words, their meaning changes dramatically depending on the order of the words. An RNN processes each word sequentially (processes each word, one at a time, from left to right) and updates it hidden state to reflect which is the word that performs the action (the eating) and which is the word that is the object being eaten.\n",
    "\n",
    "In my project, I am deploying a time series model, where I believe the sequence of variables plays a crucial role in predicting future prices making an RNN a robust choice for my model selection. For instance, yesterday’s price action should have a stronger influence on predicting today’s stock prices than price action from ten days ago.\n",
    "\n",
    "Since I am using 30 days of historical data to predict future stock prices, it is important that I use a model such as an RNN which can recognize the order in which events occur significantly influences future outcomes. For instance, the price action over the last few days is more relevant for predicting today's stock price than events that happened weeks ago.\n",
    "\n",
    "However, vanilla RNNs have limitations, such as difficulty learning long-term dependencies due to issues like vanishing gradients. To address this, more advanced versions of RNNs like LSTMs (Long Short-Term Memory) were developed and is better at capturing long-range dependencies in sequences.\n",
    "<br>\n",
    "\n",
    "**7) Long Short-Term Memory (LSTM) neural network** \n",
    "\n",
    "Specifically, to answer my research question I will be using a variant of the RNN, which is called a Long Short-Term Memory (LSTM) neural network.\n",
    "\n",
    "LSTMs (Long Short-Term Memory) are advanced types of RNNs that address common RNN issues like vanishing gradients. They are particularly effective for long text sequences because they retain information over longer dependencies.\n",
    "\n",
    "To understand the issue of a vanishing gradient, it is important to understand what a gradient is. The gradient is the slope or the direction of deepest descent in relation to minimizing the error (cost) function. For a simplified understanding let us take the equation for univariate linear regression: y = mx + b. By getting the best fit line through our set of data points we now have 'm' (slope) and 'b' (intercept). But the values for 'm' and 'b' did not come from just anywhere - it came from minimizing the the linear regression error function. In essence the error function minimizes SSR which is the sum of the square root of the residuals (observed vs. predicted values) to get the best values for 'm' and 'b'. \n",
    "\n",
    "Let us pretend the error function for linear regression was f(x) = x^2 (which it is not, but pretend it is). We can see that the error function graphs a parabola. Let us for example plug in the value where x = 4, this returns a value of 16 as 4^2 = 16. So we get the coordinates on our parabola of (4,16), which are simple (x,y) coordinates, where the value of 16 is our total error when x = 4. If we take the partial derivative of the error function, f(x) = x^2 in respect to 'x', we get the following equation: d/dx = 2x. Here the 'd/dx' just refers to the partial derivative in respect to 'x'. So now, using the same x = 4 value to plug into our partial derivative formula we get: 2 * 4 = 8. Here, the value 8 represents the slope tangent to the coordinates (4,16); or we can say that at coordinates (4,16) the value 8 represents the direction of deepest descent in relation to minimizing the error function. Specifically, the value of 8 is our gradient when x = 4. We mentioned previously that for our error function, when x = 4, y = 16, the y-value of '16' represents the total error. Now, that we have our gradient we can subtract our current 'x' value of 4 by the gradient of 8, which gives us a new value, x = -4. However, when we do that we run into a problem where the error function will never be minimized as when we plug x = -4 back into our error function it returns the same total error value of 16. This is why it is recommended to multiply the gradient by a learning rate before subtracting it from the previous 'x' value. If our learning rate = 0.5, we can multiply our gradient: 0.25 * 8 = 2. So now we can take our 'x' value of 4 and subtract it with our gradient with the learning rate applied: 4 - (0.25 * 8) = 4 - 2 = 2. The value '2' will now be plugged into our error function f(x) = x^2 -> 2^2 = 4. Now we can see our total error is at '4', which is much lower than it was at '16' previously. We repeat this process iteratively, adjusting x each time, until the error is as small as possible. This in a nutshell is gradient descent. However just to clarify, in the case of linear regression, the actual error function requires computing the partial derivatives of the error function with respect to both 'm' (slope) and 'b' (intercept). These gradients are then used to minimize the error by updating both 'm' and 'b' iteratively.\n",
    "\n",
    "Now that we understand what gradient descent is, neural networks rely on a process called backpropagation to adjust their weights (think of this as the slope and intercept in the previous example) based on the gradient, which indicates the direction of deepest descent in relation to minimizing error. However, in very deep networks or sequential models like Recurrent Neural Networks (RNNs), this process can lead to the vanishing gradient problem. As the gradients are passed backward through multiple layers or time steps, they are repeatedly multiplied, and if they are small values (fractions), this causes them to shrink exponentially. Eventually, the gradients become nearly zero, meaning earlier layers or time steps receive insignificant updates during training. As a result, the model struggles to learn long-term dependencies or patterns, making it difficult to capture important relationships in the data.\n",
    "\n",
    "LSTM networks address this issue as their architecture consists of \"cells\", rather than traditional \"nodes\" found in other neural networks. These LSTM cells are the fundamental building blocks of LSTM networks which help address the vanishing gradient problem.\n",
    "\n",
    "Each LSTM cell has a memory cell, a hidden state, and three main gates: the forget gate, the input gate, and the output gate. The memory cell stores important information over time. The forget gate decides what information in the memory cell should be discarded, helping the network forget irrelevant or outdated data. The input gate controls which new information should be added to the memory cell, allowing the LSTM to update its knowledge with new data as it comes in. The output gate determines which part of the information in the memory cell should be passed on to the hidden state, which is then passed on the the next LSTM cell. \n",
    "\n",
    "By controlling the flow of information in and out of the memory cell, the LSTM can remember long-term patterns in the data while preventing the vanishing gradient problem, which helps the model learn more effectively over longer sequences. \n",
    "\n",
    "I am using a sequence of 30 days of stock data (one observation), then the LSTM network will process each day of the sequence as a separate time step. For each of these time steps (daily data), there will be an LSTM cell that processes the data.\n",
    "\n",
    "In my case:\n",
    "\n",
    "* One obervation consists of 30 days of data (including candlestick data like open, close, high, low prices, as well as technical indicators like MFI, MACD, and RSI)\n",
    "* There are 30 time steps because each day is treated as one time step\n",
    "* There are 30 LSTM cells because one LSTM cell processes only one time step (one day)\n",
    "\n",
    "Thus, the LSTM network will process the full 30-day sequence, one day (or time step) at a time, with each LSTM cell handling a single time step in the sequence. After the LSTM processes the one time step, it passes information to the next cell (via the output gate to the hidden state, then to the next cell) in the sequence. This allows the network to capture the temporal dependencies and patterns over the 30 days of data, meaning that earlier time steps are influencing later time steps. This allows the network to learn patterns over time and remember information from previous time steps, which is crucial for time-series data like stock prices.\n",
    "\n",
    "After training the model, the LSTM will make predictions about future stock price movements by leveraging the patterns it has learned from the 30 time steps (days) across all of my observations.\n",
    "\n",
    "The combination of these gates allows the LSTM to maintain and manage long-term dependencies in the data, unlike traditional RNNs, which struggle with this due to the vanishing gradient problem. As the gates selectively control the flow of information, the LSTM network can \"remember\" important information over long periods, making it very effective for time-series data such as stock prices, where past data can influence future trends. This is particularly useful in my research on stock price prediction, where patterns and trends from previous days or months could significantly impact predictions for the next day.\n",
    "\n",
    "So, that we fully understand, I am going to use a quick second example. If we have a dataset with sentences that are all 10 words long--each sentence would be an observation, the sequence is the entire sentence, so 10 words long--one time step corresponds to one word in the sequence--since I have 10 time steps (one per word), I will have 10 LSTM cells, one for each word in the sentence. So, for each sentence (observation) with 10 words, the LSTM will process the sentence word by word (one time step at a time), and each word will be processed by an individual LSTM cell, with information being passed from one cell to the next.\n",
    "\n",
    "\n",
    "### Summary of Variables and Process of Analysis\n",
    "\n",
    "* Independent variables (8 variables)\n",
    "    + Stock Price: Low\n",
    "    + Stock Price: High\n",
    "    + Stock Price: Open\n",
    "    + Stock Price: Close\n",
    "    + Relative Strength Index (RSI)\n",
    "    + Money Flow Index (MFI)\n",
    "    + Moving Average Convergence Divergence (MACD): MACD line\n",
    "    + Moving Average Convergence Divergence (MACD): Signal line\n",
    "<br><br>\n",
    "\n",
    "* Dependent variable\n",
    "    + Binary Classification: Predicting if the closing price will go 'up' or 'down' for multiple future time periods (1 day, 3 days, 5 days, 10 days, and 15 days), compared to the closing price from the last candle of the identified candlestick pattern.\n",
    "    + Regression: Predicting the exact closing price (a continuous value) for multiple future time periods (1 day, 3 days, 5 days, 10 days, and 15 days), after the identified candlestick pattern.\n",
    "\n",
    "<br>\n",
    "As a reminder, we are going to identify these five candlestick patterns and train an LSTM on their 30-day sequences:\n",
    "\n",
    "1. Hammer\n",
    "2. Inverted Hammer\n",
    "3. Bullish Englufing Pattern\n",
    "4. Bullish Harami\n",
    "5. Three White Soldiers\n",
    "\n",
    "For example, with our data of daily stock prices we will identify all \"hammer\" candlestick patterns using the data definition I previously defined. I am then going to lookback 30 days from the end of my identified candlestick pattern to gather all the data for my independent variables; the last candle in the candlestick pattern is the 30th day in the sequence.\n",
    "\n",
    "A specific example is that I identified the last candle in a \"hammer\" candlestick pattern to occur on January 30th. So, since my sequence is 30 days, I will take all the data from January 1 to January 30th. On each of those days, I will gather my 8 independent variables. Each time-step represents one day, meaning I have 8 independent variables per day, and across the entire 30-day sequence, I will have a dataset with 30 time-steps, each containing 8 features. This 30-day sequence will serve as the input to the LSTM model, which will learn to recognize patterns in the time series data and predict the closing price for future days, conditioned on the identified candlestick pattern.\n",
    "\n",
    "Although, some of the identified patterns are of different lengths; the hammer pattern is identified using one days's worth of data, while the three white soldiers is identified using three day's worth of data--my sequence will always incorporate only 30 days worth of data.\n",
    "\n",
    "Just something to note, since my independent variable data is a 30-day sequence, it is on the 30th day of that sequence which includes the data of the last candle for the identified candlestick pattern. On the 30th day of the sequence is where I retrieve my closing prices to compare against the closing price of a future day.\n",
    "\n",
    "To conclude, at the end of my analysis I will have five different trained LSTMs each using a different set of 30-day sequence data which represents a specific candlestick pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f768ef-1b80-46b7-baa2-ab7d021a9eb4",
   "metadata": {},
   "source": [
    "# Data Acquisition - _B, C_\n",
    "\n",
    "### Load necessary packages for data acquisition:\n",
    "\n",
    "1. yfinance: Used to access Yahoo finance data via their API\n",
    "2. pandas: Used to read the finance data into a data frame and inspect data\n",
    "\n",
    "An important thing to note about the 'yfinance' package is that it automatically adjusts the stock prices for stock splits when retrieving historical data. This is great, so that I do not have to manually adjust them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5764891e-0c2f-4bd9-8063-e64771d8b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bd614-58d3-4c63-9442-026891c5ee86",
   "metadata": {},
   "source": [
    "### Preview Data\n",
    "\n",
    "I am going to select the stock ticker 'SPY' to perform my initial data cleaning. Once I create my data cleaning function, I will be able to apply it to other stock tickers. However, for this project, I am selecting 'SPY' because it encompasses many stocks and represents a broad market index, making it a reliable proxy for overall market performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a476d2d-d143-40ec-8047-a28620492e04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Capital Gains</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03 00:00:00-05:00</th>\n",
       "      <td>94.485455</td>\n",
       "      <td>94.485455</td>\n",
       "      <td>91.697098</td>\n",
       "      <td>92.692940</td>\n",
       "      <td>8164300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04 00:00:00-05:00</th>\n",
       "      <td>91.478006</td>\n",
       "      <td>91.816592</td>\n",
       "      <td>88.998361</td>\n",
       "      <td>89.068069</td>\n",
       "      <td>8089800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05 00:00:00-05:00</th>\n",
       "      <td>89.187560</td>\n",
       "      <td>90.203319</td>\n",
       "      <td>87.474713</td>\n",
       "      <td>89.227394</td>\n",
       "      <td>12177900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06 00:00:00-05:00</th>\n",
       "      <td>88.988414</td>\n",
       "      <td>90.183424</td>\n",
       "      <td>87.793404</td>\n",
       "      <td>87.793404</td>\n",
       "      <td>6227200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07 00:00:00-05:00</th>\n",
       "      <td>89.426569</td>\n",
       "      <td>92.892097</td>\n",
       "      <td>89.267234</td>\n",
       "      <td>92.892097</td>\n",
       "      <td>8066500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2000-01-03 00:00:00-05:00  94.485455  94.485455  91.697098  92.692940   \n",
       "2000-01-04 00:00:00-05:00  91.478006  91.816592  88.998361  89.068069   \n",
       "2000-01-05 00:00:00-05:00  89.187560  90.203319  87.474713  89.227394   \n",
       "2000-01-06 00:00:00-05:00  88.988414  90.183424  87.793404  87.793404   \n",
       "2000-01-07 00:00:00-05:00  89.426569  92.892097  89.267234  92.892097   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  Capital Gains  \n",
       "Date                                                                         \n",
       "2000-01-03 00:00:00-05:00   8164300        0.0           0.0            0.0  \n",
       "2000-01-04 00:00:00-05:00   8089800        0.0           0.0            0.0  \n",
       "2000-01-05 00:00:00-05:00  12177900        0.0           0.0            0.0  \n",
       "2000-01-06 00:00:00-05:00   6227200        0.0           0.0            0.0  \n",
       "2000-01-07 00:00:00-05:00   8066500        0.0           0.0            0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"SPY\" #The stock ticker for 'S&P 500'\n",
    "ticker_symbol = ticker #used for the training step in a later section as need to save ticker data\n",
    "ticker = yf.Ticker(ticker)\n",
    "\n",
    "# Define the custom date range (start and end dates in 'YYYY-MM-DD' format)\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2025-2-14\"\n",
    "\n",
    "# Fetch the historical data for the defined date range\n",
    "finance_df = ticker.history(start=start_date, end=end_date)\n",
    "#finance_df = ticker.history(period=\"10y\") #Get 10 years worth of data, #10y, #max\n",
    "\n",
    "#write out CSV\n",
    "finance_df.to_csv(f'{ticker_symbol}_financials_output.csv', index=False)  # `index=False` avoids writing the index column\n",
    "\n",
    "#preview data\n",
    "finance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de10ed-8891-44c5-9319-af86791617e8",
   "metadata": {},
   "source": [
    "# Data Cleaning and Exploratory Data Analysis\n",
    "\n",
    "### Load necessary packages for data acquisition:\n",
    "\n",
    "1. numpy: Used for numerical computations, in my case, computations with data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9453c19-a82b-4760-a7d0-a464e64bfa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load package\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fe9e2-b19c-4560-9d73-64ed34ff44cb",
   "metadata": {},
   "source": [
    "### Data Cleaning Process\n",
    "\n",
    "1. Identify the 'hammer' pattern\n",
    "\n",
    "2. Identify the 'inverted hammer' pattern\n",
    "\n",
    "3. Identify the 'bullish engulfing' pattern\n",
    "\n",
    "4. Identify the 'bullish harami' pattern\n",
    "\n",
    "5. Identify the 'three white soldiers' pattern\n",
    "\n",
    "6. Perform Further Cleaning on Variables / Calculate Variables (RSI, MACD, MFI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb714ed0-40f9-4feb-9688-862072b66a7a",
   "metadata": {},
   "source": [
    "### Data Cleaning Outcomes\n",
    "\n",
    "Each step in this 'data cleaning outcomes' section corresponds to the numeric step in the 'data cleaning process' section.\n",
    "\n",
    "**1) Identify the Hammer Pattern**\n",
    "\n",
    "Remember my following definition of the hammer candlestick pattern:\n",
    "\n",
    "_Looking for a bullish or bearish candlestick with a small body (body is less than 30% of the total candlestick length; candlestick length is the distance between low and high), with the lower shadow (the distance between the low and the open for a bullish candle, or the low and the close for a bearish candle) being at least two times the length of the body. There also must be little to no upper shadow (upper shadow will be less than 10% of the total candle length). This pattern must occur during a downtrend; to confirm a downtrend, I will fit a regression line (line of best fit) through the closing prices for the previous five candles-if the slope is negative or equal to zero, this means that a downtrend is present. It doesn't matter if the single candlestick is a bearish or bullish candle, they both can display the hammer pattern._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2883ae2-5991-4ee1-90cb-6f073c2452af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Row_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03 00:00:00-05:00</th>\n",
       "      <td>94.485455</td>\n",
       "      <td>94.485455</td>\n",
       "      <td>91.697098</td>\n",
       "      <td>92.692940</td>\n",
       "      <td>8164300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04 00:00:00-05:00</th>\n",
       "      <td>91.478006</td>\n",
       "      <td>91.816592</td>\n",
       "      <td>88.998361</td>\n",
       "      <td>89.068069</td>\n",
       "      <td>8089800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05 00:00:00-05:00</th>\n",
       "      <td>89.187560</td>\n",
       "      <td>90.203319</td>\n",
       "      <td>87.474713</td>\n",
       "      <td>89.227394</td>\n",
       "      <td>12177900</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06 00:00:00-05:00</th>\n",
       "      <td>88.988414</td>\n",
       "      <td>90.183424</td>\n",
       "      <td>87.793404</td>\n",
       "      <td>87.793404</td>\n",
       "      <td>6227200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07 00:00:00-05:00</th>\n",
       "      <td>89.426569</td>\n",
       "      <td>92.892097</td>\n",
       "      <td>89.267234</td>\n",
       "      <td>92.892097</td>\n",
       "      <td>8066500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2000-01-03 00:00:00-05:00  94.485455  94.485455  91.697098  92.692940   \n",
       "2000-01-04 00:00:00-05:00  91.478006  91.816592  88.998361  89.068069   \n",
       "2000-01-05 00:00:00-05:00  89.187560  90.203319  87.474713  89.227394   \n",
       "2000-01-06 00:00:00-05:00  88.988414  90.183424  87.793404  87.793404   \n",
       "2000-01-07 00:00:00-05:00  89.426569  92.892097  89.267234  92.892097   \n",
       "\n",
       "                             Volume  Row_index  \n",
       "Date                                            \n",
       "2000-01-03 00:00:00-05:00   8164300          1  \n",
       "2000-01-04 00:00:00-05:00   8089800          2  \n",
       "2000-01-05 00:00:00-05:00  12177900          3  \n",
       "2000-01-06 00:00:00-05:00   6227200          4  \n",
       "2000-01-07 00:00:00-05:00   8066500          5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_df = finance_df.drop('Dividends', axis=1) #remove 'Dividends' column\n",
    "finance_df = finance_df.drop('Stock Splits', axis=1) #remove 'Dividends' column\n",
    "finance_df = finance_df.drop('Capital Gains', axis=1) #remove 'Dividends' column\n",
    "finance_df['Row_index'] = range(1, len(finance_df) + 1) #creates index column\n",
    "finance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f418e0bd-48f8-4dde-8d05-262065d90843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Row_index</th>\n",
       "      <th>Candle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03 00:00:00-05:00</th>\n",
       "      <td>94.485455</td>\n",
       "      <td>94.485455</td>\n",
       "      <td>91.697098</td>\n",
       "      <td>92.692940</td>\n",
       "      <td>8164300</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04 00:00:00-05:00</th>\n",
       "      <td>91.478006</td>\n",
       "      <td>91.816592</td>\n",
       "      <td>88.998361</td>\n",
       "      <td>89.068069</td>\n",
       "      <td>8089800</td>\n",
       "      <td>2</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05 00:00:00-05:00</th>\n",
       "      <td>89.187560</td>\n",
       "      <td>90.203319</td>\n",
       "      <td>87.474713</td>\n",
       "      <td>89.227394</td>\n",
       "      <td>12177900</td>\n",
       "      <td>3</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06 00:00:00-05:00</th>\n",
       "      <td>88.988414</td>\n",
       "      <td>90.183424</td>\n",
       "      <td>87.793404</td>\n",
       "      <td>87.793404</td>\n",
       "      <td>6227200</td>\n",
       "      <td>4</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07 00:00:00-05:00</th>\n",
       "      <td>89.426569</td>\n",
       "      <td>92.892097</td>\n",
       "      <td>89.267234</td>\n",
       "      <td>92.892097</td>\n",
       "      <td>8066500</td>\n",
       "      <td>5</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2000-01-03 00:00:00-05:00  94.485455  94.485455  91.697098  92.692940   \n",
       "2000-01-04 00:00:00-05:00  91.478006  91.816592  88.998361  89.068069   \n",
       "2000-01-05 00:00:00-05:00  89.187560  90.203319  87.474713  89.227394   \n",
       "2000-01-06 00:00:00-05:00  88.988414  90.183424  87.793404  87.793404   \n",
       "2000-01-07 00:00:00-05:00  89.426569  92.892097  89.267234  92.892097   \n",
       "\n",
       "                             Volume  Row_index   Candle  \n",
       "Date                                                     \n",
       "2000-01-03 00:00:00-05:00   8164300          1  Bearish  \n",
       "2000-01-04 00:00:00-05:00   8089800          2  Bearish  \n",
       "2000-01-05 00:00:00-05:00  12177900          3  Bullish  \n",
       "2000-01-06 00:00:00-05:00   6227200          4  Bearish  \n",
       "2000-01-07 00:00:00-05:00   8066500          5  Bullish  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates a conditional statement based on conditions, and applies the 'choices' label.\n",
    "#This will result in a new column 'Candle', which describes if the daily candle was 'Bullish',\n",
    "#Bearish, or Neutral\n",
    "conditions = [\n",
    "    finance_df['Close'] > finance_df['Open'],\n",
    "    finance_df['Close'] == finance_df['Open'],\n",
    "    finance_df['Open'] > finance_df['Close']\n",
    "]\n",
    "choices = ['Bullish', 'Neutral', 'Bearish']\n",
    "finance_df['Candle'] = np.select(conditions, choices, default='Unknown')\n",
    "finance_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd63046b-0773-411c-8ad0-9bb676b9f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column 'Body_length' which calculates the body length of the \n",
    "#candle. \n",
    "finance_df['Body_length'] = abs(finance_df['Close'] - finance_df['Open']) #get the absolute number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850dd6f9-a8fb-4e47-85bd-97e15d127825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column 'Lower_shadow_length' which calculates the distance between \n",
    "#the low and the open for a bullish candle, or the low and the close for a bearish candle.\n",
    "conditions = [\n",
    "    finance_df['Candle'] == 'Bullish',\n",
    "    finance_df['Candle'] == 'Neutral',\n",
    "    finance_df['Candle'] == 'Bearish'\n",
    "]\n",
    "choices = [finance_df['Open'] - finance_df['Low'], \n",
    "           finance_df['Open'] - finance_df['Low'], \n",
    "           finance_df['Close'] - finance_df['Low']]\n",
    "finance_df['Lower_shadow_length'] = np.select(conditions, choices, default=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5704156e-5701-44d0-8399-bfea944f8dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column 'Upper_shadow_length' which calculates the distance between \n",
    "#the high and the close for a bullish candle, or the high and the open for a bearish candle.\n",
    "conditions = [\n",
    "    finance_df['Candle'] == 'Bullish',\n",
    "    finance_df['Candle'] == 'Neutral',\n",
    "    finance_df['Candle'] == 'Bearish'\n",
    "]\n",
    "choices = [finance_df['High'] - finance_df['Close'], \n",
    "           finance_df['High'] - finance_df['Close'], \n",
    "           finance_df['High'] - finance_df['Open']]\n",
    "finance_df['Upper_shadow_length'] = np.select(conditions, choices, default=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cacfe504-b3bf-489e-b769-3293156ae248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Row_index</th>\n",
       "      <th>Candle</th>\n",
       "      <th>Body_length</th>\n",
       "      <th>Lower_shadow_length</th>\n",
       "      <th>Upper_shadow_length</th>\n",
       "      <th>Total_candle_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03 00:00:00-05:00</th>\n",
       "      <td>94.485455</td>\n",
       "      <td>94.485455</td>\n",
       "      <td>91.697098</td>\n",
       "      <td>92.692940</td>\n",
       "      <td>8164300</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>1.792515</td>\n",
       "      <td>0.995842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.788357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04 00:00:00-05:00</th>\n",
       "      <td>91.478006</td>\n",
       "      <td>91.816592</td>\n",
       "      <td>88.998361</td>\n",
       "      <td>89.068069</td>\n",
       "      <td>8089800</td>\n",
       "      <td>2</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>2.409937</td>\n",
       "      <td>0.069709</td>\n",
       "      <td>0.338586</td>\n",
       "      <td>2.818232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05 00:00:00-05:00</th>\n",
       "      <td>89.187560</td>\n",
       "      <td>90.203319</td>\n",
       "      <td>87.474713</td>\n",
       "      <td>89.227394</td>\n",
       "      <td>12177900</td>\n",
       "      <td>3</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>0.039834</td>\n",
       "      <td>1.712847</td>\n",
       "      <td>0.975925</td>\n",
       "      <td>2.728606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06 00:00:00-05:00</th>\n",
       "      <td>88.988414</td>\n",
       "      <td>90.183424</td>\n",
       "      <td>87.793404</td>\n",
       "      <td>87.793404</td>\n",
       "      <td>6227200</td>\n",
       "      <td>4</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>1.195010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.195010</td>\n",
       "      <td>2.390020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07 00:00:00-05:00</th>\n",
       "      <td>89.426569</td>\n",
       "      <td>92.892097</td>\n",
       "      <td>89.267234</td>\n",
       "      <td>92.892097</td>\n",
       "      <td>8066500</td>\n",
       "      <td>5</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>3.465529</td>\n",
       "      <td>0.159335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.624863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2000-01-03 00:00:00-05:00  94.485455  94.485455  91.697098  92.692940   \n",
       "2000-01-04 00:00:00-05:00  91.478006  91.816592  88.998361  89.068069   \n",
       "2000-01-05 00:00:00-05:00  89.187560  90.203319  87.474713  89.227394   \n",
       "2000-01-06 00:00:00-05:00  88.988414  90.183424  87.793404  87.793404   \n",
       "2000-01-07 00:00:00-05:00  89.426569  92.892097  89.267234  92.892097   \n",
       "\n",
       "                             Volume  Row_index   Candle  Body_length  \\\n",
       "Date                                                                   \n",
       "2000-01-03 00:00:00-05:00   8164300          1  Bearish     1.792515   \n",
       "2000-01-04 00:00:00-05:00   8089800          2  Bearish     2.409937   \n",
       "2000-01-05 00:00:00-05:00  12177900          3  Bullish     0.039834   \n",
       "2000-01-06 00:00:00-05:00   6227200          4  Bearish     1.195010   \n",
       "2000-01-07 00:00:00-05:00   8066500          5  Bullish     3.465529   \n",
       "\n",
       "                           Lower_shadow_length  Upper_shadow_length  \\\n",
       "Date                                                                  \n",
       "2000-01-03 00:00:00-05:00             0.995842             0.000000   \n",
       "2000-01-04 00:00:00-05:00             0.069709             0.338586   \n",
       "2000-01-05 00:00:00-05:00             1.712847             0.975925   \n",
       "2000-01-06 00:00:00-05:00             0.000000             1.195010   \n",
       "2000-01-07 00:00:00-05:00             0.159335             0.000000   \n",
       "\n",
       "                           Total_candle_length  \n",
       "Date                                            \n",
       "2000-01-03 00:00:00-05:00             2.788357  \n",
       "2000-01-04 00:00:00-05:00             2.818232  \n",
       "2000-01-05 00:00:00-05:00             2.728606  \n",
       "2000-01-06 00:00:00-05:00             2.390020  \n",
       "2000-01-07 00:00:00-05:00             3.624863  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create column 'Total_candle_length' which calculates the distance between low and high prices\n",
    "finance_df['Total_candle_length'] = finance_df['High'] - finance_df['Low']\n",
    "finance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad52c79-3d88-4a5a-8693-51f174158c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "hammer = [] #initialize empty list\n",
    "for index, row in finance_df.iterrows():\n",
    "    start_index = row['Row_index'] - 5 #Get the starting index of the fifth previous candle\n",
    "    end_index = row['Row_index'] - 1 #subtacting 1 because only getting previous 5 candlestick closing prices, not current candle's close\n",
    "    #for example, if row['Row_index'] = 6; start_index = 6 - 5 = 1; end_index = 6 - 1 = 5 --- getting rows 1 (start_index) through 5 (end_index) which \n",
    "    #is the previous five candles data since our current candle is the sixth candle\n",
    "    \n",
    "    \n",
    "    if (start_index < 1): #since we are subtracting to get starting index, it will be negative numbers at first; skip these\n",
    "        hammer.append(\"No\")\n",
    "        continue\n",
    "        \n",
    "    temp_df = finance_df[(finance_df['Row_index'] >= start_index) & (finance_df['Row_index'] <= end_index)]\n",
    "    closing_prices = temp_df['Close'].values\n",
    "\n",
    "    #Fit a regression line (line of best fit) through the closing prices; negative slope represent current downtrend\n",
    "    x = np.arange(len(closing_prices))\n",
    "    slope, intercept = np.polyfit(x, closing_prices, 1) \n",
    "\n",
    "    #if slope <= 0, then in a current downtrend the previous 5 days in terms of closing prices\n",
    "    #to clarify, although slope may be zero which means no change, I will still be counting this as a downtrend\n",
    "    if (slope <= 0):\n",
    "        if ((row['Lower_shadow_length']) >= (row['Body_length'] * 2)): #lower shadow must be at least twice as long as body length\n",
    "            if ((row['Upper_shadow_length']) < (row['Total_candle_length'] * 0.10)): #Upper shadow is less than 10% of the total candle length\n",
    "                if ((row['Body_length']) < (row['Total_candle_length'] * 0.30)): #body is less than 30% of the total candlestick length\n",
    "                    hammer.append(\"Yes\")\n",
    "                else:\n",
    "                    hammer.append(\"No\")\n",
    "            else:\n",
    "                hammer.append(\"No\")\n",
    "        else:\n",
    "            hammer.append(\"No\")\n",
    "            \n",
    "    elif (slope > 0):\n",
    "        hammer.append(\"No\")\n",
    "\n",
    "\n",
    "#Create new column\n",
    "finance_df['Hammer_pattern'] = hammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0947497-66c9-4185-811f-d8bba5e517cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Row_index</th>\n",
       "      <th>Candle</th>\n",
       "      <th>Body_length</th>\n",
       "      <th>Lower_shadow_length</th>\n",
       "      <th>Upper_shadow_length</th>\n",
       "      <th>Total_candle_length</th>\n",
       "      <th>Hammer_pattern</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-02-14 00:00:00-05:00</th>\n",
       "      <td>89.087943</td>\n",
       "      <td>89.087943</td>\n",
       "      <td>88.151852</td>\n",
       "      <td>88.908691</td>\n",
       "      <td>8528800</td>\n",
       "      <td>30</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>0.179251</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936091</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-22 00:00:00-04:00</th>\n",
       "      <td>90.252842</td>\n",
       "      <td>90.392615</td>\n",
       "      <td>87.537270</td>\n",
       "      <td>89.494080</td>\n",
       "      <td>10839400</td>\n",
       "      <td>98</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>0.758763</td>\n",
       "      <td>1.956809</td>\n",
       "      <td>0.139772</td>\n",
       "      <td>2.855344</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-14 00:00:00-04:00</th>\n",
       "      <td>95.989388</td>\n",
       "      <td>96.029417</td>\n",
       "      <td>94.888592</td>\n",
       "      <td>95.839279</td>\n",
       "      <td>3397100</td>\n",
       "      <td>178</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>0.150109</td>\n",
       "      <td>0.950687</td>\n",
       "      <td>0.040029</td>\n",
       "      <td>1.140825</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-14 00:00:00-05:00</th>\n",
       "      <td>85.432068</td>\n",
       "      <td>85.432068</td>\n",
       "      <td>84.150432</td>\n",
       "      <td>85.052086</td>\n",
       "      <td>8400100</td>\n",
       "      <td>283</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>0.379982</td>\n",
       "      <td>0.901654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.281636</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-22 00:00:00-05:00</th>\n",
       "      <td>81.374623</td>\n",
       "      <td>81.496993</td>\n",
       "      <td>79.229964</td>\n",
       "      <td>81.026840</td>\n",
       "      <td>21281600</td>\n",
       "      <td>288</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>0.347783</td>\n",
       "      <td>1.796876</td>\n",
       "      <td>0.122369</td>\n",
       "      <td>2.267028</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2000-02-14 00:00:00-05:00  89.087943  89.087943  88.151852  88.908691   \n",
       "2000-05-22 00:00:00-04:00  90.252842  90.392615  87.537270  89.494080   \n",
       "2000-09-14 00:00:00-04:00  95.989388  96.029417  94.888592  95.839279   \n",
       "2001-02-14 00:00:00-05:00  85.432068  85.432068  84.150432  85.052086   \n",
       "2001-02-22 00:00:00-05:00  81.374623  81.496993  79.229964  81.026840   \n",
       "\n",
       "                             Volume  Row_index   Candle  Body_length  \\\n",
       "Date                                                                   \n",
       "2000-02-14 00:00:00-05:00   8528800         30  Bearish     0.179251   \n",
       "2000-05-22 00:00:00-04:00  10839400         98  Bearish     0.758763   \n",
       "2000-09-14 00:00:00-04:00   3397100        178  Bearish     0.150109   \n",
       "2001-02-14 00:00:00-05:00   8400100        283  Bearish     0.379982   \n",
       "2001-02-22 00:00:00-05:00  21281600        288  Bearish     0.347783   \n",
       "\n",
       "                           Lower_shadow_length  Upper_shadow_length  \\\n",
       "Date                                                                  \n",
       "2000-02-14 00:00:00-05:00             0.756839             0.000000   \n",
       "2000-05-22 00:00:00-04:00             1.956809             0.139772   \n",
       "2000-09-14 00:00:00-04:00             0.950687             0.040029   \n",
       "2001-02-14 00:00:00-05:00             0.901654             0.000000   \n",
       "2001-02-22 00:00:00-05:00             1.796876             0.122369   \n",
       "\n",
       "                           Total_candle_length Hammer_pattern  \n",
       "Date                                                           \n",
       "2000-02-14 00:00:00-05:00             0.936091            Yes  \n",
       "2000-05-22 00:00:00-04:00             2.855344            Yes  \n",
       "2000-09-14 00:00:00-04:00             1.140825            Yes  \n",
       "2001-02-14 00:00:00-05:00             1.281636            Yes  \n",
       "2001-02-22 00:00:00-05:00             2.267028            Yes  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can see that we now have a new column 'Hammer_pattern' -- 'Yes' = hammer pattern is identified\n",
    "finance_df[finance_df['Hammer_pattern'] == \"Yes\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fea86a8-c56a-49ef-a17e-5430d0074c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hammer_pattern\n",
       "No     6248\n",
       "Yes      70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can see how many hammer candlestick patterns are present\n",
    "finance_df['Hammer_pattern'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee88d4-940f-4f6c-ae5f-1d15951c39b6",
   "metadata": {},
   "source": [
    "**2) Identify the Inverted Hammer Pattern**\n",
    "\n",
    "Remember my following definition of the inverted hammer candlestick pattern:\n",
    "\n",
    "_Looking for a candlestick (bullish or bearish) with a small body (less than 30% of the total candlestick length; candlestick length is the distance between low and high) at the bottom, a long upper shadow (at least twice the length of the body), and little to no lower shadow (lower shadow will be less than 10% of the total candle length). This pattern must occur during a downtrend; to confirm a downtrend, I will fit a regression line (line of best fit) through the closing prices for the previous five candles-if the slope is negative or equal to zero, this means that a downtrend is present. It doesn't matter if the single candlestick is a bearish or bullish candle, they both can display the inverted hammer pattern._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b9ba738-c1bd-4c63-a059-26d07f7b9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_hammer = [] #initialize empty list\n",
    "for index, row in finance_df.iterrows():\n",
    "    start_index = row['Row_index'] - 5 #Get the starting index of the fifth previous candle\n",
    "    end_index = row['Row_index'] - 1 #subtacting 1 because only getting previous 5 candlestick closing prices, not current candle's close\n",
    "    \n",
    "    if (start_index < 1): #since we are subtracting to get starting index, it will be a negative number; skip these\n",
    "        inverted_hammer.append(\"No\")\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    temp_df = finance_df[(finance_df['Row_index'] >= start_index) & (finance_df['Row_index'] <= end_index)]\n",
    "    closing_prices = temp_df['Close'].values\n",
    "\n",
    "    #Fit a regression line (line of best fit) through the closing prices; negative slope represents current downtrend\n",
    "    x = np.arange(len(closing_prices))\n",
    "    slope, intercept = np.polyfit(x, closing_prices, 1) \n",
    "\n",
    "    #if slope <= 0, then in a current downtrend the previous 5 days in terms of closing prices\n",
    "    #to clarify, although slope may be zero which means no change, I will still be counting this as a downtrend\n",
    "    if (slope <= 0):\n",
    "        if ((row['Upper_shadow_length']) >= (row['Body_length'] * 2.0)): #upper shadow is at least twice the length of the candle body\n",
    "            if ((row['Lower_shadow_length']) < (row['Total_candle_length'] * 0.10)): #lower shadow is less than 20% of the total candle length\n",
    "                if ((row['Body_length']) < (row['Total_candle_length'] * 0.30)): #body is less than 30% of the total candlestick length\n",
    "                    inverted_hammer.append(\"Yes\")\n",
    "                else:\n",
    "                    inverted_hammer.append(\"No\")\n",
    "            else:\n",
    "                inverted_hammer.append(\"No\")\n",
    "        else:\n",
    "            inverted_hammer.append(\"No\")\n",
    "                \n",
    "    elif (slope > 0):\n",
    "        inverted_hammer.append(\"No\")\n",
    "\n",
    "#Create new column\n",
    "finance_df['InvertedHammer_pattern'] = inverted_hammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18532f39-5498-4a1d-bbe8-625f311bd3c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvertedHammer_pattern\n",
       "No     6266\n",
       "Yes      52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can see how many inverted hammer candlestick patterns are present\n",
    "finance_df['InvertedHammer_pattern'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75491ff-021d-4652-ae9f-247c6ee270c6",
   "metadata": {},
   "source": [
    "**3) Identify the Bullish Engulfing Pattern**\n",
    "\n",
    "Remember my following definition of the bullish engulfing candlestick pattern:\n",
    "\n",
    "_Looking for a small bearish candle followed by a large bullish candle that completely engulfs the range (high and low prices) of the first candle (two-candle pattern). The second candle's body (open and close price) must be larger by at least 2 times the body of the first candle and fully engulf the body of the first candle. This pattern must occur during a downtrend; to confirm a downtrend, I will fit a regression line (line of best fit) through the closing prices for the previous five candles-if the slope is negative or equal to zero, this means that a downtrend is present. Note that the first candle (the bearish candle) in the identified pattern will be treated as the fifth candle in the slope calculation for confirming the downtrend._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "047be669-faf9-4c5b-b08a-7faf68f4d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bullish_engulfing = [] #initialize empty list\n",
    "slope = np.array([])\n",
    "for index, row in finance_df.iterrows():\n",
    "    start_index = row['Row_index'] - 5 #Get the starting index of the fifth previous candle\n",
    "    end_index = row['Row_index'] - 1 #subtacting 1 because only getting previous 5 candlestick closing prices, not current candle's close\n",
    "    \n",
    "    if (start_index < 1): #since we are subtracting to get starting index, it will be a negative number; skip these\n",
    "        bullish_engulfing.append(\"No\")\n",
    "        continue\n",
    "        \n",
    "    #get data for five previous days worth of candlestick data\n",
    "    temp_df = finance_df[(finance_df['Row_index'] >= start_index) & (finance_df['Row_index'] <= end_index)]\n",
    "    closing_prices = temp_df['Close'].values\n",
    "\n",
    "    #check to see if the directly previous candle is a bearish candle, this is a requirement for identifying bullish engulfing pattern\n",
    "    check_df = finance_df[finance_df['Row_index'] == end_index]\n",
    "    if (check_df['Candle'].iloc[0] == 'Bullish'):\n",
    "        bullish_engulfing.append(\"No\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    #Fit a regression line (line of best fit) through the closing prices; negative slope represents current downtrend\n",
    "    x = np.arange(len(closing_prices))\n",
    "    slope, intercept = np.polyfit(x, closing_prices, 1) \n",
    "\n",
    "    #if slope <= 0, then in a current downtrend the previous 5 days in terms of closing prices\n",
    "    #to clarify, although slope may be zero which means no change, I will still be counting this as a downtrend.\n",
    "    #The final candle in the two-candlestick pattern must be bullish\n",
    "    if ((slope <= 0) & (row['Candle'] == 'Bullish')):\n",
    "        \n",
    "        #Looking for a small bearish candle followed by a large bullish candle that completely engulfs the range (high and low prices) of the first candle (two-candle pattern)\n",
    "        if ((row['High'] > check_df['High'].iloc[0]) & (row['Low'] < check_df['Low'].iloc[0])):\n",
    "        \n",
    "            if ((row['Body_length']) >= (check_df['Body_length'].iloc[0] * 2.0)): #the second candle's body must be larger by at least 2 times the body of the previous candle\n",
    "                \n",
    "                #The second candle's body must fully engulf the body of the first candle.\n",
    "                #Specifically, the second candle's close must be larger than the previous candle's open and the second candle's open must be less\n",
    "                #than the second candle's close. This is because the second candle is a bullish candle and the previous candle is a bearish candle.\n",
    "                if ((row['Close'] > check_df['Open'].iloc[0]) & (row['Open'] < check_df['Close'].iloc[0])): \n",
    "                    bullish_engulfing.append(\"Yes\")\n",
    "                else:\n",
    "                    bullish_engulfing.append(\"No\")\n",
    "            else:\n",
    "                    bullish_engulfing.append(\"No\")\n",
    "        else:\n",
    "            bullish_engulfing.append(\"No\")\n",
    "                \n",
    "    else:\n",
    "        bullish_engulfing.append(\"No\")\n",
    "\n",
    "#Create new column\n",
    "finance_df['BullishEngulfing_pattern'] = bullish_engulfing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652064ca-d1c5-438d-829a-47fb933fef0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BullishEngulfing_pattern\n",
       "No     6294\n",
       "Yes      24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can see how many bullish engulfing candlestick patterns are present\n",
    "finance_df['BullishEngulfing_pattern'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d531d5-24e4-42d1-ba54-a8980aaaa074",
   "metadata": {},
   "source": [
    "**4) Identify the Bullish Harami Pattern**\n",
    "\n",
    "Remember my following definition of the bullish harami candlestick pattern:\n",
    "\n",
    "_Looking for a large bearish candle followed by a small bullish candle that is entirely within the range of the first candle; this means that the small bullish candle should be fully contained within the previous candle's high and low. The large bearish candle will be at least twice the entire length of the following bullish candle. The body of the large bearish candle will also completely engulf the body of the small bullish candle. This pattern must occur during a downtrend; to confirm a downtrend, I will fit a regression line (line of best fit) through the closing prices for the previous five candles-if the slope is negative or equal to zero, this means that a downtrend is present. Note that the first candle (the bearish candle) in the identified pattern will be treated as the fifth candle in the slope calculation for confirming the downtrend._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4f428b9-4a1e-4c67-8b77-d53af14149d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bullish_harami = [] #initialize empty list\n",
    "slope = np.array([])\n",
    "for index, row in finance_df.iterrows():\n",
    "    start_index = row['Row_index'] - 5 #Get the starting index of the fifth previous candle\n",
    "    end_index = row['Row_index'] - 1 #subtacting 1 because only getting previous 5 candlestick closing prices, not current candle's close\n",
    "    \n",
    "    if (start_index < 1): #since we are subtracting to get starting index, it will be a negative number; skip these\n",
    "        bullish_harami.append(\"No\")\n",
    "        continue\n",
    "        \n",
    "    #get data for five previous days worth of candlestick data\n",
    "    temp_df = finance_df[(finance_df['Row_index'] >= start_index) & (finance_df['Row_index'] <= end_index)]\n",
    "    closing_prices = temp_df['Close'].values\n",
    "\n",
    "    #check to see if the directly previous candle is a bearish candle, this is a requirement for identifying bullish harami pattern\n",
    "    check_df = finance_df[finance_df['Row_index'] == end_index]\n",
    "    if (check_df['Candle'].iloc[0] == 'Bullish'):\n",
    "        bullish_harami.append(\"No\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    #Fit a regression line (line of best fit) through the closing prices; negative slope represents current downtrend\n",
    "    x = np.arange(len(closing_prices))\n",
    "    slope, intercept = np.polyfit(x, closing_prices, 1) \n",
    "\n",
    "    #if slope <= 0, then in a current downtrend the previous 5 days in terms of closing prices\n",
    "    #to clarify, although slope may be zero which means no change, I will still be counting this as a downtrend.\n",
    "    #The final candle in the two-candlestick pattern must be bullish.\n",
    "    if ((slope <= 0) & (row['Candle'] == 'Bullish')):\n",
    "        if ((check_df['Total_candle_length'].iloc[0]) >= (row['Total_candle_length'] * 2.0)): #the bearish candle will be at least twice the length of the bullish candle\n",
    "            \n",
    "            #The second candle must be fully contained within the previous candle's high and low.\n",
    "            if ((row['High'] < check_df['High'].iloc[0]) & (row['Low'] > check_df['Low'].iloc[0])): \n",
    "\n",
    "                #The second candle's body must also be fully contained within the previous candle's body (close and open).\n",
    "                if ((row['Open'] > check_df['Close'].iloc[0]) & (row['Close'] < check_df['Open'].iloc[0])): \n",
    "                    bullish_harami.append(\"Yes\")\n",
    "                else:\n",
    "                    bullish_harami.append(\"No\")\n",
    "            \n",
    "            else:\n",
    "                bullish_harami.append(\"No\")\n",
    "        else:\n",
    "                bullish_harami.append(\"No\")\n",
    "                \n",
    "    else:\n",
    "        bullish_harami.append(\"No\")\n",
    "\n",
    "#Create new column\n",
    "finance_df['BullishHarami_pattern'] = bullish_harami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea892c9-7b42-45ab-b524-a64a8b81c381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BullishHarami_pattern\n",
       "No     6288\n",
       "Yes      30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can see how many bullish harami candlestick patterns are present\n",
    "finance_df['BullishHarami_pattern'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a9715b-e17c-45bc-ae24-08612c1ea4e5",
   "metadata": {},
   "source": [
    "**5) Identify the Three White Soldiers Pattern**\n",
    "\n",
    "Remember my following definition of the three white soliders candlestick pattern:\n",
    "\n",
    "_Looking for three consecutive bullish candles with each one closing higher than the previous candle. The candles should show a steady upward movement without large wicks. The upper and lower wicks should each be no more than 20% of the total candle length. Unlike the other patterns, this pattern does not need to occur during a downtrend. The visual below is a representation of how I am going to identify the three white soliders pattern as highlighted with blue dots._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4de8e6ed-fc51-46aa-8156-c32dcc11d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_white_soldiers = [] #initialize empty list\n",
    "slope = np.array([])\n",
    "for index, row in finance_df.iterrows():\n",
    "    start_index = row['Row_index'] - 2 #Get the starting index of the second previous candle\n",
    "    end_index = row['Row_index'] - 1 #subtacting 1 because only getting previous 2 candlestick closing prices, not current candle's close\n",
    "    \n",
    "    if (start_index < 1): #since we are subtracting to get starting index, it will be a negative number; skip these\n",
    "        three_white_soldiers.append(\"No\")\n",
    "        continue\n",
    "        \n",
    "    #get data for five previous days worth of candlestick data. Check to see if previous two candles are bullish; since need three total bullish candles\n",
    "    #for this pattern.\n",
    "    check_df = finance_df[(finance_df['Row_index'] >= start_index) & (finance_df['Row_index'] <= end_index)]\n",
    "    if ((check_df['Candle'].iloc[0] == 'Bearish') or (check_df['Candle'].iloc[1] == 'Bearish')):\n",
    "        three_white_soldiers.append(\"No\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    #The final candle in the three-candlestick pattern must be bullish.\n",
    "    if (row['Candle'] == 'Bullish'):\n",
    "\n",
    "        #the first candle in the pattern should have upper and lower wicks no more than 20% of the total candle length\n",
    "        if (((check_df['Lower_shadow_length'].iloc[0]) <= (check_df['Total_candle_length'].iloc[0] * 0.20)) & ((check_df['Upper_shadow_length'].iloc[0]) <= (check_df['Total_candle_length'].iloc[0] * 0.20))):\n",
    "\n",
    "            #the second candle in the pattern should have upper and lower wicks no more than 20% of the total candle length\n",
    "            if (((check_df['Lower_shadow_length'].iloc[1]) <= (check_df['Total_candle_length'].iloc[1] * 0.20)) & ((check_df['Upper_shadow_length'].iloc[1]) <= (check_df['Total_candle_length'].iloc[1] * 0.20))): \n",
    "                \n",
    "                #The three candles should have increasing closing prices\n",
    "                if ((row['Close'] > (check_df['Close'].iloc[1])) & ((check_df['Close'].iloc[1]) > (check_df['Close'].iloc[0]))): \n",
    "                    three_white_soldiers.append(\"Yes\")\n",
    "                else:\n",
    "                    three_white_soldiers.append(\"No\")\n",
    "            else:\n",
    "                three_white_soldiers.append(\"No\")\n",
    "        else:\n",
    "            three_white_soldiers.append(\"No\")\n",
    "                \n",
    "    else:\n",
    "        three_white_soldiers.append(\"No\")\n",
    "\n",
    "#Create new column\n",
    "finance_df['ThreeWhiteSoldiers_pattern'] = three_white_soldiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b3ff14-6e3f-42d5-b27f-e2a37d957405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeWhiteSoldiers_pattern\n",
       "No     6284\n",
       "Yes      34\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can see how many three white soldier candlestick patterns are present\n",
    "finance_df['ThreeWhiteSoldiers_pattern'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a7eca-5e4b-4f96-b15e-5e0440cbec4e",
   "metadata": {},
   "source": [
    "### Variable Cleaning\n",
    "\n",
    "**6) Perform Further Cleaning on Variables**\n",
    "\n",
    "I will also perform further cleaning below to calculate the following values needed to train my model:\n",
    "\n",
    "* MACD and Signal Line\n",
    "* RSI\n",
    "* MFI\n",
    "* Normalize stock prices two different ways: Log transform & Sklearn's scaler function\n",
    "* Creating the 'random' column in the dataset with randomly assigned \"Yes\" and \"No\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52c9a8d7-6205-48be-b7e1-1d4fe49baaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #Used to normalize data\n",
    "\n",
    "###Calculate MACD and Signal Line\n",
    "# Calculate the 12-day EMA\n",
    "finance_df['EMA12'] = finance_df['Close'].ewm(span=12, adjust=False).mean()\n",
    "\n",
    "# Calculate the 26-day EMA\n",
    "finance_df['EMA26'] = finance_df['Close'].ewm(span=26, adjust=False).mean()\n",
    "\n",
    "# Calculate the MACD (12-day EMA - 26-day EMA)\n",
    "finance_df['MACD'] = finance_df['EMA12'] - finance_df['EMA26']\n",
    "\n",
    "# Calculate the Signal Line (9-day EMA of MACD)\n",
    "finance_df['Signal_Line'] = finance_df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "\n",
    "\n",
    "###RSI\n",
    "# Calculate the daily price changes\n",
    "finance_df['Price_Change'] = finance_df['Close'].diff()\n",
    "\n",
    "# Separate gains and losses\n",
    "finance_df['Gain'] = finance_df['Price_Change'].apply(lambda x: x if x > 0 else 0)\n",
    "finance_df['Loss'] = finance_df['Price_Change'].apply(lambda x: -x if x < 0 else 0)\n",
    "\n",
    "# Calculate the average gain and loss over a 14-day period\n",
    "period = 14\n",
    "finance_df['Avg_Gain'] = finance_df['Gain'].rolling(window=period, min_periods=1).mean()\n",
    "finance_df['Avg_Loss'] = finance_df['Loss'].rolling(window=period, min_periods=1).mean()\n",
    "\n",
    "# Calculate the relative strength (RS)\n",
    "finance_df['RS'] = finance_df['Avg_Gain'] / finance_df['Avg_Loss']\n",
    "\n",
    "# Calculate the RSI\n",
    "finance_df['RSI'] = 100 - (100 / (1 + finance_df['RS']))\n",
    "\n",
    "\n",
    "####Used to calculate MFI\n",
    "# Step 1: Calculate the Typical Price (TP)\n",
    "finance_df['TP'] = (finance_df['High'] + finance_df['Low'] + finance_df['Close']) / 3\n",
    "\n",
    "# Step 2: Calculate the Money Flow (MF)\n",
    "finance_df['MF'] = finance_df['TP'] * finance_df['Volume']\n",
    "\n",
    "# Step 3: Calculate Positive and Negative Money Flow\n",
    "finance_df['Positive_MF'] = finance_df['MF'].where(finance_df['TP'] > finance_df['TP'].shift(1), 0)\n",
    "finance_df['Negative_MF'] = finance_df['MF'].where(finance_df['TP'] < finance_df['TP'].shift(1), 0)\n",
    "\n",
    "# Step 4: Calculate the rolling sum of Positive and Negative Money Flow over the specified period (e.g., 14 periods)\n",
    "window = 14\n",
    "finance_df['Positive_MF_sum'] = finance_df['Positive_MF'].rolling(window=window).sum()\n",
    "finance_df['Negative_MF_sum'] = finance_df['Negative_MF'].rolling(window=window).sum()\n",
    "\n",
    "# Step 5: Calculate the Money Flow Ratio\n",
    "finance_df['Money_Flow_Ratio'] = finance_df['Positive_MF_sum'] / finance_df['Negative_MF_sum']\n",
    "\n",
    "# Step 6: Calculate the Money Flow Index (MFI)\n",
    "finance_df['MFI'] = 100 - (100 / (1 + finance_df['Money_Flow_Ratio']))\n",
    "\n",
    "\n",
    "###Normalize stock price variables\n",
    "#normalize via log transform\n",
    "finance_df['Log_Close'] = np.log(finance_df['Close'])\n",
    "finance_df['Log_Open'] = np.log(finance_df['Open'])\n",
    "finance_df['Log_High'] = np.log(finance_df['High'])\n",
    "finance_df['Log_Low'] = np.log(finance_df['Low'])\n",
    "\n",
    "#normalize via Sklearn's scaler function\n",
    "scaler_close = MinMaxScaler()\n",
    "scaler_open = MinMaxScaler()\n",
    "scaler_high = MinMaxScaler()\n",
    "scaler_low = MinMaxScaler()\n",
    "finance_df['Normalized_Close'] = scaler_close.fit_transform(finance_df[['Close']])\n",
    "finance_df['Normalized_Open'] = scaler_open.fit_transform(finance_df[['Open']])\n",
    "finance_df['Normalized_High'] = scaler_high.fit_transform(finance_df[['High']])\n",
    "finance_df['Normalized_Low'] = scaler_low.fit_transform(finance_df[['Low']])\n",
    "\n",
    "\n",
    "####Used to create a new column to test random values of 'yes' to simulate presence of a random pattern\n",
    "# Specify the number of \"Yes\" values you want, may show up as less during training due to location of the \"Yes\" value, as need at least 30 days\n",
    "#of data for the 30-day sequence, or if the future closing price is not available (only have data to 2/14)\n",
    "num_yes = 200\n",
    "\n",
    "# Create a list of \"Yes\" and \"No\" values\n",
    "yes_no_list = [\"Yes\"] * num_yes + [\"No\"] * (len(finance_df) - num_yes)\n",
    "\n",
    "#set seed for reproducibility\n",
    "np.random.seed(6) \n",
    "\n",
    "# Shuffle the list to randomize the order\n",
    "np.random.shuffle(yes_no_list)\n",
    "\n",
    "# Add the list as a new column in the DataFrame\n",
    "finance_df['Random_Yes_No'] = yes_no_list\n",
    "\n",
    "#exclude the first 26 rows because calculations from MACD needs at least 26 days to calculate\n",
    "finance_df = finance_df.iloc[26:].reset_index(drop=True)\n",
    "\n",
    "#write out CSV of cleaned dataset\n",
    "finance_df.to_csv(f'{ticker_symbol}_financials_cleaned_output.csv', index=False)  # `index=False` avoids writing the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923edfe2-3271-45ab-a6ef-0688ae9a67ca",
   "metadata": {},
   "source": [
    "#### Advantages and Disadvantages During Data Collection Phase\n",
    "\n",
    "An advantage of collecting the data is that there is built in stock packages to collect stock market data. I used the 'yfinance' package to easily get stock price data for the ticker 'SPY'. A disadvantage would be that after collecting the data for the candle stick patterns, I realized that they occur very rarely. For that reason I have decided to not implement the bullish harami, bullish engulfing, and three white soldiers patterns as they are the most rarely occurring patterns and I want to make sure I have enough data to train a reliable model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463efaa8-fb83-4b1d-af68-a59f53949bcc",
   "metadata": {},
   "source": [
    "## Data Modeling / Machine Learning - _D_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5823806-8c4c-49fe-baf8-44b76d8b91e7",
   "metadata": {},
   "source": [
    "#### LSTM Classification Model\n",
    "\n",
    "Prior to running my machine learning model, the code below is designed to analyze a financial dataset (finance_df) by identifying a specific trading pattern, such as the \"Hammer pattern,\" and subsequently predicting whether the stock's price will increase based on the pattern's occurrence. The code first filters the dataset to only include rows where the 'Hammer_pattern' is marked as \"Yes.\" The pattern_df dataframe contains these filtered rows, and the code then iterates through these rows to collect a sequence of independent variables that can be used for prediction. These independent variables include various stock metrics like open, close, high, low prices, as well as technical indicators such as RSI (Relative Strength Index), MFI (Money Flow Index), and MACD (Moving Average Convergence Divergence). The code ensures that for each identified pattern, a series of previous days' data (up to 30 days) is gathered to build these feature sets, which are stored in separate lists. Additionally, a dependent variable is created to capture whether the stock price increases by a specified percentage (e.g., 1% or more) in the days following the identified pattern.\n",
    "\n",
    "The code also handles the logic of determining whether the stock's price has increased by the desired percentage after the pattern appears. For each identified pattern, the code checks if the stock price on the following day (determined by 'days_out') exceeds the original price by the specified percentage. If the price increase criterion is met, the dependent variable is set to 1 (indicating a positive class), and if it isn't, it is set to 0 (indicating a negative class). The independent variables, which include multiple arrays of stock data for each identified pattern, are stored in corresponding lists and then converted into NumPy arrays for further processing or machine learning tasks. This approach prepares the data for machine learning models to predict future stock price movements based on the identified pattern and accompanying technical indicators.\n",
    "\n",
    "**Note!!!**: I have chosen not to implement machine learning models to predict the future prices for three candlestick patterns. The reason is because of the small sample size of data. These are the Bullish Engulfing, Bullish Harami, and Three White Soldiers pattern.\n",
    "\n",
    "To summarize or expound on what I have just said, the code directly below will allow us to:\n",
    "\n",
    "1. Select the candlestick pattern (\"Random\", \"Hammer\", \"Inverted Hammer\"): The random pattern is a column in the dataset with randomly assigned \"Yes\" and \"No\" values. These \"Yes\" and \"No\" values are distributed randomly, and my goal is to compare the model's performance using these random patterns labeled \"Yes\" versus patterns that are specifically identified as candlestick patterns. This will help me understand if the model behaves differently when dealing with randomly assigned patterns versus known candlestick patterns.\n",
    "<br>\n",
    "2. Generate our independent variables that can be used for prediction. There will be 15 different sets of independent variables. Each one of them has a different shape and includes a different subset of independent variables. This allows us to compare the performance of independent variables so that we can evaluate the best performing combination of independent variables.\n",
    "<br>\n",
    "3. Generate our dependent variable. Our value of the dependent variable is dependent on the following two model parameters that is specified by me:\n",
    "    + My research question states that I will predict a stock's closing price sometime after the candlestick pattern concludes. I will try different values for this such as one days afterwards, three days, five, ten, and fifteen.\n",
    "    + Another parameter for defining the dependent variable is the percentage increase required to classify a future stock closing price as a positive class. For example, if the parameter is set to '1.0', the future closing price only needs to be greater than the last closing price identified within the 30-day sequence. However, if set to '1.1', the future closing price must exceed the last closing price in the sequence by 1%, i.e., the last closing price multiplied by 1.01.\n",
    "\n",
    "\n",
    "The result of the code will be a numpy array with values of from all of our cleaned variables. This array incorporates the idea that one observation (one sequence) is 30 days of stock data. Each of these 30 time-steps (remember, one time-step = one day), will represent daily data of my eight chosen independent variables. The dependent variable in my array will be future closing stock price.\n",
    "\n",
    "Depending on my selected candlestick pattern, I may have more observations as some candlestick patterns occur more often than others. Here is an example on how my independent and dependent variables will look like:\n",
    "\n",
    "-Shape: (30, 8)<br>\n",
    "_independent_observation = np.array([ <br>\n",
    "    [0.054, 0.062, 0.054, 0.059, 45.3, 1000000, 0.0012, 0.0010],  # Day 1 <br>\n",
    "    [0.059, 0.063, 0.059, 0.062, 46.1, 1010000, 0.0013, 0.0011],  # Day 2 <br>\n",
    "    [0.061, 0.064, 0.060, 0.063, 47.2, 1025000, 0.0014, 0.0012],  # Day 3 <br>\n",
    "    # ... 27 more rows ... <br>\n",
    "    [0.070, 0.074, 0.071, 0.073, 55.0, 1200000, 0.0020, 0.0018]   # Day 30 <br>\n",
    "])_\n",
    "\n",
    "-Binary label: 1 if the future closing price is higher, 0 otherwise <br>\n",
    "_dependent_classification = np.array([1])_\n",
    "\n",
    "-Future day's closing price (e.g., 0.075) <br>\n",
    "_dependent_regression = np.array([0.075])_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2fabf69e-7422-4478-9bdd-31244647edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset data frame for desired pattern\n",
    "pattern_df = finance_df[finance_df['Hammer_pattern'] == \"Yes\"]\n",
    "#pattern_df = finance_df[finance_df['Random_Yes_No'] == \"Yes\"]\n",
    "\n",
    "#How many days after the pattern is identified to use for the dependent variable\n",
    "days_out = 1\n",
    "\n",
    "#What percent increase from the current price is considered a positive class. For example 1.01 = 1% increase; 100 * 1.01 = 101. So if original\n",
    "#price is $100, anything greater than $101 is considered a positive class.\n",
    "pct_increase = 1.00\n",
    "\n",
    "#Gather independent variables\n",
    "independent_list1 = []\n",
    "independent_list2 = []\n",
    "independent_list3 = []\n",
    "independent_list4 = []\n",
    "independent_list5 = []\n",
    "independent_list6 = []\n",
    "independent_list7 = []\n",
    "independent_list8 = []\n",
    "independent_list9 = []\n",
    "independent_list10 = []\n",
    "independent_list11 = []\n",
    "independent_list12 = []\n",
    "independent_list13 = []\n",
    "independent_list14 = []\n",
    "independent_list15 = []\n",
    "\n",
    "#gather dependent variables\n",
    "dependent_list = []\n",
    "\n",
    "pattern_index = list(pattern_df[\"Row_index\"])\n",
    "#pattern_index = [60, 62]\n",
    "for i in pattern_index:\n",
    "    #if (i == 62):\n",
    "    #    break\n",
    "    \n",
    "    #unable to get 30 days worth of data if index is less than 56, because previously removed first 26 observations\n",
    "    if (i < 56):\n",
    "        continue\n",
    "\n",
    "    #get 30 days worth of data to gather data for indpendent variables\n",
    "    subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 29)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "    #subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 13)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "    \n",
    "    #Get day after data to gather closing price for dependent variable\n",
    "    dependent_df = finance_df[finance_df[\"Row_index\"] == (i)]\n",
    "    dependent2_df = finance_df[finance_df[\"Row_index\"] == (i + days_out)]\n",
    "    \n",
    "    temp_list1 = []\n",
    "    temp_list2 = []\n",
    "    temp_list3 = []\n",
    "    temp_list4 = []\n",
    "    temp_list5 = []\n",
    "    temp_list6 = []\n",
    "    temp_list7 = []\n",
    "    temp_list8 = []\n",
    "    temp_list9 = []\n",
    "    temp_list10 = []\n",
    "    temp_list11 = []\n",
    "    temp_list12 = []\n",
    "    temp_list13 = []\n",
    "    temp_list14 = []\n",
    "    temp_list15 = []\n",
    "\n",
    "    #append temp_list to independent_list\n",
    "    if len(dependent2_df) > 0: #dependent2_df may have length of zero as it is a future date, data may not be available\n",
    "    \n",
    "\n",
    "        for index, row in subset_df.iterrows():\n",
    "                \n",
    "                test_array1 = np.array([row['Open'], row['Close'], row['High'], row['Low']])\n",
    "                test_array2 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low']])\n",
    "                test_array3 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low']])\n",
    "        \n",
    "                test_array4 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI']])\n",
    "                test_array5 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI']])\n",
    "                test_array6 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI']])\n",
    "        \n",
    "                test_array7 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MFI']])\n",
    "                test_array8 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MFI']])\n",
    "                test_array9 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MFI']])\n",
    "        \n",
    "                test_array10 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MACD'], row['Signal_Line']])\n",
    "                test_array11 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MACD'], row['Signal_Line']])\n",
    "                test_array12 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MACD'], row['Signal_Line']])\n",
    "        \n",
    "                test_array13 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                test_array14 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                test_array15 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "        \n",
    "                \n",
    "                temp_list1.append(test_array1)\n",
    "                temp_list2.append(test_array2)\n",
    "                temp_list3.append(test_array3)\n",
    "                temp_list4.append(test_array4)\n",
    "                temp_list5.append(test_array5)\n",
    "                temp_list6.append(test_array6)\n",
    "                temp_list7.append(test_array7)\n",
    "                temp_list8.append(test_array8)\n",
    "                temp_list9.append(test_array9)\n",
    "                temp_list10.append(test_array10)\n",
    "                temp_list11.append(test_array11)\n",
    "                temp_list12.append(test_array12)\n",
    "                temp_list13.append(test_array13)\n",
    "                temp_list14.append(test_array14)\n",
    "                temp_list15.append(test_array15)\n",
    "                \n",
    "        independent_list1.append(temp_list1)\n",
    "        independent_list2.append(temp_list2)\n",
    "        independent_list3.append(temp_list3)\n",
    "        independent_list4.append(temp_list4)\n",
    "        independent_list5.append(temp_list5)\n",
    "        independent_list6.append(temp_list6)\n",
    "        independent_list7.append(temp_list7)\n",
    "        independent_list8.append(temp_list8)\n",
    "        independent_list9.append(temp_list9)\n",
    "        independent_list10.append(temp_list10)\n",
    "        independent_list11.append(temp_list11)\n",
    "        independent_list12.append(temp_list12)\n",
    "        independent_list13.append(temp_list13)\n",
    "        independent_list14.append(temp_list14)\n",
    "        independent_list15.append(temp_list15)\n",
    "    \n",
    "        if (dependent2_df['Close'].iloc[0] > dependent_df['Close'].iloc[0] * pct_increase):\n",
    "            dependent_list.append(1)\n",
    "        else:\n",
    "            dependent_list.append(0)\n",
    "\n",
    "\n",
    "independent_array1 = np.array(independent_list1)\n",
    "independent_array2 = np.array(independent_list2)\n",
    "independent_array3 = np.array(independent_list3)\n",
    "independent_array4 = np.array(independent_list4)\n",
    "independent_array5 = np.array(independent_list5)\n",
    "independent_array6 = np.array(independent_list6)\n",
    "independent_array7 = np.array(independent_list7)\n",
    "independent_array8= np.array(independent_list8)\n",
    "independent_array9 = np.array(independent_list9)\n",
    "independent_array10 = np.array(independent_list10)\n",
    "independent_array11 = np.array(independent_list11)\n",
    "independent_array12 = np.array(independent_list12)\n",
    "independent_array13 = np.array(independent_list13)\n",
    "independent_array14 = np.array(independent_list14)\n",
    "independent_array15 = np.array(independent_list15)\n",
    "dependent_array = np.array(dependent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6ad04cfe-33f2-443d-85a5-b52ac112f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 30, 4)\n",
      "(69, 30, 5)\n",
      "(69, 30, 6)\n",
      "(69, 30, 8)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(independent_array1)) # 30 time-steps and 4 features per time-step\n",
    "print(np.shape(independent_array4)) # 30 time-steps and 5 features per time-step\n",
    "print(np.shape(independent_array10)) # 30 time-steps and 6 features per time-step\n",
    "print(np.shape(independent_array15)) # 30 time-steps and 8 features per time-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "de192799-9a6b-4d91-ae33-a1b8f127368b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([37, 32]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of observations of each class\n",
    "np.unique(dependent_array, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff446ed-2fa0-4989-8319-9ee0dde40a26",
   "metadata": {},
   "source": [
    "This is my LSTM classification model as shown below.\n",
    "\n",
    "This model is designed for binary classification tasks, where the goal is to predict one of two possible outcomes (\"Yes\" or \"No\"). It uses an LSTM (Long Short-Term Memory) network, which is a type of Recurrent Neural Network (RNN) that works well with sequential data, like time series in my case. The model begins with an LSTM layer of 128 units, using the \"tanh\" activation function to capture patterns in the sequential input data. The return_sequences=True means this layer outputs sequences, which are passed on to the next LSTM layer. A dropout layer is added to reduce overfitting by randomly \"dropping\" some of the units during training.\n",
    "\n",
    "The second LSTM layer, with 64 units, processes the sequence further, but without returning sequences (return_sequences=False). This makes the output a single vector, which is then passed through another dropout layer. The model ends with a dense output layer, which has one unit with a sigmoid activation function, giving a probability between 0 and 1 for binary classification. The model is compiled using the Adam optimizer, a commonly used optimization algorithm, with binary cross-entropy as the loss function, as this is suitable for binary classification problems. The performance of the model is evaluated using accuracy as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d76c0e0b-6c7b-44e8-a261-bc9358caf8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy: 57.14%; Average accuray: 0.48571428954601287\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Define the LSTM classification model\n",
    "def create_lstm_classification(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(128, activation='tanh', return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
    "    \n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))  # Final LSTM layer\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense output layer for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification (probability)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Binary cross-entropy for classification\n",
    "    \n",
    "    return model\n",
    "\n",
    "#independent_array(s) and dependent_array are already defined\n",
    "#independent variables (features)\n",
    "X = independent_array1  # Shape: (890, 30, [4, 5, 6, or 8])\n",
    "\n",
    "#dependent variable (target)\n",
    "y = dependent_array  # Shape: (890,) (binary labels, 0 or 1)\n",
    "\n",
    "#split data into training and testing sets (80% training, 20% testing), random state for reproducible results\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6)\n",
    "\n",
    "#define the input shape based on your data; for example independent array_1 has input_shape of (30, 4); independent array_15's shape is (30,8)\n",
    "input_shape = (30, X.shape[2])  # 30 time-steps and 8 features per time-step for independent_array_15\n",
    "\n",
    "#create the LSTM model\n",
    "classification_model = create_lstm_classification(input_shape)\n",
    "\n",
    "#train the classification model and store history. verbose = 0 -> hides the training output\n",
    "history = classification_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose = 0)\n",
    "\n",
    "#get the validation accuracy from history object\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "#find the highest validation accuracy achieved during training\n",
    "best_val_accuracy = max(val_accuracy)\n",
    "avg_val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "# Evaluate the model on the test data, returning best validation accuracy and average validation accuracy throughout all epochs\n",
    "print(f\"Max Accuracy: {best_val_accuracy * 100:.2f}%; Average accuray: {avg_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627637b-1d38-46c8-bbee-3894d3b7807e",
   "metadata": {},
   "source": [
    "The model above was ran using data from independent_array #1, which had the shape of (69, 30, 4) or in other words 69 observations, 30 time-steps and 4 features per time-step. Independent array #1 as shown in the code only includes non-normalized stock price variables (open, low, close, high).\n",
    "\n",
    "The model was also run using 30-day sequences, with each sequence concluding on the 30th day featuring a hammer candlestick pattern on that 30th day. Lastly, I selected the two parameter combinations for the dependent variable: that the future closing price was one day in the future, the day directly after the 30 day sequence. The second parameter was that the dependent variable was labeled as a positive class if it's future closing price was higher than it was previously than the closingn price of the last candle in the 30 day sequence. \n",
    "\n",
    "We can see that the best accuracy score achieved by the model was 57.14% after 10 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80c49b-8b06-49f6-bada-bdbcb685ff06",
   "metadata": {},
   "source": [
    "#### Exploring Model Performance with Parameter Variations and Stratified K-Fold Cross Validation - LSTM Classification Model\n",
    "\n",
    "Now, using the same LSTM model as defined in the previous step I will try various combinations of parameters and variables for my model. \n",
    "\n",
    "For the parameter combinations, I will evaluate my model using three patterns: random days, the hammer pattern, and the inverted hammer pattern. I’ve chosen not to evaluate the other patterns due to insufficient observations in the dataset. When I refer to evaluating my model on random days, I mean that I previously created a column in the dataset with randomly assigned \"Yes\" values. These \"Yes\" values are distributed randomly, and my goal is to compare the model's performance using these random patterns versus patterns that are specifically identified as candlestick patterns. This will help me understand if the model behaves differently when dealing with randomly assigned patterns versus known candlestick patterns.\n",
    "\n",
    "Other parameters I will test will be how many days out after the pattern is identified to use for the dependent variable. For example, if this is set to the value of \"1\", the closing price for the day directly after the candlestick pattern will be what influences the dependent variable. Another example, is if this parameter is \"10\", then the future closing price is associated with 10 days after the last candle of the candle stick pattern.\n",
    "\n",
    "To build off from the previous paragraph, my last parameter will be what percent increase from the original price is considered a positive class. For example 1.01 = 1% increase; 100 * 1.01 = 101. So if the original price is 100 dollars, anything greater than 101 dollars is considered a positive class. In my analysis I have set these values to [1.0, 1.01, and 1.02]. Note, if the value is set to '1.0' then if the original price is 100 dollars, anything greater than 100 dollars is considered a positive class.\n",
    "\n",
    "I will also use statified K-fold Cross validation. Stratified K-Fold Cross Validation is often preferred over regular K-Fold because it ensures that each fold of the data has a similar distribution of the target classes. This is particularly important when dealing with imbalanced datasets where some classes may be underrepresented. In regular K-Fold cross-validation, the data is randomly split, which could result in some folds having disproportionately many samples from one class and too few from another. This can lead to biased model performance estimates, as the model might not be exposed to enough of the minority class to learn effectively.\n",
    "\n",
    "In contrast, Stratified K-Fold ensures that each fold contains roughly the same proportion of each class as in the original dataset. This helps the model train and validate on a more balanced representation of the target variable, leading to more reliable and generalizable performance metrics. Stratified K-Fold is particularly beneficial for classification tasks where the goal is to maintain fairness in model evaluation, and it can help prevent skewed results caused by class imbalances.\n",
    "\n",
    "In my case, when splitting my dataset, I want to make sure I have the same ratio of positive and negative classes in each fold as in the original dataset. This will ensure that my model is consistently evaluated on balanced data and help improve its ability to predict both classes effectively.\n",
    "\n",
    "The result of running the code below will output a CSV file which shows the accuracy scores of each parameter and variable combination. I am going to have to run this code below multiple times, each time changing the stock ticker (if I choose to analyze another stock, but I won't in this project; I will only evaluate the stock ticker \"SPY\" to save resources.) I want to evaluate and the selected pattern (the code below can only run one selected pattern and one stock ticker at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fc13439a-d1d6-4f1d-b076-a041c964c703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_27512\\1563598923.py:311: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  accuracy_df = pd.concat([accuracy_df, df_new], ignore_index=True)\n",
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 1\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 2\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 3\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 4\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "### User inputs ###\n",
    "selected_pattern = \"InvertedHammer\"   #choices: 'Random', 'Hammer', 'InvertedHammer'\n",
    "\n",
    "#How many days after the pattern is identified to use for the dependent variable\n",
    "days_out = [1, 3, 5, 10, 15]\n",
    "\n",
    "#What percent increase from the current price is considered a positive class. For example 1.01 = 1% increase; 100 * 1.01 = 101. So if original\n",
    "#price is $100, anything greater than $101 is considered a positive class.\n",
    "pct_increase = [1.00, 1.01, 1.02]\n",
    "\n",
    "######\n",
    "\n",
    "\n",
    "# Define the classification model\n",
    "def create_lstm_classification(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(128, activation='tanh', return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
    "    \n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))  # Final LSTM layer\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense output layer for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification (probability)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Binary cross-entropy for classification\n",
    "    return model\n",
    "\n",
    "    \n",
    "\n",
    "#Subset data frame for desired pattern\n",
    "if (selected_pattern == \"Random\"):\n",
    "    pattern_df = finance_df[finance_df['Random_Yes_No'] == \"Yes\"]\n",
    "elif (selected_pattern == \"Hammer\"):\n",
    "    pattern_df = finance_df[finance_df['Hammer_pattern'] == \"Yes\"]\n",
    "else:\n",
    "    pattern_df = finance_df[finance_df['InvertedHammer_pattern'] == \"Yes\"]\n",
    "\n",
    "\n",
    "#initialize an empty DataFrame with column names\n",
    "accuracy_df = pd.DataFrame(columns=['ticker', 'pattern', 'independent_array', 'best_accuracy', 'avg_accuracy', 'days_out', 'Total_observations', \n",
    "                                   'Negative_observations', 'Positive_observations', 'Percent_increase_parameter'])\n",
    "\n",
    "\n",
    "for percent in pct_increase:\n",
    "\n",
    "    for day in days_out:\n",
    "        #Gather independent variables\n",
    "        independent_list1 = []\n",
    "        independent_list2 = []\n",
    "        independent_list3 = []\n",
    "        independent_list4 = []\n",
    "        independent_list5 = []\n",
    "        independent_list6 = []\n",
    "        independent_list7 = []\n",
    "        independent_list8 = []\n",
    "        independent_list9 = []\n",
    "        independent_list10 = []\n",
    "        independent_list11 = []\n",
    "        independent_list12 = []\n",
    "        independent_list13 = []\n",
    "        independent_list14 = []\n",
    "        independent_list15 = []\n",
    "        \n",
    "        #gather dependent variables\n",
    "        dependent_list = []\n",
    "\n",
    "        #these are the row indexes that have the identified patterns; loop through\n",
    "        pattern_index = list(pattern_df[\"Row_index\"])\n",
    "        for i in pattern_index:\n",
    "            #if (i == 62):\n",
    "            #    break\n",
    "            \n",
    "            #unable to get 30 days worth of data if index is less than 56, because previously removed first 26 observations\n",
    "            if (i < 56):\n",
    "                continue\n",
    "        \n",
    "            #get 30 days worth of data to gather data for indpendent variables\n",
    "            subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 29)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "            #subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 13)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "            \n",
    "            #Get day after data to gather closing price for dependent variable\n",
    "            dependent_df = finance_df[finance_df[\"Row_index\"] == (i)]\n",
    "            dependent2_df = finance_df[finance_df[\"Row_index\"] == (i + day)]\n",
    "            \n",
    "            temp_list1 = []\n",
    "            temp_list2 = []\n",
    "            temp_list3 = []\n",
    "            temp_list4 = []\n",
    "            temp_list5 = []\n",
    "            temp_list6 = []\n",
    "            temp_list7 = []\n",
    "            temp_list8 = []\n",
    "            temp_list9 = []\n",
    "            temp_list10 = []\n",
    "            temp_list11 = []\n",
    "            temp_list12 = []\n",
    "            temp_list13 = []\n",
    "            temp_list14 = []\n",
    "            temp_list15 = []\n",
    "        \n",
    "            #append temp_list to independent_list\n",
    "            if len(dependent2_df) > 0: #dependent2_df may have length of zero as it is a future date, data may not be available\n",
    "            \n",
    "        \n",
    "                for index, row in subset_df.iterrows():\n",
    "                        \n",
    "                        test_array1 = np.array([row['Open'], row['Close'], row['High'], row['Low']])\n",
    "                        test_array2 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low']])\n",
    "                        test_array3 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low']])\n",
    "                \n",
    "                        test_array4 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI']])\n",
    "                        test_array5 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI']])\n",
    "                        test_array6 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI']])\n",
    "                \n",
    "                        test_array7 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MFI']])\n",
    "                        test_array8 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MFI']])\n",
    "                        test_array9 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MFI']])\n",
    "                \n",
    "                        test_array10 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array11 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array12 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MACD'], row['Signal_Line']])\n",
    "                \n",
    "                        test_array13 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array14 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array15 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                \n",
    "                \n",
    "                        temp_list1.append(test_array1)\n",
    "                        temp_list2.append(test_array2)\n",
    "                        temp_list3.append(test_array3)\n",
    "                        temp_list4.append(test_array4)\n",
    "                        temp_list5.append(test_array5)\n",
    "                        temp_list6.append(test_array6)\n",
    "                        temp_list7.append(test_array7)\n",
    "                        temp_list8.append(test_array8)\n",
    "                        temp_list9.append(test_array9)\n",
    "                        temp_list10.append(test_array10)\n",
    "                        temp_list11.append(test_array11)\n",
    "                        temp_list12.append(test_array12)\n",
    "                        temp_list13.append(test_array13)\n",
    "                        temp_list14.append(test_array14)\n",
    "                        temp_list15.append(test_array15)\n",
    "                        \n",
    "                independent_list1.append(temp_list1)\n",
    "                independent_list2.append(temp_list2)\n",
    "                independent_list3.append(temp_list3)\n",
    "                independent_list4.append(temp_list4)\n",
    "                independent_list5.append(temp_list5)\n",
    "                independent_list6.append(temp_list6)\n",
    "                independent_list7.append(temp_list7)\n",
    "                independent_list8.append(temp_list8)\n",
    "                independent_list9.append(temp_list9)\n",
    "                independent_list10.append(temp_list10)\n",
    "                independent_list11.append(temp_list11)\n",
    "                independent_list12.append(temp_list12)\n",
    "                independent_list13.append(temp_list13)\n",
    "                independent_list14.append(temp_list14)\n",
    "                independent_list15.append(temp_list15)\n",
    "            \n",
    "                if (dependent2_df['Close'].iloc[0] > dependent_df['Close'].iloc[0] * percent):\n",
    "                    dependent_list.append(1)\n",
    "                else:\n",
    "                    dependent_list.append(0)\n",
    "        \n",
    "        independent_array1 = np.array(independent_list1)\n",
    "        independent_array2 = np.array(independent_list2)\n",
    "        independent_array3 = np.array(independent_list3)\n",
    "        independent_array4 = np.array(independent_list4)\n",
    "        independent_array5 = np.array(independent_list5)\n",
    "        independent_array6 = np.array(independent_list6)\n",
    "        independent_array7 = np.array(independent_list7)\n",
    "        independent_array8= np.array(independent_list8)\n",
    "        independent_array9 = np.array(independent_list9)\n",
    "        independent_array10 = np.array(independent_list10)\n",
    "        independent_array11 = np.array(independent_list11)\n",
    "        independent_array12 = np.array(independent_list12)\n",
    "        independent_array13 = np.array(independent_list13)\n",
    "        independent_array14 = np.array(independent_list14)\n",
    "        independent_array15 = np.array(independent_list15)\n",
    "        dependent_array = np.array(dependent_list)\n",
    "    \n",
    "    \n",
    "        y = dependent_array\n",
    "        independent_array = []\n",
    "        best_accuracy = []\n",
    "        avg_accuracy = []\n",
    "        counter_independentarray = 0\n",
    "        for i in range(1, 16):\n",
    "            #if i != 12: #testing what seems is the most well performing model\n",
    "                #continue\n",
    "            \n",
    "            # Select which independent_array to use\n",
    "            if i == 1:\n",
    "                X = independent_array1  # Shape: (890, 30, 4)\n",
    "                independent_array.append(\"independent_array1\")\n",
    "            if i == 2:\n",
    "                X = independent_array2  # Shape: (890, 30, 4)\n",
    "                independent_array.append(\"independent_array2\")\n",
    "            if i == 3:\n",
    "                X = independent_array3  # Shape: (890, 30, 4)\n",
    "                independent_array.append(\"independent_array3\")\n",
    "            if i == 4:\n",
    "                X = independent_array4  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array4\")\n",
    "            if i == 5:\n",
    "                X = independent_array5  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array5\")\n",
    "            if i == 6:\n",
    "                X = independent_array6  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array6\")\n",
    "            if i == 7:\n",
    "                X = independent_array7  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array7\")\n",
    "            if i == 8:\n",
    "                X = independent_array8  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array8\")\n",
    "            if i == 9:\n",
    "                X = independent_array9  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array9\")\n",
    "            if i == 10:\n",
    "                X = independent_array10  # Shape: (890, 30, 6)\n",
    "                independent_array.append(\"independent_array10\")\n",
    "            if i == 11:\n",
    "                X = independent_array11  # Shape: (890, 30, 6)\n",
    "                independent_array.append(\"independent_array11\")\n",
    "            if i == 12:\n",
    "                X = independent_array12  # Shape: (890, 30, 6)\n",
    "                independent_array.append(\"independent_array12\")\n",
    "            if i == 13:\n",
    "                X = independent_array13  # Shape: (890, 30, 8)\n",
    "                independent_array.append(\"independent_array13\")\n",
    "            if i == 14:\n",
    "                X = independent_array14  # Shape: (890, 30, 8)\n",
    "                independent_array.append(\"independent_array14\")\n",
    "            if i == 15:\n",
    "                X = independent_array15  # Shape: (890, 30, 8)\n",
    "                independent_array.append(\"independent_array15\")\n",
    "        \n",
    "            counter_independentarray = counter_independentarray + 1\n",
    "            \n",
    "            # Define the input shape based on the number of features\n",
    "            input_shape = (30, X.shape[2])  # 30 time-steps and `X.shape[2]` features per time-step\n",
    "            \n",
    "            # Create the LSTM model\n",
    "            classification_model = create_lstm_classification(input_shape)\n",
    "            \n",
    "            # Initialize k-fold cross-validation\n",
    "            #kf = KFold(n_splits=5, shuffle=True, random_state=6)  #regular 5-fold cross-validation w/out stratification\n",
    "            kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=6)  # 5-fold cross-validation with stratification\n",
    "\n",
    "            #initialize to gather all the accuracy scores at each epoch for all 5 folds\n",
    "            fold_accuracies = []\n",
    "            \n",
    "            #stratified K-fold Cross-Validation\n",
    "            counter_kfold = 0\n",
    "            for train_index, val_index in kf.split(X, y): #used for stratified k-fold\n",
    "            #for train_index, val_index in kf.split(X): #used for regular k-fold\n",
    "                \n",
    "                counter_kfold = counter_kfold + 1\n",
    "                print(f\"Now running, pct_increase: {percent}; days out: {day}; independent_array: {counter_independentarray}; K-fold: {counter_kfold}\")\n",
    "                \n",
    "                X_train, X_val = X[train_index], X[val_index]\n",
    "                y_train, y_val = y[train_index], y[val_index]\n",
    "                \n",
    "                # Train the classification model and store the history; verbose = 0 to hide epoch running info in cell output\n",
    "                history = classification_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "                \n",
    "                # Get the validation accuracies for this fold. What this does is that an accuracy score is calculated at each epoch,\n",
    "                #and in this list I am getting all the accuracy scores from all five folds\n",
    "                val_accuracy = history.history['val_accuracy']\n",
    "                fold_accuracies.append(val_accuracy)\n",
    "        \n",
    "        \n",
    "            \n",
    "            # Calculate the best and average validation accuracy across all folds\n",
    "            best_val_accuracy = np.max(fold_accuracies) #get the max accuracy across all epochs across all five folds\n",
    "            avg_val_accuracy = np.mean(fold_accuracies) #get the mean accuracy across all epochs across all five folds\n",
    "            best_accuracy.append(best_val_accuracy)\n",
    "            avg_accuracy.append(avg_val_accuracy)\n",
    "        \n",
    "        \n",
    "        # Example of new data to add\n",
    "        df_new = pd.DataFrame({\n",
    "            'ticker': ticker_symbol,\n",
    "            'pattern': selected_pattern,\n",
    "            'independent_array': independent_array,\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'avg_accuracy': avg_accuracy,\n",
    "            'days_out': day,\n",
    "            'Total_observations': sum(np.unique(dependent_array, return_counts=True)[1]),\n",
    "            'Negative_observations': np.unique(dependent_array, return_counts=True)[1][0],\n",
    "            'Positive_observations': np.unique(dependent_array, return_counts=True)[1][1],\n",
    "            'Percent_increase_parameter': percent\n",
    "        })\n",
    "    \n",
    "        # Concatenate the new data to the empty DataFrame\n",
    "        accuracy_df = pd.concat([accuracy_df, df_new], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ff542d41-e198-4065-9476-668ce80808fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will output multiple CSV files with training results for classification model\n",
    "accuracy_df.to_csv(f'{ticker_symbol}_{selected_pattern}_classification_output.csv', index=False)  # `index=False` avoids writing the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b066a-018e-47a0-8e89-5bf60e52f5c3",
   "metadata": {},
   "source": [
    "After I have ran the above code, multiple times for each pattern (random, hammer, and inverted hammer) and received a CSV output for each, I will determine the results in the reporting section of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1f3a3-51e9-4725-a54a-e465bea069c6",
   "metadata": {},
   "source": [
    "#### LSTM Regression Model\n",
    "\n",
    "Now, I am going to transition from classification to the regression model. As the second part of my research question is aimed at comparing the performance between these two models.\n",
    "\n",
    "Below, as we did with prior to running the classification model, the first thing we need to do is get the data to run the regression model. The independent variables will be the same as when they were run through the classification model. What changes is the dependent variable. Instead of a binary variable, we are going to have a continous dependent variable that represents the stock's closing price on a future day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1edde645-bf9a-4094-8ddf-6c72e03a5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset data frame for desired pattern\n",
    "pattern_df = finance_df[finance_df['Hammer_pattern'] == \"Yes\"]\n",
    "#pattern_df = finance_df[finance_df['Random_Yes_No'] == \"Yes\"]\n",
    "\n",
    "#How many days after the pattern is identified to use for the dependent variable\n",
    "days_out = 1\n",
    "\n",
    "#What percent increase from the current price is considered a positive class. For example 1.01 = 1% increase; 100 * 1.01 = 101. So if original\n",
    "#price is $100, anything greater than $101 is considered a positive class.\n",
    "pct_increase = 1.00\n",
    "\n",
    "#Gather independent variables\n",
    "independent_list1 = []\n",
    "independent_list2 = []\n",
    "independent_list3 = []\n",
    "independent_list4 = []\n",
    "independent_list5 = []\n",
    "independent_list6 = []\n",
    "independent_list7 = []\n",
    "independent_list8 = []\n",
    "independent_list9 = []\n",
    "independent_list10 = []\n",
    "independent_list11 = []\n",
    "independent_list12 = []\n",
    "independent_list13 = []\n",
    "independent_list14 = []\n",
    "independent_list15 = []\n",
    "\n",
    "#gather dependent variables\n",
    "dependent_list = [] #this is for classification tasks\n",
    "dependent_list_regression = [] #this is for regression tasks\n",
    "dependent_list_regression_log = []\n",
    "dependent_list_regression_normalized = []\n",
    "\n",
    "pattern_index = list(pattern_df[\"Row_index\"])\n",
    "#pattern_index = [60, 62]\n",
    "for i in pattern_index:\n",
    "    #if (i == 62):\n",
    "    #    break\n",
    "    \n",
    "    #unable to get 30 days worth of data if index is less than 56, because previously removed first 26 observations\n",
    "    if (i < 56):\n",
    "        continue\n",
    "\n",
    "    #get 30 days worth of data to gather data for indpendent variables\n",
    "    subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 29)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "    \n",
    "    #Get day after data to gather closing price for dependent variable\n",
    "    dependent_df = finance_df[finance_df[\"Row_index\"] == (i)]\n",
    "    dependent2_df = finance_df[finance_df[\"Row_index\"] == (i + days_out)]\n",
    "    \n",
    "    temp_list1 = []\n",
    "    temp_list2 = []\n",
    "    temp_list3 = []\n",
    "    temp_list4 = []\n",
    "    temp_list5 = []\n",
    "    temp_list6 = []\n",
    "    temp_list7 = []\n",
    "    temp_list8 = []\n",
    "    temp_list9 = []\n",
    "    temp_list10 = []\n",
    "    temp_list11 = []\n",
    "    temp_list12 = []\n",
    "    temp_list13 = []\n",
    "    temp_list14 = []\n",
    "    temp_list15 = []\n",
    "\n",
    "    #append temp_list to independent_list\n",
    "    if len(dependent2_df) > 0: #dependent2_df may have length of zero as it is a future date, data may not be available\n",
    "    \n",
    "\n",
    "        for index, row in subset_df.iterrows():\n",
    "                \n",
    "                test_array1 = np.array([row['Open'], row['Close'], row['High'], row['Low']])\n",
    "                test_array2 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low']])\n",
    "                test_array3 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low']])\n",
    "        \n",
    "                test_array4 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI']])\n",
    "                test_array5 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI']])\n",
    "                test_array6 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI']])\n",
    "        \n",
    "                test_array7 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MFI']])\n",
    "                test_array8 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MFI']])\n",
    "                test_array9 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MFI']])\n",
    "        \n",
    "                test_array10 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MACD'], row['Signal_Line']])\n",
    "                test_array11 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MACD'], row['Signal_Line']])\n",
    "                test_array12 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MACD'], row['Signal_Line']])\n",
    "        \n",
    "                test_array13 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                test_array14 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                test_array15 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "        \n",
    "                \n",
    "                temp_list1.append(test_array1)\n",
    "                temp_list2.append(test_array2)\n",
    "                temp_list3.append(test_array3)\n",
    "                temp_list4.append(test_array4)\n",
    "                temp_list5.append(test_array5)\n",
    "                temp_list6.append(test_array6)\n",
    "                temp_list7.append(test_array7)\n",
    "                temp_list8.append(test_array8)\n",
    "                temp_list9.append(test_array9)\n",
    "                temp_list10.append(test_array10)\n",
    "                temp_list11.append(test_array11)\n",
    "                temp_list12.append(test_array12)\n",
    "                temp_list13.append(test_array13)\n",
    "                temp_list14.append(test_array14)\n",
    "                temp_list15.append(test_array15)\n",
    "               \n",
    "        independent_list1.append(temp_list1)\n",
    "        independent_list2.append(temp_list2)\n",
    "        independent_list3.append(temp_list3)\n",
    "        independent_list4.append(temp_list4)\n",
    "        independent_list5.append(temp_list5)\n",
    "        independent_list6.append(temp_list6)\n",
    "        independent_list7.append(temp_list7)\n",
    "        independent_list8.append(temp_list8)\n",
    "        independent_list9.append(temp_list9)\n",
    "        independent_list10.append(temp_list10)\n",
    "        independent_list11.append(temp_list11)\n",
    "        independent_list12.append(temp_list12)\n",
    "        independent_list13.append(temp_list13)\n",
    "        independent_list14.append(temp_list14)\n",
    "        independent_list15.append(temp_list15)\n",
    "    \n",
    "        dependent_list_regression.append(dependent2_df['Close'].iloc[0])\n",
    "        dependent_list_regression_log.append(dependent2_df['Log_Close'].iloc[0])\n",
    "        dependent_list_regression_normalized.append(dependent2_df['Normalized_Close'].iloc[0])\n",
    "\n",
    "        if (dependent2_df['Close'].iloc[0] > dependent_df['Close'].iloc[0] * pct_increase):\n",
    "            dependent_list.append(1)\n",
    "        else:\n",
    "            dependent_list.append(0)\n",
    "\n",
    "\n",
    "independent_array1 = np.array(independent_list1)\n",
    "independent_array2 = np.array(independent_list2)\n",
    "independent_array3 = np.array(independent_list3)\n",
    "independent_array4 = np.array(independent_list4)\n",
    "independent_array5 = np.array(independent_list5)\n",
    "independent_array6 = np.array(independent_list6)\n",
    "independent_array7 = np.array(independent_list7)\n",
    "independent_array8= np.array(independent_list8)\n",
    "independent_array9 = np.array(independent_list9)\n",
    "independent_array10 = np.array(independent_list10)\n",
    "independent_array11 = np.array(independent_list11)\n",
    "independent_array12 = np.array(independent_list12)\n",
    "independent_array13 = np.array(independent_list13)\n",
    "independent_array14 = np.array(independent_list14)\n",
    "independent_array15 = np.array(independent_list15)\n",
    "dependent_array = np.array(dependent_list) #used to see how many positive and negative classes\n",
    "dependent_array_regression = np.array(dependent_list_regression)\n",
    "dependent_array_regression_log = np.array(dependent_list_regression_log)\n",
    "dependent_array_regression_normalized = np.array(dependent_list_regression_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2568c-cbb2-4f44-b1cb-3a292d5d1aef",
   "metadata": {},
   "source": [
    "This code below defines and trains a regression model using an LSTM (Long Short-Term Memory) network, a type of recurrent neural network (RNN) designed for sequence prediction tasks. The regression model aims to predict a continuous target variable based on a series of input features. First, the code imports the necessary libraries, including Keras for building and training the model, scikit-learn for data preprocessing and splitting, and other utility libraries like numpy and pandas. It defines a function create_lstm_regression() to create the LSTM-based regression model. The model consists of two LSTM layers, each followed by a Dropout layer to reduce the risk of overfitting. The first LSTM layer has 128 units and returns sequences of data, allowing the next LSTM layer to process the sequence. The second LSTM layer has 64 units and does not return sequences. The final layer is a Dense layer with a single neuron and a linear activation function, which outputs a continuous value suitable for regression tasks. The model is compiled using the Adam optimizer and mean squared error (MSE) loss function, which is commonly used for regression.\n",
    "\n",
    "In the second part of the code, the input data (X) and target labels (y) are prepared for training. The independent variables (X) are chosen from the earlier dataset (e.g., independent_array1), which contains time-series features such as stock prices and technical indicators, while the dependent variable (y) contains the regression targets (e.g., future stock price movements). The data is then split into training and testing sets using train_test_split(), where 80% is used for training and 20% for testing. The input_shape for the LSTM model is determined by the number of time steps (30) and the number of features per time-step (e.g., 8 for independent_array_15). The LSTM model is then created by calling create_lstm_regression() with the input_shape, and the model is trained using the fit() method. The training process runs for 10 epochs, with a batch size of 32, and the model's performance is evaluated on the test set using the validation data. The verbose = 1 option displays the training progress during each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2728228f-3cdc-4d6e-85e5-19d0f8658d10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 758ms/step - loss: 65740.9219 - mae: 203.2404 - val_loss: 52114.9180 - val_mae: 187.3432\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 59008.4766 - mae: 191.7096 - val_loss: 51820.3789 - val_mae: 186.5379\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 59213.7461 - mae: 189.7480 - val_loss: 51560.4414 - val_mae: 185.8472\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 61183.7383 - mae: 196.5097 - val_loss: 51328.4375 - val_mae: 185.2185\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 64968.6641 - mae: 201.8303 - val_loss: 51115.5391 - val_mae: 184.6420\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 65988.2812 - mae: 202.6831 - val_loss: 50930.0391 - val_mae: 184.1364\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 65451.7305 - mae: 202.7320 - val_loss: 50758.2305 - val_mae: 183.6656\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 59947.5195 - mae: 189.7587 - val_loss: 50587.1172 - val_mae: 183.1947\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 73399.4453 - mae: 212.8492 - val_loss: 50407.9062 - val_mae: 182.7036\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 67499.9766 - mae: 201.8873 - val_loss: 50222.9688 - val_mae: 182.2100\n"
     ]
    }
   ],
   "source": [
    "#code for regression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "\n",
    "# Define the regression model\n",
    "def create_lstm_regression(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(128, activation='tanh', return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
    "    \n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))  # Final LSTM layer\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense output layer for regression\n",
    "    model.add(Dense(1, activation='linear'))  # Predicting a continuous value\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])  # MSE for regression tasks\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Independent variables (features)\n",
    "X = independent_array1  # Shape: (890, 30, )\n",
    "\n",
    "# Dependent variable (target); make sure to match the dependent array with the correct independent variables-- if X == independent_array3 then y should be set to dependent_array_regression_normalized \n",
    "y = dependent_array_regression  # Shape: (890,)\n",
    "\n",
    "#split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6)\n",
    "\n",
    "#define the input shape based on your data; for example independent array_1 has input_shape of (30, 4); independent array_15's shape is (30,8)\n",
    "input_shape = (30, X.shape[2])  # 30 time-steps and 8 features per time-step for independent_array_15\n",
    "\n",
    "#create the LSTM model\n",
    "regression_model = create_lstm_regression(input_shape)\n",
    "\n",
    "#train the classification model and store history. verbose = 0 -> hides the training output\n",
    "history = regression_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7be14b42-f15d-4b0e-974e-4ce96c7e0660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
      "Total correct predictions: 7; out of 14 observations in test set\n",
      "Total observations: 69\n",
      "Number of observations each class from dependent variable: (array([0, 1]), array([37, 32]))\n"
     ]
    }
   ],
   "source": [
    "#get the predictions of the model when applied on the test set\n",
    "y_pred = regression_model.predict(X_test)\n",
    "\n",
    "#Get the actual closing prices from the test set; we know the closing price on the final day of the candlestick pattern, is always the 30th day, and 2nd item in the array\n",
    "last_closing_price = X_test[:, 29, 1]\n",
    "\n",
    "comparison = (y_pred.flatten() > last_closing_price * pct_increase) #are the predictions greater than the actual closing prices\n",
    "comparison_2 = (y_pred.flatten() <= last_closing_price * pct_increase) #are the predictions less than or equal to the actual closing prices\n",
    "\n",
    "comparison_3 = (y_test > last_closing_price * pct_increase) #are the actual closing prices from the test set greater than the actual closing prices\n",
    "comparison_4 = (y_test <= last_closing_price * pct_increase) #are the actual closing prices from the test set less than or equal to the actual closing prices\n",
    "\n",
    "# Case 1: When both predicted and actual values are greater than the closing price\n",
    "correct_greater = comparison & comparison_3\n",
    "# Case 2: When both predicted and actual values are less than or equal to the closing price\n",
    "correct_lesser_or_equal = comparison_2 & comparison_4\n",
    "\n",
    "#total correct predictions\n",
    "print(f'Total correct predictions: {np.sum(correct_greater) + np.sum(correct_lesser_or_equal)}; out of {len(y_test)} observations in test set')\n",
    "print(f'Total observations: {sum(np.unique(dependent_array, return_counts=True)[1])}')\n",
    "print(f'Number of observations each class from dependent variable: {np.unique(dependent_array, return_counts=True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea1d152-81ed-43a0-9931-a35974ac4b24",
   "metadata": {},
   "source": [
    "A regression model is designed to predict continuous values, not for classification tasks. However, I needed a way to compare the performance of both my regression and classification models. To do this, I evaluated the predicted values from my regression model using the following approach:\n",
    "\n",
    "1. If the predicted closing price is greater than the closing price of the last candle in the identified candlestick pattern, and the actual closing price (from the test set) is also greater than the last candle’s closing price, this is considered a correct prediction.\n",
    "2. If the predicted closing price is less than or equal to the closing price of the last candle in the identified candlestick pattern, and the actual closing price (from the test set) is also less than or equal to the last candle’s closing price, this is also considered a correct prediction.\n",
    "3. I then count the number of correct predictions from both cases (steps 1 and 2), and divide this by the total number of observations in the test set to calculate the accuracy.\n",
    "\n",
    "In this example, we have a total of 69 observations, with 37 of those observations belonging to the negative class, meaning the future closing price was less than the closing price from the last candle in the identified candlestick pattern. Dividing 37 by 69 gives us a percentage of 53.6%. This percentage represents the proportion of negative class observations in the test set.\n",
    "\n",
    "When comparing this to the performance of our regression model, we see that it correctly classified 7 out of 14 total in the test set observations, or 50.0%. This means that if I had predicted every observation to belong to the negative class, my model would have performed better than the regression model (since 53.6% of the observations were negative class)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6c227-0b39-4fe4-8f64-4c1818df7349",
   "metadata": {},
   "source": [
    "#### Exploring Model Performance with Parameter Variations and Stratified K-Fold Cross Validation - LSTM Regression Model\n",
    "\n",
    "I am going to repeat the analysis that I did with various parameter combinations and stratified K-fold cross validation from when I performed the training of the LSTM classification model.\n",
    "\n",
    "This time, as mentioned before, I will have a different dependent variable as instead of having binary dependent variables, I will have a continuous dependent variable.\n",
    "\n",
    "For the parameter combinations, I will evaluate my model using three patterns: random days, the hammer pattern, and the inverted hammer pattern. I’ve chosen not to evaluate the other patterns due to insufficient observations in the dataset. When I refer to evaluating my model on random days, I mean that I previously created a column in the dataset with randomly assigned \"Yes\" values. These \"Yes\" values are distributed randomly, and my goal is to compare the model's performance using these random patterns versus patterns that are specifically identified as candlestick patterns. This will help me understand if the model behaves differently when dealing with randomly assigned patterns versus known candlestick patterns.\n",
    "\n",
    "Other parameters I will test will be how many days out after the pattern is identified to use for the dependent variable. For example, if this is set to the value of \"1\", the closing price for the day directly after the candlestick pattern will be the dependent variable. If set to \"10\" for example, the closing price 10 days after the last candle in the candlestick pattern will be the dependent variable.\n",
    "\n",
    "My last parameter combination will be what percent increase from the original price is considered a positive class. For example 1.01 = 1% increase; 100 * 1.01 = 101. So if the original price is 100 dollars, anything greater than 101 dollars is considered a positive class.\n",
    "\n",
    "I will also use statified K-fold Cross validation as I previously did when training the classification model. \n",
    "\n",
    "The result of running the code below will output a CSV file which shows the accuracy scores of each parameter and variable combination. I am going to have to run this code below multiple times, each time for the selected candle stick pattern (the code below can only run one selected pattern and one stock ticker at a time). Again, I will only run the stock ticker \"SPY\" in an effort to save resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1813d5c3-8bc7-4588-8834-78ef3994d324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_27512\\4038827188.py:358: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  accuracy_df = pd.concat([accuracy_df, df_new], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "Total correct predictions: 2; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
      "Total correct predictions: 0; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "Total correct predictions: 9; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "Total correct predictions: 0; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
      "Total correct predictions: 2; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "Total correct predictions: 0; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Total correct predictions: 2; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "Total correct predictions: 0; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "Total correct predictions: 2; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step\n",
      "Total correct predictions: 0; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
      "Total correct predictions: 2; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
      "Total correct predictions: 0; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([18, 34]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 9; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step\n",
      "Total correct predictions: 2; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([19, 33]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Total correct predictions: 9; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "Total correct predictions: 1; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
      "Total correct predictions: 1; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([40, 12]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([28, 24]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([21, 31]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([22, 30]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "Total correct predictions: 11; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n",
      "Total correct predictions: 2; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step\n",
      "Total correct predictions: 11; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Total correct predictions: 1; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step\n",
      "Total correct predictions: 11; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Total correct predictions: 1; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 2; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
      "Total correct predictions: 11; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Total correct predictions: 1; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n",
      "Total correct predictions: 11; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Total correct predictions: 10; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 0; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([47,  5]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Total correct predictions: 9; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "Total correct predictions: 9; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 9; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
      "Total correct predictions: 2; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 9; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "Total correct predictions: 9; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([39, 13]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step\n",
      "Total correct predictions: 3; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([35, 17]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "Total correct predictions: 8; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 8; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 1; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 2; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 3; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 4; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 5; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 6; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 7; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 8; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 9; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 10; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 11; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Total correct predictions: 9; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 4; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 12; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Total correct predictions: 7; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
      "Total correct predictions: 3; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 13; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
      "Total correct predictions: 4; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Total correct predictions: 2; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 14; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "Total correct predictions: 6; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Total correct predictions: 5; out of 11 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n",
      "Total correct predictions: 5; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Total correct predictions: 6; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: 15; K-fold: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Total correct predictions: 7; out of 10 observations in test set\n",
      "Total observations (combined train and test sets): 52\n",
      "Number of observations each class from dependent variable (combined): (array([0, 1]), array([26, 26]))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "### User inputs ###\n",
    "selected_pattern = \"InvertedHammer\"   #choices: 'Random', 'Hammer', 'InvertedHammer'\n",
    "\n",
    "#How many days after the pattern is identified to use for the dependent variable\n",
    "days_out = [1, 3, 5, 10, 15]\n",
    "\n",
    "#What percent increase from the current price is considered a positive class. For example 1.01 = 1% increase; 100 * 1.01 = 101. So if original\n",
    "#price is $100, anything greater than $101 is considered a positive class.\n",
    "pct_increase = [1.00, 1.01, 1.02]\n",
    "\n",
    "######\n",
    "\n",
    "\n",
    "# Define the regression model\n",
    "def create_lstm_regression(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(128, activation='tanh', return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
    "    \n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))  # Final LSTM layer\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense output layer for regression\n",
    "    model.add(Dense(1, activation='linear'))  # Predicting a continuous value\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])  # MSE for regression tasks\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "\n",
    "#Subset data frame for desired pattern\n",
    "if (selected_pattern == \"Random\"):\n",
    "    pattern_df = finance_df[finance_df['Random_Yes_No'] == \"Yes\"]\n",
    "elif (selected_pattern == \"Hammer\"):\n",
    "    pattern_df = finance_df[finance_df['Hammer_pattern'] == \"Yes\"]\n",
    "else:\n",
    "    pattern_df = finance_df[finance_df['InvertedHammer_pattern'] == \"Yes\"]\n",
    "\n",
    "\n",
    "#initialize an empty DataFrame with column names\n",
    "accuracy_df = pd.DataFrame(columns=['ticker', 'pattern', 'independent_array', 'best_accuracy', 'avg_accuracy', 'days_out', 'Total_observations', \n",
    "                                   'Negative_observations', 'Positive_observations', 'Percent_increase_parameter'])\n",
    "\n",
    "\n",
    "for percent in pct_increase:\n",
    "\n",
    "    for day in days_out:\n",
    "        #Gather independent variables\n",
    "        independent_list1 = []\n",
    "        independent_list2 = []\n",
    "        independent_list3 = []\n",
    "        independent_list4 = []\n",
    "        independent_list5 = []\n",
    "        independent_list6 = []\n",
    "        independent_list7 = []\n",
    "        independent_list8 = []\n",
    "        independent_list9 = []\n",
    "        independent_list10 = []\n",
    "        independent_list11 = []\n",
    "        independent_list12 = []\n",
    "        independent_list13 = []\n",
    "        independent_list14 = []\n",
    "        independent_list15 = []\n",
    "        dependent_list_regression = []\n",
    "        dependent_list_regression_log = [] \n",
    "        dependent_list_regression_normalized = [] \n",
    "        \n",
    "        #gather dependent variables\n",
    "        dependent_list = []\n",
    "\n",
    "        #these are the row indexes that have the identified patterns; loop through\n",
    "        pattern_index = list(pattern_df[\"Row_index\"])\n",
    "        for i in pattern_index:\n",
    "            #if (i == 62):\n",
    "            #    break\n",
    "            \n",
    "            #unable to get 30 days worth of data if index is less than 56, because previously removed first 26 observations\n",
    "            if (i < 56):\n",
    "                continue\n",
    "        \n",
    "            #get 30 days worth of data to gather data for indpendent variables\n",
    "            subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 29)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "            #subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 13)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "            \n",
    "            #Get day after data to gather closing price for dependent variable\n",
    "            dependent_df = finance_df[finance_df[\"Row_index\"] == (i)]\n",
    "            dependent2_df = finance_df[finance_df[\"Row_index\"] == (i + day)]\n",
    "            \n",
    "            temp_list1 = []\n",
    "            temp_list2 = []\n",
    "            temp_list3 = []\n",
    "            temp_list4 = []\n",
    "            temp_list5 = []\n",
    "            temp_list6 = []\n",
    "            temp_list7 = []\n",
    "            temp_list8 = []\n",
    "            temp_list9 = []\n",
    "            temp_list10 = []\n",
    "            temp_list11 = []\n",
    "            temp_list12 = []\n",
    "            temp_list13 = []\n",
    "            temp_list14 = []\n",
    "            temp_list15 = []\n",
    "        \n",
    "            #append temp_list to independent_list\n",
    "            if len(dependent2_df) > 0: #dependent2_df may have length of zero as it is a future date, data may not be available\n",
    "            \n",
    "        \n",
    "                for index, row in subset_df.iterrows():\n",
    "                        \n",
    "                        test_array1 = np.array([row['Open'], row['Close'], row['High'], row['Low']])\n",
    "                        test_array2 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low']])\n",
    "                        test_array3 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low']])\n",
    "                \n",
    "                        test_array4 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI']])\n",
    "                        test_array5 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI']])\n",
    "                        test_array6 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI']])\n",
    "                \n",
    "                        test_array7 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MFI']])\n",
    "                        test_array8 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MFI']])\n",
    "                        test_array9 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MFI']])\n",
    "                \n",
    "                        test_array10 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array11 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array12 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MACD'], row['Signal_Line']])\n",
    "                \n",
    "                        test_array13 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array14 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array15 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                \n",
    "                \n",
    "                        temp_list1.append(test_array1)\n",
    "                        temp_list2.append(test_array2)\n",
    "                        temp_list3.append(test_array3)\n",
    "                        temp_list4.append(test_array4)\n",
    "                        temp_list5.append(test_array5)\n",
    "                        temp_list6.append(test_array6)\n",
    "                        temp_list7.append(test_array7)\n",
    "                        temp_list8.append(test_array8)\n",
    "                        temp_list9.append(test_array9)\n",
    "                        temp_list10.append(test_array10)\n",
    "                        temp_list11.append(test_array11)\n",
    "                        temp_list12.append(test_array12)\n",
    "                        temp_list13.append(test_array13)\n",
    "                        temp_list14.append(test_array14)\n",
    "                        temp_list15.append(test_array15)\n",
    "                        \n",
    "                independent_list1.append(temp_list1)\n",
    "                independent_list2.append(temp_list2)\n",
    "                independent_list3.append(temp_list3)\n",
    "                independent_list4.append(temp_list4)\n",
    "                independent_list5.append(temp_list5)\n",
    "                independent_list6.append(temp_list6)\n",
    "                independent_list7.append(temp_list7)\n",
    "                independent_list8.append(temp_list8)\n",
    "                independent_list9.append(temp_list9)\n",
    "                independent_list10.append(temp_list10)\n",
    "                independent_list11.append(temp_list11)\n",
    "                independent_list12.append(temp_list12)\n",
    "                independent_list13.append(temp_list13)\n",
    "                independent_list14.append(temp_list14)\n",
    "                independent_list15.append(temp_list15)\n",
    "            \n",
    "                dependent_list_regression.append(dependent2_df['Close'].iloc[0])\n",
    "                dependent_list_regression_log.append(dependent2_df['Log_Close'].iloc[0])\n",
    "                dependent_list_regression_normalized.append(dependent2_df['Normalized_Close'].iloc[0])\n",
    "        \n",
    "                if (dependent2_df['Close'].iloc[0] > dependent_df['Close'].iloc[0] * percent):\n",
    "                    dependent_list.append(1)\n",
    "                else:\n",
    "                    dependent_list.append(0)\n",
    "        \n",
    "        independent_array1 = np.array(independent_list1)\n",
    "        independent_array2 = np.array(independent_list2)\n",
    "        independent_array3 = np.array(independent_list3)\n",
    "        independent_array4 = np.array(independent_list4)\n",
    "        independent_array5 = np.array(independent_list5)\n",
    "        independent_array6 = np.array(independent_list6)\n",
    "        independent_array7 = np.array(independent_list7)\n",
    "        independent_array8= np.array(independent_list8)\n",
    "        independent_array9 = np.array(independent_list9)\n",
    "        independent_array10 = np.array(independent_list10)\n",
    "        independent_array11 = np.array(independent_list11)\n",
    "        independent_array12 = np.array(independent_list12)\n",
    "        independent_array13 = np.array(independent_list13)\n",
    "        independent_array14 = np.array(independent_list14)\n",
    "        independent_array15 = np.array(independent_list15)\n",
    "        dependent_array = np.array(dependent_list)\n",
    "        dependent_array_regression = np.array(dependent_list_regression)\n",
    "        dependent_array_regression_log = np.array(dependent_list_regression_log)\n",
    "        dependent_array_regression_normalized = np.array(dependent_list_regression_normalized)\n",
    "    \n",
    "    \n",
    "        independent_array = []\n",
    "        best_accuracy = []\n",
    "        avg_accuracy = []\n",
    "        counter_independentarray = 0\n",
    "        for i in range(1, 16):\n",
    "            #if i != 12: #testing what seems is the most well performing model\n",
    "                #continue\n",
    "            \n",
    "            # Select which independent_array to use\n",
    "            if i == 1:\n",
    "                X = independent_array1  # Shape: (890, 30, 4)\n",
    "                independent_array.append(\"independent_array1\")\n",
    "                y = dependent_array_regression\n",
    "            if i == 2:\n",
    "                X = independent_array2  # Shape: (890, 30, 4)\n",
    "                independent_array.append(\"independent_array2\")\n",
    "                y = dependent_array_regression_log\n",
    "            if i == 3:\n",
    "                X = independent_array3  # Shape: (890, 30, 4)\n",
    "                independent_array.append(\"independent_array3\")\n",
    "                y = dependent_array_regression_normalized\n",
    "            if i == 4:\n",
    "                X = independent_array4  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array4\")\n",
    "                y = dependent_array_regression\n",
    "            if i == 5:\n",
    "                X = independent_array5  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array5\")\n",
    "                y = dependent_array_regression_log\n",
    "            if i == 6:\n",
    "                X = independent_array6  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array6\")\n",
    "                y = dependent_array_regression_normalized\n",
    "            if i == 7:\n",
    "                X = independent_array7  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array7\")\n",
    "                y = dependent_array_regression\n",
    "            if i == 8:\n",
    "                X = independent_array8  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array8\")\n",
    "                y = dependent_array_regression_log\n",
    "            if i == 9:\n",
    "                X = independent_array9  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array9\")\n",
    "                y = dependent_array_regression_normalized\n",
    "            if i == 10:\n",
    "                X = independent_array10  # Shape: (890, 30, 6)\n",
    "                independent_array.append(\"independent_array10\")\n",
    "                y = dependent_array_regression\n",
    "            if i == 11:\n",
    "                X = independent_array11  # Shape: (890, 30, 6)\n",
    "                independent_array.append(\"independent_array11\")\n",
    "                y = dependent_array_regression_log\n",
    "            if i == 12:\n",
    "                X = independent_array12  # Shape: (890, 30, 6)\n",
    "                independent_array.append(\"independent_array12\")\n",
    "                y = dependent_array_regression_normalized\n",
    "            if i == 13:\n",
    "                X = independent_array13  # Shape: (890, 30, 8)\n",
    "                independent_array.append(\"independent_array13\")\n",
    "                y = dependent_array_regression\n",
    "            if i == 14:\n",
    "                X = independent_array14  # Shape: (890, 30, 8)\n",
    "                independent_array.append(\"independent_array14\")\n",
    "                y = dependent_array_regression_log\n",
    "            if i == 15:\n",
    "                X = independent_array15  # Shape: (890, 30, 8)\n",
    "                independent_array.append(\"independent_array15\")\n",
    "                y = dependent_array_regression_normalized\n",
    "        \n",
    "            counter_independentarray = counter_independentarray + 1\n",
    "            \n",
    "            # Define the input shape based on the number of features\n",
    "            input_shape = (30, X.shape[2])  # 30 time-steps and `X.shape[2]` features per time-step\n",
    "            \n",
    "            # Create the LSTM model\n",
    "            regression_model = create_lstm_regression(input_shape)\n",
    "            \n",
    "            # Initialize k-fold cross-validation\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=6)  #regular 5-fold cross-validation w/out stratification, for regression tasks because no class imbalance\n",
    "            #kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=6)  # 5-fold cross-validation with stratification\n",
    "            \n",
    "            #create list to gather accuracy scores after training each fold\n",
    "            fold_accuracies = []\n",
    "            \n",
    "            #K-fold Cross-Validation\n",
    "            counter_kfold = 0\n",
    "            #for train_index, val_index in kf.split(X, y): #used for stratified k-fold\n",
    "            for train_index, val_index in kf.split(X): #used for regular k-fold\n",
    "                \n",
    "                counter_kfold = counter_kfold + 1\n",
    "                print(f\"Now running, pct_increase: {percent}; days out: {day}; independent_array: {counter_independentarray}; K-fold: {counter_kfold}\")\n",
    "                \n",
    "                X_train, X_val = X[train_index], X[val_index]\n",
    "                y_train, y_val = y[train_index], y[val_index]\n",
    "                \n",
    "                # Train the classification model and store the history; verbose = 0 to hide epoch running info in cell output\n",
    "                history = regression_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "                #get the predictions of the model when applied on the test set\n",
    "                y_pred = regression_model.predict(X_val)\n",
    "                \n",
    "                #Get the actual closing prices from the test set; we know the closing price on the final day of the candlestick pattern, \n",
    "                #is always the 30th day, and 2nd item in the array\n",
    "                last_closing_price = X_val[:, 29, 1]\n",
    "                \n",
    "                comparison = (y_pred.flatten() > last_closing_price * percent) #are the predictions greater than the actual closing prices\n",
    "                comparison_2 = (y_pred.flatten() <= last_closing_price * percent) #are the predictions less than or equal to the actual closing prices\n",
    "                \n",
    "                comparison_3 = (y_val > last_closing_price * percent) #are the actual closing prices from the test set greater than the actual closing prices\n",
    "                comparison_4 = (y_val <= last_closing_price * percent) #are the actual closing prices from the test set less than or equal to the actual closing prices\n",
    "                \n",
    "                # Case 1: When both predicted and actual values are greater than the closing price\n",
    "                correct_greater = comparison & comparison_3\n",
    "                # Case 2: When both predicted and actual values are less than or equal to the closing price\n",
    "                correct_lesser_or_equal = comparison_2 & comparison_4\n",
    "                \n",
    "                #total correct predictions\n",
    "                print(f'Total correct predictions: {np.sum(correct_greater) + np.sum(correct_lesser_or_equal)}; out of {len(y_val)} observations in test set')\n",
    "                print(f'Total observations (combined train and test sets): {sum(np.unique(dependent_array, return_counts=True)[1])}')\n",
    "                print(f'Number of observations each class from dependent variable (combined): {np.unique(dependent_array, return_counts=True)}')\n",
    "\n",
    "                #the accuracy score at the 10th epoch for each fold is appended to this list; this is different than gathering the accuracy\n",
    "                #scores for the classification model, because the classification model gets all accuracy scores from each epoch\n",
    "                fold_accuracies.append((np.sum(correct_greater) + np.sum(correct_lesser_or_equal)) / len(y_val))\n",
    "        \n",
    "        \n",
    "            \n",
    "            # Calculate the best and average validation accuracy across all folds\n",
    "            best_val_accuracy = np.max(fold_accuracies) #from the 10th epoch for each of the five folds, the accuracy is collected, and the max accuracy is stored\n",
    "            avg_val_accuracy = np.mean(fold_accuracies) #from the 10th epoch for each of the five folds, the accuracy is collected, and the mean accuracy is stored\n",
    "            best_accuracy.append(best_val_accuracy)\n",
    "            avg_accuracy.append(avg_val_accuracy)\n",
    "        \n",
    "        \n",
    "        # Example of new data to add\n",
    "        df_new = pd.DataFrame({\n",
    "            'ticker': ticker_symbol,\n",
    "            'pattern': selected_pattern,\n",
    "            'independent_array': independent_array,\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'avg_accuracy': avg_accuracy,\n",
    "            'days_out': day,\n",
    "            'Total_observations': sum(np.unique(dependent_array, return_counts=True)[1]),\n",
    "            'Negative_observations': np.unique(dependent_array, return_counts=True)[1][0],\n",
    "            'Positive_observations': np.unique(dependent_array, return_counts=True)[1][1],\n",
    "            'Percent_increase_parameter': percent\n",
    "        })\n",
    "    \n",
    "        # Concatenate the new data to the empty DataFrame\n",
    "        accuracy_df = pd.concat([accuracy_df, df_new], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9cb5c5ca-dcc3-458e-b635-684b5eac6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will output multiple CSV files with training results for classification model\n",
    "accuracy_df.to_csv(f'{ticker_symbol}_{selected_pattern}_regression_output.csv', index=False)  # `index=False` avoids writing the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ebb6b0-6033-4715-b52e-02959294bc95",
   "metadata": {},
   "source": [
    "#### Increasing number of observations for best performing model (Chose Classification Over Regression as Best Performing Model)\n",
    "\n",
    "After reviewing all of the CSV outputs with the training result data and respective accuracy scores, I have determined that the classification model performs better and more consistent with independent array #15 as the best performing set of independent variables. **I further explain why I chose the classification model over the regression model in the 'Reporting' section of this document.**\n",
    "\n",
    "**At this point, I have enough data to answer my research question, however, now I am going to increase the number of randomly generated sequences in order to make my model more adaptable for use on any given day as the hammer and inverted candlestick patterns have around a 1% occurrence rate. My hope is that even when a true candlestick pattern is not present, the model could still make reliable predictions for future closing prices.**\n",
    "\n",
    "Now, I am going to see if increasing the number of observations will change the accuracy scores for my best performing set of independent variables. While I cannot increase the number of observations when a candlestick pattern is identified, as that number is already fixed, I can increase the number of observations for my random \"Yes\" and \"No\" values. By simulating the presence of a random pattern with more data, I will test whether adding additional random observations (via the newly generated 'Random_Yes_No_2' column) will influence the accuracy scores. This approach will allow me to assess the impact of a larger dataset on model performance using the same model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d65bf6af-d36e-47f2-bead-b2fc8ba972f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Used to create another new column to test random values of 'yes' to simulate presence of a random pattern\n",
    "# Specify the number of \"Yes\" values you want, may show up as less during training due to location of the \"Yes\" value, as need at least 30 days\n",
    "#of data for the 30-day sequence, or if the future closing price is not available (only have data to 2/14)\n",
    "num_yes = 2200\n",
    "\n",
    "# Create a list of \"Yes\" and \"No\" values\n",
    "yes_no_list = [\"Yes\"] * num_yes + [\"No\"] * (len(finance_df) - num_yes)\n",
    "\n",
    "#set seed for reproducibility\n",
    "np.random.seed(6) \n",
    "\n",
    "# Shuffle the list to randomize the order\n",
    "np.random.shuffle(yes_no_list)\n",
    "\n",
    "# Add the list as a new column in the DataFrame; we already have a column 'Random_Yes_No' which was used to train the occurence of a random pattern\n",
    "#this mimics that idea but will now be a new column 'Random_Yes_No_2', but this time with more generated random observations\n",
    "finance_df['Random_Yes_No_2'] = yes_no_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dfd77dd9-3047-4c68-afdf-f9f6f8dab158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 1; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5199 - loss: 0.7155 - val_accuracy: 0.4521 - val_loss: 0.6954\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.5184 - loss: 0.6940 - val_accuracy: 0.5000 - val_loss: 0.6950\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.5173 - loss: 0.6976 - val_accuracy: 0.5297 - val_loss: 0.6909\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.5402 - loss: 0.6860 - val_accuracy: 0.5388 - val_loss: 0.6906\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.5505 - loss: 0.6877 - val_accuracy: 0.5342 - val_loss: 0.6907\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.5293 - loss: 0.6888 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.5610 - loss: 0.6899 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.5568 - loss: 0.6896 - val_accuracy: 0.5297 - val_loss: 0.6911\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.5274 - loss: 0.6893 - val_accuracy: 0.5411 - val_loss: 0.6920\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.5503 - loss: 0.6889 - val_accuracy: 0.5342 - val_loss: 0.6907\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.5395 - loss: 0.6903 - val_accuracy: 0.5479 - val_loss: 0.6874\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.5397 - loss: 0.6919 - val_accuracy: 0.5639 - val_loss: 0.6853\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.5661 - loss: 0.6847 - val_accuracy: 0.5662 - val_loss: 0.6863\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.5259 - loss: 0.6927 - val_accuracy: 0.5479 - val_loss: 0.6874\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.5561 - loss: 0.6895 - val_accuracy: 0.5548 - val_loss: 0.6875\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.5437 - loss: 0.6891 - val_accuracy: 0.5457 - val_loss: 0.6865\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.5510 - loss: 0.6863 - val_accuracy: 0.5502 - val_loss: 0.6878\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.5593 - loss: 0.6860 - val_accuracy: 0.5457 - val_loss: 0.6897\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5328 - loss: 0.6902 - val_accuracy: 0.5457 - val_loss: 0.6913\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5446 - loss: 0.6876 - val_accuracy: 0.5594 - val_loss: 0.6863\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.5588 - loss: 0.6864 - val_accuracy: 0.5639 - val_loss: 0.6857\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5470 - loss: 0.6887 - val_accuracy: 0.5685 - val_loss: 0.6857\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5473 - loss: 0.6906 - val_accuracy: 0.5639 - val_loss: 0.6856\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5463 - loss: 0.6891 - val_accuracy: 0.5708 - val_loss: 0.6850\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5521 - loss: 0.6868 - val_accuracy: 0.5594 - val_loss: 0.6860\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5571 - loss: 0.6846 - val_accuracy: 0.5731 - val_loss: 0.6866\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.5580 - loss: 0.6871 - val_accuracy: 0.5479 - val_loss: 0.6873\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5679 - loss: 0.6863 - val_accuracy: 0.5205 - val_loss: 0.6932\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5226 - loss: 0.6900 - val_accuracy: 0.5616 - val_loss: 0.6873\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.5576 - loss: 0.6860 - val_accuracy: 0.5434 - val_loss: 0.6901\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5471 - loss: 0.6885 - val_accuracy: 0.5365 - val_loss: 0.6884\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5415 - loss: 0.6894 - val_accuracy: 0.5434 - val_loss: 0.6911\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.5488 - loss: 0.6882 - val_accuracy: 0.5434 - val_loss: 0.6911\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5549 - loss: 0.6844 - val_accuracy: 0.5365 - val_loss: 0.6891\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.5691 - loss: 0.6840 - val_accuracy: 0.5342 - val_loss: 0.6914\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5506 - loss: 0.6861 - val_accuracy: 0.5434 - val_loss: 0.6894\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5669 - loss: 0.6836 - val_accuracy: 0.5411 - val_loss: 0.7003\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5268 - loss: 0.6945 - val_accuracy: 0.5320 - val_loss: 0.6913\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5474 - loss: 0.6867 - val_accuracy: 0.5297 - val_loss: 0.6916\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5290 - loss: 0.6881 - val_accuracy: 0.5297 - val_loss: 0.6942\n",
      "Now running, pct_increase: 1.0; days out: 1; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.5571 - loss: 0.6860 - val_accuracy: 0.5309 - val_loss: 0.6882\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.5558 - loss: 0.6823 - val_accuracy: 0.5538 - val_loss: 0.6855\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.5469 - loss: 0.6901 - val_accuracy: 0.5263 - val_loss: 0.6861\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.5594 - loss: 0.6850 - val_accuracy: 0.5309 - val_loss: 0.6864\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.5576 - loss: 0.6885 - val_accuracy: 0.5332 - val_loss: 0.6890\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5523 - loss: 0.6879 - val_accuracy: 0.5355 - val_loss: 0.6875\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.5435 - loss: 0.6881 - val_accuracy: 0.5309 - val_loss: 0.6893\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.5638 - loss: 0.6827 - val_accuracy: 0.5240 - val_loss: 0.6873\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.5676 - loss: 0.6827 - val_accuracy: 0.5378 - val_loss: 0.6865\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.5764 - loss: 0.6765 - val_accuracy: 0.5492 - val_loss: 0.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_27512\\3723232288.py:311: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  accuracy_df = pd.concat([accuracy_df, df_new], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running, pct_increase: 1.0; days out: 3; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.5491 - loss: 0.7074 - val_accuracy: 0.5753 - val_loss: 0.6837\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.5599 - loss: 0.6887 - val_accuracy: 0.5753 - val_loss: 0.6815\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.5764 - loss: 0.6848 - val_accuracy: 0.5753 - val_loss: 0.6811\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.5442 - loss: 0.6902 - val_accuracy: 0.5753 - val_loss: 0.6847\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.5657 - loss: 0.6843 - val_accuracy: 0.5753 - val_loss: 0.6809\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.5926 - loss: 0.6824 - val_accuracy: 0.5753 - val_loss: 0.6806\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.5815 - loss: 0.6837 - val_accuracy: 0.5753 - val_loss: 0.6797\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.5824 - loss: 0.6799 - val_accuracy: 0.5776 - val_loss: 0.6816\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.5801 - loss: 0.6816 - val_accuracy: 0.5731 - val_loss: 0.6810\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.5704 - loss: 0.6838 - val_accuracy: 0.5799 - val_loss: 0.6796\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.5828 - loss: 0.6816 - val_accuracy: 0.5753 - val_loss: 0.6806\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.5717 - loss: 0.6827 - val_accuracy: 0.5776 - val_loss: 0.6805\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.5925 - loss: 0.6775 - val_accuracy: 0.5776 - val_loss: 0.6829\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.5927 - loss: 0.6743 - val_accuracy: 0.5731 - val_loss: 0.6820\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.5984 - loss: 0.6753 - val_accuracy: 0.5708 - val_loss: 0.6853\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.5858 - loss: 0.6807 - val_accuracy: 0.5731 - val_loss: 0.6823\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.5800 - loss: 0.6761 - val_accuracy: 0.5662 - val_loss: 0.6831\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.5831 - loss: 0.6769 - val_accuracy: 0.5662 - val_loss: 0.6837\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.5799 - loss: 0.6792 - val_accuracy: 0.5594 - val_loss: 0.6842\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.5971 - loss: 0.6728 - val_accuracy: 0.5753 - val_loss: 0.6827\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.5703 - loss: 0.6810 - val_accuracy: 0.5812 - val_loss: 0.6788\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.5829 - loss: 0.6806 - val_accuracy: 0.5858 - val_loss: 0.6767\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.5846 - loss: 0.6766 - val_accuracy: 0.5767 - val_loss: 0.6768\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.6079 - loss: 0.6717 - val_accuracy: 0.5835 - val_loss: 0.6799\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.5832 - loss: 0.6807 - val_accuracy: 0.5995 - val_loss: 0.6736\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5722 - loss: 0.6838 - val_accuracy: 0.5835 - val_loss: 0.6748\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.5803 - loss: 0.6773 - val_accuracy: 0.5881 - val_loss: 0.6732\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.6105 - loss: 0.6678 - val_accuracy: 0.5789 - val_loss: 0.6756\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5874 - loss: 0.6745 - val_accuracy: 0.5721 - val_loss: 0.6802\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6055 - loss: 0.6680 - val_accuracy: 0.5858 - val_loss: 0.6789\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.5866 - loss: 0.6729 - val_accuracy: 0.5904 - val_loss: 0.6750\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5660 - loss: 0.6766 - val_accuracy: 0.5858 - val_loss: 0.6800\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.5684 - loss: 0.6726 - val_accuracy: 0.5881 - val_loss: 0.6810\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6143 - loss: 0.6594 - val_accuracy: 0.5858 - val_loss: 0.6741\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.5889 - loss: 0.6715 - val_accuracy: 0.5789 - val_loss: 0.6742\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.5968 - loss: 0.6670 - val_accuracy: 0.5904 - val_loss: 0.6778\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.5965 - loss: 0.6665 - val_accuracy: 0.5812 - val_loss: 0.6769\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.6024 - loss: 0.6616 - val_accuracy: 0.5995 - val_loss: 0.6804\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.5908 - loss: 0.6684 - val_accuracy: 0.5904 - val_loss: 0.6750\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6140 - loss: 0.6628 - val_accuracy: 0.5904 - val_loss: 0.6764\n",
      "Now running, pct_increase: 1.0; days out: 3; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5874 - loss: 0.6697 - val_accuracy: 0.5881 - val_loss: 0.6803\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5764 - loss: 0.6800 - val_accuracy: 0.5858 - val_loss: 0.6871\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.5970 - loss: 0.6630 - val_accuracy: 0.5950 - val_loss: 0.6817\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5824 - loss: 0.6696 - val_accuracy: 0.5881 - val_loss: 0.6843\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6025 - loss: 0.6653 - val_accuracy: 0.5858 - val_loss: 0.6745\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6089 - loss: 0.6576 - val_accuracy: 0.5721 - val_loss: 0.6842\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.5976 - loss: 0.6668 - val_accuracy: 0.5789 - val_loss: 0.6827\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6008 - loss: 0.6612 - val_accuracy: 0.5812 - val_loss: 0.6906\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6176 - loss: 0.6563 - val_accuracy: 0.5744 - val_loss: 0.6921\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6010 - loss: 0.6614 - val_accuracy: 0.5881 - val_loss: 0.6916\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.5584 - loss: 0.6965 - val_accuracy: 0.5936 - val_loss: 0.6938\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.5735 - loss: 0.6907 - val_accuracy: 0.5936 - val_loss: 0.6763\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.5904 - loss: 0.6795 - val_accuracy: 0.5936 - val_loss: 0.6760\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.6004 - loss: 0.6717 - val_accuracy: 0.5936 - val_loss: 0.6762\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.5798 - loss: 0.6759 - val_accuracy: 0.5936 - val_loss: 0.6775\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.5948 - loss: 0.6779 - val_accuracy: 0.5913 - val_loss: 0.6761\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.5943 - loss: 0.6731 - val_accuracy: 0.5936 - val_loss: 0.6752\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.5977 - loss: 0.6744 - val_accuracy: 0.5936 - val_loss: 0.6776\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.5824 - loss: 0.6846 - val_accuracy: 0.5845 - val_loss: 0.6774\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.5895 - loss: 0.6759 - val_accuracy: 0.5913 - val_loss: 0.6779\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5778 - loss: 0.6792 - val_accuracy: 0.5950 - val_loss: 0.6727\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.5913 - loss: 0.6755 - val_accuracy: 0.5950 - val_loss: 0.6763\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.5768 - loss: 0.6796 - val_accuracy: 0.5950 - val_loss: 0.6736\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5962 - loss: 0.6724 - val_accuracy: 0.5950 - val_loss: 0.6728\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.6096 - loss: 0.6681 - val_accuracy: 0.5973 - val_loss: 0.6768\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6037 - loss: 0.6707 - val_accuracy: 0.5995 - val_loss: 0.6728\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.5856 - loss: 0.6726 - val_accuracy: 0.5950 - val_loss: 0.6755\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.6117 - loss: 0.6654 - val_accuracy: 0.5950 - val_loss: 0.6767\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.5945 - loss: 0.6728 - val_accuracy: 0.5973 - val_loss: 0.6749\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.5922 - loss: 0.6703 - val_accuracy: 0.5950 - val_loss: 0.6767\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6148 - loss: 0.6651 - val_accuracy: 0.6018 - val_loss: 0.6708\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.6097 - loss: 0.6675 - val_accuracy: 0.6087 - val_loss: 0.6678\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.5990 - loss: 0.6704 - val_accuracy: 0.6041 - val_loss: 0.6679\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.6049 - loss: 0.6648 - val_accuracy: 0.6041 - val_loss: 0.6666\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.6062 - loss: 0.6672 - val_accuracy: 0.6064 - val_loss: 0.6691\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.5991 - loss: 0.6677 - val_accuracy: 0.5835 - val_loss: 0.6734\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.5730 - loss: 0.6827 - val_accuracy: 0.6041 - val_loss: 0.6693\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.5862 - loss: 0.6713 - val_accuracy: 0.5927 - val_loss: 0.6688\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.6173 - loss: 0.6622 - val_accuracy: 0.6064 - val_loss: 0.6616\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.5985 - loss: 0.6640 - val_accuracy: 0.6064 - val_loss: 0.6675\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.6040 - loss: 0.6655 - val_accuracy: 0.5904 - val_loss: 0.6715\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.6140 - loss: 0.6566 - val_accuracy: 0.5515 - val_loss: 0.6814\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.5805 - loss: 0.6720 - val_accuracy: 0.5629 - val_loss: 0.6678\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6092 - loss: 0.6551 - val_accuracy: 0.5858 - val_loss: 0.6760\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6138 - loss: 0.6622 - val_accuracy: 0.5675 - val_loss: 0.6708\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6097 - loss: 0.6643 - val_accuracy: 0.5538 - val_loss: 0.6773\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6007 - loss: 0.6665 - val_accuracy: 0.5927 - val_loss: 0.6756\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6182 - loss: 0.6567 - val_accuracy: 0.5721 - val_loss: 0.6860\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6004 - loss: 0.6505 - val_accuracy: 0.5995 - val_loss: 0.6650\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6268 - loss: 0.6469 - val_accuracy: 0.5950 - val_loss: 0.6806\n",
      "Now running, pct_increase: 1.0; days out: 5; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6157 - loss: 0.6498 - val_accuracy: 0.6407 - val_loss: 0.6347\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.6123 - loss: 0.6536 - val_accuracy: 0.6613 - val_loss: 0.6341\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6294 - loss: 0.6443 - val_accuracy: 0.6270 - val_loss: 0.6390\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6353 - loss: 0.6380 - val_accuracy: 0.6453 - val_loss: 0.6339\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6107 - loss: 0.6469 - val_accuracy: 0.6270 - val_loss: 0.6357\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6174 - loss: 0.6524 - val_accuracy: 0.6407 - val_loss: 0.6354\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6008 - loss: 0.6489 - val_accuracy: 0.6339 - val_loss: 0.6401\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6246 - loss: 0.6363 - val_accuracy: 0.6430 - val_loss: 0.6409\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6075 - loss: 0.6515 - val_accuracy: 0.6316 - val_loss: 0.6402\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6199 - loss: 0.6493 - val_accuracy: 0.6339 - val_loss: 0.6388\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.5815 - loss: 0.6986 - val_accuracy: 0.6224 - val_loss: 0.6612\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6310 - loss: 0.6637 - val_accuracy: 0.6224 - val_loss: 0.6590\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6299 - loss: 0.6563 - val_accuracy: 0.6087 - val_loss: 0.6686\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6116 - loss: 0.6708 - val_accuracy: 0.6224 - val_loss: 0.6652\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6076 - loss: 0.6710 - val_accuracy: 0.6224 - val_loss: 0.6640\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6364 - loss: 0.6571 - val_accuracy: 0.6201 - val_loss: 0.6635\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6047 - loss: 0.6690 - val_accuracy: 0.6224 - val_loss: 0.6747\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.6291 - loss: 0.6607 - val_accuracy: 0.6224 - val_loss: 0.6642\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6358 - loss: 0.6544 - val_accuracy: 0.6133 - val_loss: 0.6647\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6447 - loss: 0.6536 - val_accuracy: 0.6224 - val_loss: 0.6631\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6107 - loss: 0.6666 - val_accuracy: 0.6156 - val_loss: 0.6578\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.6164 - loss: 0.6640 - val_accuracy: 0.6224 - val_loss: 0.6568\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.6321 - loss: 0.6537 - val_accuracy: 0.6270 - val_loss: 0.6593\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.6177 - loss: 0.6654 - val_accuracy: 0.6224 - val_loss: 0.6550\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.6250 - loss: 0.6615 - val_accuracy: 0.6270 - val_loss: 0.6532\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.6523 - loss: 0.6405 - val_accuracy: 0.6270 - val_loss: 0.6600\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.6399 - loss: 0.6537 - val_accuracy: 0.6156 - val_loss: 0.6572\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.6405 - loss: 0.6473 - val_accuracy: 0.6224 - val_loss: 0.6575\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.6344 - loss: 0.6522 - val_accuracy: 0.6201 - val_loss: 0.6567\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.6316 - loss: 0.6530 - val_accuracy: 0.6384 - val_loss: 0.6514\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.6234 - loss: 0.6524 - val_accuracy: 0.6247 - val_loss: 0.6469\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.6231 - loss: 0.6495 - val_accuracy: 0.6339 - val_loss: 0.6436\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.6415 - loss: 0.6354 - val_accuracy: 0.6430 - val_loss: 0.6409\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.6479 - loss: 0.6339 - val_accuracy: 0.6270 - val_loss: 0.6495\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.6480 - loss: 0.6392 - val_accuracy: 0.6430 - val_loss: 0.6516\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.6366 - loss: 0.6476 - val_accuracy: 0.6384 - val_loss: 0.6430\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.6467 - loss: 0.6387 - val_accuracy: 0.6362 - val_loss: 0.6454\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.6170 - loss: 0.6488 - val_accuracy: 0.6293 - val_loss: 0.6492\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.6339 - loss: 0.6319 - val_accuracy: 0.6430 - val_loss: 0.6377\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.6345 - loss: 0.6354 - val_accuracy: 0.6178 - val_loss: 0.6499\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.6581 - loss: 0.6307 - val_accuracy: 0.6339 - val_loss: 0.6312\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.6390 - loss: 0.6295 - val_accuracy: 0.6499 - val_loss: 0.6180\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.6548 - loss: 0.6193 - val_accuracy: 0.6453 - val_loss: 0.6293\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.6568 - loss: 0.6169 - val_accuracy: 0.6430 - val_loss: 0.6180\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.6493 - loss: 0.6219 - val_accuracy: 0.6613 - val_loss: 0.6083\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6547 - loss: 0.6166 - val_accuracy: 0.6453 - val_loss: 0.6221\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.6681 - loss: 0.6119 - val_accuracy: 0.6522 - val_loss: 0.6120\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6676 - loss: 0.6105 - val_accuracy: 0.6407 - val_loss: 0.6236\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.6649 - loss: 0.6052 - val_accuracy: 0.6522 - val_loss: 0.6250\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6454 - loss: 0.6140 - val_accuracy: 0.6499 - val_loss: 0.6273\n",
      "Now running, pct_increase: 1.0; days out: 10; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6782 - loss: 0.5913 - val_accuracy: 0.6911 - val_loss: 0.6015\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6664 - loss: 0.6101 - val_accuracy: 0.6888 - val_loss: 0.6037\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6591 - loss: 0.6082 - val_accuracy: 0.6796 - val_loss: 0.6081\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6572 - loss: 0.6000 - val_accuracy: 0.6911 - val_loss: 0.5951\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.6497 - loss: 0.6043 - val_accuracy: 0.6613 - val_loss: 0.6125\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6581 - loss: 0.5974 - val_accuracy: 0.6865 - val_loss: 0.5978\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6666 - loss: 0.5930 - val_accuracy: 0.6865 - val_loss: 0.5960\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6882 - loss: 0.5791 - val_accuracy: 0.6728 - val_loss: 0.6231\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6553 - loss: 0.5856 - val_accuracy: 0.6659 - val_loss: 0.6010\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6695 - loss: 0.5855 - val_accuracy: 0.6728 - val_loss: 0.6109\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.6381 - loss: 0.6637 - val_accuracy: 0.6362 - val_loss: 0.6484\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6494 - loss: 0.6584 - val_accuracy: 0.6362 - val_loss: 0.6449\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6283 - loss: 0.6575 - val_accuracy: 0.6362 - val_loss: 0.6496\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6382 - loss: 0.6529 - val_accuracy: 0.6362 - val_loss: 0.6407\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6261 - loss: 0.6523 - val_accuracy: 0.6362 - val_loss: 0.6644\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6541 - loss: 0.6382 - val_accuracy: 0.6384 - val_loss: 0.6728\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6254 - loss: 0.6579 - val_accuracy: 0.6362 - val_loss: 0.6401\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6267 - loss: 0.6519 - val_accuracy: 0.6362 - val_loss: 0.6437\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6524 - loss: 0.6336 - val_accuracy: 0.6362 - val_loss: 0.6319\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6327 - loss: 0.6396 - val_accuracy: 0.6384 - val_loss: 0.6493\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6399 - loss: 0.6459 - val_accuracy: 0.6362 - val_loss: 0.6504\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6493 - loss: 0.6367 - val_accuracy: 0.6384 - val_loss: 0.6476\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.6438 - loss: 0.6356 - val_accuracy: 0.6430 - val_loss: 0.6360\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.6347 - loss: 0.6374 - val_accuracy: 0.6407 - val_loss: 0.6472\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.6654 - loss: 0.6312 - val_accuracy: 0.6407 - val_loss: 0.6393\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.6469 - loss: 0.6253 - val_accuracy: 0.6476 - val_loss: 0.6327\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.6315 - loss: 0.6214 - val_accuracy: 0.6362 - val_loss: 0.6404\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - accuracy: 0.6246 - loss: 0.6432 - val_accuracy: 0.6407 - val_loss: 0.6292\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - accuracy: 0.6443 - loss: 0.6271 - val_accuracy: 0.6339 - val_loss: 0.6218\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.6311 - loss: 0.6377 - val_accuracy: 0.6545 - val_loss: 0.6256\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.6344 - loss: 0.6365 - val_accuracy: 0.6522 - val_loss: 0.6136\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.6420 - loss: 0.6385 - val_accuracy: 0.6453 - val_loss: 0.6132\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.6344 - loss: 0.6271 - val_accuracy: 0.6384 - val_loss: 0.6238\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.6537 - loss: 0.6262 - val_accuracy: 0.6339 - val_loss: 0.6245\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.6352 - loss: 0.6322 - val_accuracy: 0.6407 - val_loss: 0.6099\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.6537 - loss: 0.6219 - val_accuracy: 0.6407 - val_loss: 0.6019\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.6561 - loss: 0.6218 - val_accuracy: 0.6476 - val_loss: 0.5998\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.6501 - loss: 0.6090 - val_accuracy: 0.6384 - val_loss: 0.6054\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.6885 - loss: 0.5969 - val_accuracy: 0.6156 - val_loss: 0.6125\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.6480 - loss: 0.6047 - val_accuracy: 0.6476 - val_loss: 0.6220\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.6707 - loss: 0.6044 - val_accuracy: 0.6568 - val_loss: 0.6025\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.6579 - loss: 0.6121 - val_accuracy: 0.6613 - val_loss: 0.5930\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.6508 - loss: 0.5973 - val_accuracy: 0.6682 - val_loss: 0.5954\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.6608 - loss: 0.6033 - val_accuracy: 0.6568 - val_loss: 0.6045\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.6916 - loss: 0.5710 - val_accuracy: 0.6568 - val_loss: 0.6047\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.6814 - loss: 0.5852 - val_accuracy: 0.6545 - val_loss: 0.6063\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6678 - loss: 0.5943 - val_accuracy: 0.6613 - val_loss: 0.5972\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6790 - loss: 0.5760 - val_accuracy: 0.6613 - val_loss: 0.5905\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6750 - loss: 0.5851 - val_accuracy: 0.6362 - val_loss: 0.6191\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6501 - loss: 0.6002 - val_accuracy: 0.6568 - val_loss: 0.6178\n",
      "Now running, pct_increase: 1.0; days out: 15; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6573 - loss: 0.5968 - val_accuracy: 0.6934 - val_loss: 0.5876\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6708 - loss: 0.5634 - val_accuracy: 0.6659 - val_loss: 0.6177\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6720 - loss: 0.5786 - val_accuracy: 0.6705 - val_loss: 0.6017\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6744 - loss: 0.5715 - val_accuracy: 0.6865 - val_loss: 0.6003\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6811 - loss: 0.5725 - val_accuracy: 0.6796 - val_loss: 0.6172\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6710 - loss: 0.5695 - val_accuracy: 0.6728 - val_loss: 0.6302\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6442 - loss: 0.5953 - val_accuracy: 0.6842 - val_loss: 0.6104\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.6962 - loss: 0.5663 - val_accuracy: 0.6705 - val_loss: 0.5988\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6953 - loss: 0.5494 - val_accuracy: 0.6705 - val_loss: 0.6160\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6741 - loss: 0.5624 - val_accuracy: 0.6156 - val_loss: 0.6329\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.7796 - loss: 0.4872 - val_accuracy: 0.8539 - val_loss: 0.4109\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8573 - loss: 0.4031 - val_accuracy: 0.8539 - val_loss: 0.3968\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8617 - loss: 0.3908 - val_accuracy: 0.8562 - val_loss: 0.3964\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8634 - loss: 0.3899 - val_accuracy: 0.8562 - val_loss: 0.3921\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.8611 - loss: 0.3836 - val_accuracy: 0.8539 - val_loss: 0.4006\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.8469 - loss: 0.4110 - val_accuracy: 0.8539 - val_loss: 0.3916\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8582 - loss: 0.3873 - val_accuracy: 0.8539 - val_loss: 0.3956\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8432 - loss: 0.4152 - val_accuracy: 0.8539 - val_loss: 0.3906\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8606 - loss: 0.3883 - val_accuracy: 0.8493 - val_loss: 0.3987\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.8475 - loss: 0.4062 - val_accuracy: 0.8493 - val_loss: 0.3874\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8409 - loss: 0.4186 - val_accuracy: 0.8539 - val_loss: 0.4043\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.8515 - loss: 0.3949 - val_accuracy: 0.8562 - val_loss: 0.3987\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8540 - loss: 0.3940 - val_accuracy: 0.8539 - val_loss: 0.4054\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.8596 - loss: 0.3876 - val_accuracy: 0.8539 - val_loss: 0.4045\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 94ms/step - accuracy: 0.8507 - loss: 0.3990 - val_accuracy: 0.8539 - val_loss: 0.4153\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.8523 - loss: 0.4061 - val_accuracy: 0.8562 - val_loss: 0.4140\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.8474 - loss: 0.3854 - val_accuracy: 0.8539 - val_loss: 0.4052\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.8660 - loss: 0.3609 - val_accuracy: 0.8562 - val_loss: 0.4048\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.8562 - loss: 0.3778 - val_accuracy: 0.8562 - val_loss: 0.4027\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8502 - loss: 0.3841 - val_accuracy: 0.8539 - val_loss: 0.4000\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.8519 - loss: 0.3843 - val_accuracy: 0.8539 - val_loss: 0.3908\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8586 - loss: 0.3800 - val_accuracy: 0.8539 - val_loss: 0.3888\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.8675 - loss: 0.3677 - val_accuracy: 0.8539 - val_loss: 0.3895\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.8618 - loss: 0.3765 - val_accuracy: 0.8539 - val_loss: 0.3889\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.8540 - loss: 0.3786 - val_accuracy: 0.8493 - val_loss: 0.3930\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.8620 - loss: 0.3728 - val_accuracy: 0.8539 - val_loss: 0.3905\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.8483 - loss: 0.3857 - val_accuracy: 0.8516 - val_loss: 0.3918\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.8511 - loss: 0.3955 - val_accuracy: 0.8562 - val_loss: 0.3922\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.8679 - loss: 0.3701 - val_accuracy: 0.8470 - val_loss: 0.3996\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8516 - loss: 0.3777 - val_accuracy: 0.8539 - val_loss: 0.3915\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8654 - loss: 0.3711 - val_accuracy: 0.8584 - val_loss: 0.3618\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.8450 - loss: 0.4180 - val_accuracy: 0.8630 - val_loss: 0.3634\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.8479 - loss: 0.4061 - val_accuracy: 0.8607 - val_loss: 0.3654\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8568 - loss: 0.3749 - val_accuracy: 0.8584 - val_loss: 0.3691\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.8555 - loss: 0.3871 - val_accuracy: 0.8607 - val_loss: 0.3673\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8572 - loss: 0.3733 - val_accuracy: 0.8584 - val_loss: 0.3709\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.8486 - loss: 0.3912 - val_accuracy: 0.8607 - val_loss: 0.3695\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8473 - loss: 0.4044 - val_accuracy: 0.8607 - val_loss: 0.3679\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8440 - loss: 0.3880 - val_accuracy: 0.8584 - val_loss: 0.3752\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8672 - loss: 0.3705 - val_accuracy: 0.8562 - val_loss: 0.3712\n",
      "Now running, pct_increase: 1.01; days out: 1; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8552 - loss: 0.3800 - val_accuracy: 0.8535 - val_loss: 0.3890\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8643 - loss: 0.3660 - val_accuracy: 0.8558 - val_loss: 0.3834\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8674 - loss: 0.3632 - val_accuracy: 0.8513 - val_loss: 0.3844\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8599 - loss: 0.3664 - val_accuracy: 0.8513 - val_loss: 0.3879\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8606 - loss: 0.3718 - val_accuracy: 0.8604 - val_loss: 0.3854\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8587 - loss: 0.3852 - val_accuracy: 0.8604 - val_loss: 0.3862\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8657 - loss: 0.3616 - val_accuracy: 0.8535 - val_loss: 0.3900\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8625 - loss: 0.3737 - val_accuracy: 0.8513 - val_loss: 0.3931\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8485 - loss: 0.3843 - val_accuracy: 0.8535 - val_loss: 0.3992\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8523 - loss: 0.3814 - val_accuracy: 0.8490 - val_loss: 0.3978\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7132 - loss: 0.6077 - val_accuracy: 0.7215 - val_loss: 0.5856\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.7120 - loss: 0.5978 - val_accuracy: 0.7260 - val_loss: 0.5850\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7046 - loss: 0.6058 - val_accuracy: 0.7215 - val_loss: 0.5827\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7100 - loss: 0.6011 - val_accuracy: 0.7215 - val_loss: 0.5847\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7077 - loss: 0.6101 - val_accuracy: 0.7215 - val_loss: 0.5834\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.7219 - loss: 0.5840 - val_accuracy: 0.7215 - val_loss: 0.5826\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.7215 - loss: 0.5781 - val_accuracy: 0.7215 - val_loss: 0.5832\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7272 - loss: 0.5763 - val_accuracy: 0.7215 - val_loss: 0.5835\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.7365 - loss: 0.5712 - val_accuracy: 0.7215 - val_loss: 0.5828\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7150 - loss: 0.5940 - val_accuracy: 0.7215 - val_loss: 0.5822\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7107 - loss: 0.5892 - val_accuracy: 0.7215 - val_loss: 0.5781\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7190 - loss: 0.5877 - val_accuracy: 0.7237 - val_loss: 0.5788\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7287 - loss: 0.5712 - val_accuracy: 0.7215 - val_loss: 0.5860\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.7220 - loss: 0.5789 - val_accuracy: 0.7215 - val_loss: 0.5810\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7200 - loss: 0.5887 - val_accuracy: 0.7237 - val_loss: 0.5816\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7274 - loss: 0.5788 - val_accuracy: 0.7215 - val_loss: 0.5830\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7218 - loss: 0.5731 - val_accuracy: 0.7215 - val_loss: 0.5830\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7215 - loss: 0.5792 - val_accuracy: 0.7237 - val_loss: 0.5795\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.7221 - loss: 0.5740 - val_accuracy: 0.7237 - val_loss: 0.5779\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - accuracy: 0.7296 - loss: 0.5660 - val_accuracy: 0.7215 - val_loss: 0.5803\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.7398 - loss: 0.5520 - val_accuracy: 0.7208 - val_loss: 0.5784\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.7295 - loss: 0.5675 - val_accuracy: 0.7185 - val_loss: 0.5878\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 0.7312 - loss: 0.5686 - val_accuracy: 0.7185 - val_loss: 0.5812\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.7224 - loss: 0.5749 - val_accuracy: 0.7208 - val_loss: 0.5897\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.7288 - loss: 0.5654 - val_accuracy: 0.7208 - val_loss: 0.5819\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7251 - loss: 0.5690 - val_accuracy: 0.6979 - val_loss: 0.6014\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.7229 - loss: 0.5703 - val_accuracy: 0.7208 - val_loss: 0.5871\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.7265 - loss: 0.5642 - val_accuracy: 0.7002 - val_loss: 0.6039\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.7271 - loss: 0.5708 - val_accuracy: 0.6957 - val_loss: 0.5982\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.7199 - loss: 0.5641 - val_accuracy: 0.7117 - val_loss: 0.6007\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.7062 - loss: 0.5867 - val_accuracy: 0.7208 - val_loss: 0.5605\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.7265 - loss: 0.5705 - val_accuracy: 0.7368 - val_loss: 0.5472\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.7100 - loss: 0.5830 - val_accuracy: 0.7391 - val_loss: 0.5407\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7304 - loss: 0.5564 - val_accuracy: 0.7368 - val_loss: 0.5503\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.7442 - loss: 0.5544 - val_accuracy: 0.7391 - val_loss: 0.5510\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7255 - loss: 0.5633 - val_accuracy: 0.7414 - val_loss: 0.5485\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7203 - loss: 0.5730 - val_accuracy: 0.7437 - val_loss: 0.5503\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7415 - loss: 0.5530 - val_accuracy: 0.7368 - val_loss: 0.5520\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.7353 - loss: 0.5599 - val_accuracy: 0.7208 - val_loss: 0.5619\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7272 - loss: 0.5676 - val_accuracy: 0.7323 - val_loss: 0.5765\n",
      "Now running, pct_increase: 1.01; days out: 3; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7090 - loss: 0.6003 - val_accuracy: 0.7277 - val_loss: 0.5534\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7104 - loss: 0.5821 - val_accuracy: 0.7208 - val_loss: 0.5585\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7320 - loss: 0.5624 - val_accuracy: 0.7185 - val_loss: 0.5675\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7425 - loss: 0.5435 - val_accuracy: 0.7117 - val_loss: 0.5711\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7353 - loss: 0.5384 - val_accuracy: 0.7140 - val_loss: 0.5671\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7456 - loss: 0.5409 - val_accuracy: 0.7094 - val_loss: 0.5685\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7428 - loss: 0.5487 - val_accuracy: 0.6865 - val_loss: 0.5967\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7578 - loss: 0.5291 - val_accuracy: 0.7094 - val_loss: 0.5816\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7482 - loss: 0.5298 - val_accuracy: 0.7162 - val_loss: 0.5612\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7366 - loss: 0.5313 - val_accuracy: 0.6934 - val_loss: 0.6011\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6005 - loss: 0.6756 - val_accuracy: 0.6370 - val_loss: 0.6490\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.6172 - loss: 0.6624 - val_accuracy: 0.6393 - val_loss: 0.6546\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6254 - loss: 0.6625 - val_accuracy: 0.6393 - val_loss: 0.6514\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6432 - loss: 0.6473 - val_accuracy: 0.6370 - val_loss: 0.6465\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.6174 - loss: 0.6613 - val_accuracy: 0.6393 - val_loss: 0.6550\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6498 - loss: 0.6416 - val_accuracy: 0.6393 - val_loss: 0.6472\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.6372 - loss: 0.6490 - val_accuracy: 0.6393 - val_loss: 0.6509\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6512 - loss: 0.6413 - val_accuracy: 0.6370 - val_loss: 0.6486\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6442 - loss: 0.6470 - val_accuracy: 0.6393 - val_loss: 0.6511\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6463 - loss: 0.6441 - val_accuracy: 0.6370 - val_loss: 0.6504\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6395 - loss: 0.6480 - val_accuracy: 0.6270 - val_loss: 0.6584\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6431 - loss: 0.6453 - val_accuracy: 0.6339 - val_loss: 0.6501\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6574 - loss: 0.6428 - val_accuracy: 0.6384 - val_loss: 0.6567\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6605 - loss: 0.6373 - val_accuracy: 0.6178 - val_loss: 0.6523\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6467 - loss: 0.6456 - val_accuracy: 0.6156 - val_loss: 0.6546\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6492 - loss: 0.6375 - val_accuracy: 0.6270 - val_loss: 0.6555\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.6590 - loss: 0.6399 - val_accuracy: 0.6110 - val_loss: 0.6637\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.6472 - loss: 0.6453 - val_accuracy: 0.6201 - val_loss: 0.6662\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.6385 - loss: 0.6521 - val_accuracy: 0.6224 - val_loss: 0.6593\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.6575 - loss: 0.6416 - val_accuracy: 0.6407 - val_loss: 0.6497\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.6437 - loss: 0.6477 - val_accuracy: 0.6430 - val_loss: 0.6415\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6794 - loss: 0.6241 - val_accuracy: 0.6728 - val_loss: 0.6440\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6483 - loss: 0.6401 - val_accuracy: 0.6293 - val_loss: 0.6448\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.6526 - loss: 0.6428 - val_accuracy: 0.6590 - val_loss: 0.6415\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.6619 - loss: 0.6366 - val_accuracy: 0.6476 - val_loss: 0.6425\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.6568 - loss: 0.6332 - val_accuracy: 0.6590 - val_loss: 0.6423\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.6499 - loss: 0.6381 - val_accuracy: 0.6384 - val_loss: 0.6493\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.6372 - loss: 0.6472 - val_accuracy: 0.6522 - val_loss: 0.6476\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.6597 - loss: 0.6368 - val_accuracy: 0.6407 - val_loss: 0.6588\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.6514 - loss: 0.6389 - val_accuracy: 0.6568 - val_loss: 0.6487\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.6469 - loss: 0.6425 - val_accuracy: 0.7025 - val_loss: 0.6049\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.6459 - loss: 0.6425 - val_accuracy: 0.6796 - val_loss: 0.6146\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6535 - loss: 0.6377 - val_accuracy: 0.6613 - val_loss: 0.6355\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.6739 - loss: 0.6217 - val_accuracy: 0.6728 - val_loss: 0.6186\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.6562 - loss: 0.6363 - val_accuracy: 0.6659 - val_loss: 0.6269\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.6703 - loss: 0.6263 - val_accuracy: 0.6613 - val_loss: 0.6364\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6797 - loss: 0.6163 - val_accuracy: 0.6957 - val_loss: 0.6183\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.6799 - loss: 0.6169 - val_accuracy: 0.6979 - val_loss: 0.6154\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.6534 - loss: 0.6228 - val_accuracy: 0.6613 - val_loss: 0.6243\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.6627 - loss: 0.6260 - val_accuracy: 0.6682 - val_loss: 0.6230\n",
      "Now running, pct_increase: 1.01; days out: 5; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.6791 - loss: 0.6186 - val_accuracy: 0.6659 - val_loss: 0.6274\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.6839 - loss: 0.6036 - val_accuracy: 0.6545 - val_loss: 0.6264\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.6603 - loss: 0.6188 - val_accuracy: 0.6636 - val_loss: 0.6263\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6764 - loss: 0.6087 - val_accuracy: 0.6453 - val_loss: 0.6466\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6859 - loss: 0.6044 - val_accuracy: 0.6705 - val_loss: 0.6254\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6749 - loss: 0.6080 - val_accuracy: 0.6453 - val_loss: 0.6362\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6777 - loss: 0.6007 - val_accuracy: 0.6590 - val_loss: 0.6401\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6783 - loss: 0.6071 - val_accuracy: 0.6613 - val_loss: 0.6222\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6824 - loss: 0.5983 - val_accuracy: 0.6568 - val_loss: 0.6310\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6995 - loss: 0.5878 - val_accuracy: 0.6522 - val_loss: 0.6336\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.5340 - loss: 0.7088 - val_accuracy: 0.5515 - val_loss: 0.6919\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.5699 - loss: 0.6843 - val_accuracy: 0.5057 - val_loss: 0.6932\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5442 - loss: 0.6878 - val_accuracy: 0.4943 - val_loss: 0.6917\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5501 - loss: 0.6863 - val_accuracy: 0.5080 - val_loss: 0.6974\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5396 - loss: 0.6860 - val_accuracy: 0.5011 - val_loss: 0.6994\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.5438 - loss: 0.6911 - val_accuracy: 0.5126 - val_loss: 0.6951\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5881 - loss: 0.6781 - val_accuracy: 0.5149 - val_loss: 0.6903\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5865 - loss: 0.6763 - val_accuracy: 0.5217 - val_loss: 0.6950\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.5679 - loss: 0.6785 - val_accuracy: 0.5149 - val_loss: 0.6908\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.5915 - loss: 0.6717 - val_accuracy: 0.5126 - val_loss: 0.6901\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.5992 - loss: 0.6716 - val_accuracy: 0.5767 - val_loss: 0.6673\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.5836 - loss: 0.6728 - val_accuracy: 0.5309 - val_loss: 0.6869\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5622 - loss: 0.6802 - val_accuracy: 0.6201 - val_loss: 0.6715\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.6056 - loss: 0.6603 - val_accuracy: 0.5927 - val_loss: 0.6822\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.5742 - loss: 0.6763 - val_accuracy: 0.5561 - val_loss: 0.6782\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.6064 - loss: 0.6630 - val_accuracy: 0.5858 - val_loss: 0.6769\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6074 - loss: 0.6562 - val_accuracy: 0.5927 - val_loss: 0.6706\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.6104 - loss: 0.6571 - val_accuracy: 0.6293 - val_loss: 0.6646\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - accuracy: 0.5869 - loss: 0.6646 - val_accuracy: 0.5881 - val_loss: 0.6798\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6276 - loss: 0.6385 - val_accuracy: 0.6110 - val_loss: 0.6698\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.5990 - loss: 0.6574 - val_accuracy: 0.5973 - val_loss: 0.6441\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.6217 - loss: 0.6524 - val_accuracy: 0.5973 - val_loss: 0.6534\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.6048 - loss: 0.6596 - val_accuracy: 0.6156 - val_loss: 0.6458\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.6290 - loss: 0.6439 - val_accuracy: 0.5995 - val_loss: 0.6558\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.6387 - loss: 0.6375 - val_accuracy: 0.5835 - val_loss: 0.6592\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.6031 - loss: 0.6484 - val_accuracy: 0.6018 - val_loss: 0.6587\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.6163 - loss: 0.6546 - val_accuracy: 0.6133 - val_loss: 0.6565\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.6346 - loss: 0.6373 - val_accuracy: 0.6087 - val_loss: 0.6547\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.6320 - loss: 0.6424 - val_accuracy: 0.6110 - val_loss: 0.6545\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.6217 - loss: 0.6329 - val_accuracy: 0.6041 - val_loss: 0.6556\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.5972 - loss: 0.6533 - val_accuracy: 0.6339 - val_loss: 0.6316\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.6528 - loss: 0.6266 - val_accuracy: 0.6476 - val_loss: 0.6228\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.6444 - loss: 0.6311 - val_accuracy: 0.6201 - val_loss: 0.6400\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.6545 - loss: 0.6144 - val_accuracy: 0.6499 - val_loss: 0.6244\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.6316 - loss: 0.6387 - val_accuracy: 0.6362 - val_loss: 0.6341\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.6394 - loss: 0.6373 - val_accuracy: 0.6636 - val_loss: 0.6199\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.6589 - loss: 0.6089 - val_accuracy: 0.6178 - val_loss: 0.6388\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.6680 - loss: 0.6077 - val_accuracy: 0.6293 - val_loss: 0.6319\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.6781 - loss: 0.6079 - val_accuracy: 0.6476 - val_loss: 0.6245\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6685 - loss: 0.6027 - val_accuracy: 0.6590 - val_loss: 0.6245\n",
      "Now running, pct_increase: 1.01; days out: 10; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.6570 - loss: 0.6216 - val_accuracy: 0.6476 - val_loss: 0.6126\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6422 - loss: 0.6118 - val_accuracy: 0.6545 - val_loss: 0.6178\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6676 - loss: 0.6126 - val_accuracy: 0.6636 - val_loss: 0.6070\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.6763 - loss: 0.5877 - val_accuracy: 0.5973 - val_loss: 0.6573\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6418 - loss: 0.6030 - val_accuracy: 0.6407 - val_loss: 0.6275\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6819 - loss: 0.5831 - val_accuracy: 0.6453 - val_loss: 0.6133\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.6763 - loss: 0.5745 - val_accuracy: 0.6430 - val_loss: 0.6194\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.6945 - loss: 0.5675 - val_accuracy: 0.6178 - val_loss: 0.6371\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6683 - loss: 0.5832 - val_accuracy: 0.6407 - val_loss: 0.6248\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.6898 - loss: 0.5464 - val_accuracy: 0.6728 - val_loss: 0.6038\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.5054 - loss: 0.7049 - val_accuracy: 0.5172 - val_loss: 0.6907\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.4985 - loss: 0.6967 - val_accuracy: 0.5080 - val_loss: 0.6913\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.5082 - loss: 0.6971 - val_accuracy: 0.5263 - val_loss: 0.6885\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5215 - loss: 0.6908 - val_accuracy: 0.5400 - val_loss: 0.6886\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5394 - loss: 0.6863 - val_accuracy: 0.5149 - val_loss: 0.6922\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.5293 - loss: 0.6925 - val_accuracy: 0.5584 - val_loss: 0.6885\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5110 - loss: 0.6903 - val_accuracy: 0.5103 - val_loss: 0.6869\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5376 - loss: 0.6805 - val_accuracy: 0.5309 - val_loss: 0.6844\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5259 - loss: 0.6809 - val_accuracy: 0.5309 - val_loss: 0.6857\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.5545 - loss: 0.6788 - val_accuracy: 0.5698 - val_loss: 0.6789\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.5609 - loss: 0.6767 - val_accuracy: 0.5858 - val_loss: 0.6650\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.5376 - loss: 0.6753 - val_accuracy: 0.5950 - val_loss: 0.6679\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5688 - loss: 0.6723 - val_accuracy: 0.5423 - val_loss: 0.6786\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.5626 - loss: 0.6694 - val_accuracy: 0.5789 - val_loss: 0.6696\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5500 - loss: 0.6746 - val_accuracy: 0.5789 - val_loss: 0.6562\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.5923 - loss: 0.6653 - val_accuracy: 0.5675 - val_loss: 0.6754\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.5740 - loss: 0.6620 - val_accuracy: 0.6018 - val_loss: 0.6651\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5858 - loss: 0.6574 - val_accuracy: 0.5309 - val_loss: 0.6912\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5299 - loss: 0.6715 - val_accuracy: 0.6018 - val_loss: 0.6704\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5651 - loss: 0.6626 - val_accuracy: 0.5629 - val_loss: 0.6701\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.5687 - loss: 0.6610 - val_accuracy: 0.6201 - val_loss: 0.6389\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5880 - loss: 0.6555 - val_accuracy: 0.6087 - val_loss: 0.6405\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.5838 - loss: 0.6490 - val_accuracy: 0.5698 - val_loss: 0.6691\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.5820 - loss: 0.6677 - val_accuracy: 0.6133 - val_loss: 0.6448\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.5932 - loss: 0.6516 - val_accuracy: 0.5767 - val_loss: 0.6631\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.5955 - loss: 0.6572 - val_accuracy: 0.6224 - val_loss: 0.6439\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.6109 - loss: 0.6465 - val_accuracy: 0.6156 - val_loss: 0.6364\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.6309 - loss: 0.6373 - val_accuracy: 0.6064 - val_loss: 0.6426\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.6082 - loss: 0.6430 - val_accuracy: 0.6247 - val_loss: 0.6394\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.6391 - loss: 0.6236 - val_accuracy: 0.6041 - val_loss: 0.6488\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.6044 - loss: 0.6399 - val_accuracy: 0.6293 - val_loss: 0.6204\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.6279 - loss: 0.6243 - val_accuracy: 0.6178 - val_loss: 0.6330\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.6276 - loss: 0.6291 - val_accuracy: 0.5973 - val_loss: 0.6327\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.6448 - loss: 0.6149 - val_accuracy: 0.6407 - val_loss: 0.6248\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.6397 - loss: 0.6194 - val_accuracy: 0.6247 - val_loss: 0.6180\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.6419 - loss: 0.6102 - val_accuracy: 0.6522 - val_loss: 0.6142\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6458 - loss: 0.6123 - val_accuracy: 0.5995 - val_loss: 0.6540\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.6366 - loss: 0.6242 - val_accuracy: 0.6362 - val_loss: 0.6212\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.6402 - loss: 0.6106 - val_accuracy: 0.6293 - val_loss: 0.6287\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.6617 - loss: 0.5890 - val_accuracy: 0.6110 - val_loss: 0.6426\n",
      "Now running, pct_increase: 1.01; days out: 15; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.6587 - loss: 0.6051 - val_accuracy: 0.6751 - val_loss: 0.5907\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.6548 - loss: 0.6019 - val_accuracy: 0.6522 - val_loss: 0.5857\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6678 - loss: 0.5888 - val_accuracy: 0.6453 - val_loss: 0.5842\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.6473 - loss: 0.5820 - val_accuracy: 0.6751 - val_loss: 0.5929\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.6704 - loss: 0.5844 - val_accuracy: 0.6773 - val_loss: 0.5985\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6867 - loss: 0.5778 - val_accuracy: 0.6934 - val_loss: 0.5770\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.6640 - loss: 0.5721 - val_accuracy: 0.6705 - val_loss: 0.5927\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.6780 - loss: 0.5789 - val_accuracy: 0.6819 - val_loss: 0.5704\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6607 - loss: 0.5874 - val_accuracy: 0.6476 - val_loss: 0.5783\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6873 - loss: 0.5726 - val_accuracy: 0.6568 - val_loss: 0.5750\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.8981 - loss: 0.2653 - val_accuracy: 0.9703 - val_loss: 0.1295\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9720 - loss: 0.1297 - val_accuracy: 0.9703 - val_loss: 0.1181\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9703 - loss: 0.1282 - val_accuracy: 0.9703 - val_loss: 0.1107\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9730 - loss: 0.1163 - val_accuracy: 0.9703 - val_loss: 0.1097\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9674 - loss: 0.1371 - val_accuracy: 0.9703 - val_loss: 0.1138\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9671 - loss: 0.1298 - val_accuracy: 0.9703 - val_loss: 0.1090\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9684 - loss: 0.1298 - val_accuracy: 0.9703 - val_loss: 0.1058\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9661 - loss: 0.1338 - val_accuracy: 0.9703 - val_loss: 0.1085\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9693 - loss: 0.1241 - val_accuracy: 0.9703 - val_loss: 0.1180\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9741 - loss: 0.1076 - val_accuracy: 0.9703 - val_loss: 0.1086\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9687 - loss: 0.1207 - val_accuracy: 0.9703 - val_loss: 0.1205\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9661 - loss: 0.1219 - val_accuracy: 0.9703 - val_loss: 0.1275\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9676 - loss: 0.1251 - val_accuracy: 0.9703 - val_loss: 0.1184\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9757 - loss: 0.1044 - val_accuracy: 0.9703 - val_loss: 0.1205\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9636 - loss: 0.1296 - val_accuracy: 0.9703 - val_loss: 0.1206\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9705 - loss: 0.1122 - val_accuracy: 0.9703 - val_loss: 0.1208\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9689 - loss: 0.1188 - val_accuracy: 0.9703 - val_loss: 0.1311\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9696 - loss: 0.1205 - val_accuracy: 0.9703 - val_loss: 0.1192\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9685 - loss: 0.1078 - val_accuracy: 0.9703 - val_loss: 0.1172\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9712 - loss: 0.1078 - val_accuracy: 0.9703 - val_loss: 0.1183\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9699 - loss: 0.1118 - val_accuracy: 0.9703 - val_loss: 0.1040\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9630 - loss: 0.1294 - val_accuracy: 0.9703 - val_loss: 0.1083\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9718 - loss: 0.1062 - val_accuracy: 0.9703 - val_loss: 0.1047\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9702 - loss: 0.1064 - val_accuracy: 0.9703 - val_loss: 0.1052\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9686 - loss: 0.1120 - val_accuracy: 0.9703 - val_loss: 0.1062\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9722 - loss: 0.1048 - val_accuracy: 0.9703 - val_loss: 0.1079\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9592 - loss: 0.1340 - val_accuracy: 0.9703 - val_loss: 0.1060\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.9716 - loss: 0.1060 - val_accuracy: 0.9703 - val_loss: 0.1069\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.9679 - loss: 0.1195 - val_accuracy: 0.9703 - val_loss: 0.1061\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.9674 - loss: 0.1131 - val_accuracy: 0.9703 - val_loss: 0.1049\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.9728 - loss: 0.0941 - val_accuracy: 0.9680 - val_loss: 0.1193\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.9663 - loss: 0.1033 - val_accuracy: 0.9658 - val_loss: 0.1308\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.9647 - loss: 0.1197 - val_accuracy: 0.9658 - val_loss: 0.1273\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.9743 - loss: 0.0863 - val_accuracy: 0.9658 - val_loss: 0.1259\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.9674 - loss: 0.1027 - val_accuracy: 0.9658 - val_loss: 0.1326\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.9730 - loss: 0.0958 - val_accuracy: 0.9658 - val_loss: 0.1274\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9674 - loss: 0.1036 - val_accuracy: 0.9680 - val_loss: 0.1288\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.9720 - loss: 0.0974 - val_accuracy: 0.9658 - val_loss: 0.1366\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.9742 - loss: 0.0958 - val_accuracy: 0.9680 - val_loss: 0.1322\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.9686 - loss: 0.0959 - val_accuracy: 0.9658 - val_loss: 0.1310\n",
      "Now running, pct_increase: 1.02; days out: 1; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9760 - loss: 0.0929 - val_accuracy: 0.9725 - val_loss: 0.0979\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9689 - loss: 0.1082 - val_accuracy: 0.9725 - val_loss: 0.0929\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9700 - loss: 0.1024 - val_accuracy: 0.9725 - val_loss: 0.0947\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9657 - loss: 0.1052 - val_accuracy: 0.9703 - val_loss: 0.0911\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9703 - loss: 0.0943 - val_accuracy: 0.9703 - val_loss: 0.0921\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.9678 - loss: 0.1085 - val_accuracy: 0.9703 - val_loss: 0.0993\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.9710 - loss: 0.0906 - val_accuracy: 0.9703 - val_loss: 0.0916\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.9770 - loss: 0.0827 - val_accuracy: 0.9703 - val_loss: 0.0938\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9737 - loss: 0.0873 - val_accuracy: 0.9680 - val_loss: 0.0963\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.9738 - loss: 0.0923 - val_accuracy: 0.9703 - val_loss: 0.0920\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.8883 - loss: 0.3802 - val_accuracy: 0.8881 - val_loss: 0.3406\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8957 - loss: 0.3192 - val_accuracy: 0.8881 - val_loss: 0.3387\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8772 - loss: 0.3444 - val_accuracy: 0.8881 - val_loss: 0.3409\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8918 - loss: 0.3181 - val_accuracy: 0.8881 - val_loss: 0.3466\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8809 - loss: 0.3351 - val_accuracy: 0.8881 - val_loss: 0.3409\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8918 - loss: 0.3279 - val_accuracy: 0.8881 - val_loss: 0.3477\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8881 - loss: 0.3301 - val_accuracy: 0.8881 - val_loss: 0.3437\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8889 - loss: 0.3224 - val_accuracy: 0.8881 - val_loss: 0.3519\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8809 - loss: 0.3439 - val_accuracy: 0.8881 - val_loss: 0.3391\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8876 - loss: 0.3342 - val_accuracy: 0.8881 - val_loss: 0.3448\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8865 - loss: 0.3231 - val_accuracy: 0.8881 - val_loss: 0.3323\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8780 - loss: 0.3497 - val_accuracy: 0.8881 - val_loss: 0.3300\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8863 - loss: 0.3195 - val_accuracy: 0.8881 - val_loss: 0.3239\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8872 - loss: 0.3285 - val_accuracy: 0.8881 - val_loss: 0.3336\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8935 - loss: 0.3196 - val_accuracy: 0.8881 - val_loss: 0.3296\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8864 - loss: 0.3357 - val_accuracy: 0.8881 - val_loss: 0.3237\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8804 - loss: 0.3344 - val_accuracy: 0.8881 - val_loss: 0.3355\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8933 - loss: 0.3227 - val_accuracy: 0.8881 - val_loss: 0.3332\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8897 - loss: 0.3115 - val_accuracy: 0.8881 - val_loss: 0.3214\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.8961 - loss: 0.2912 - val_accuracy: 0.8881 - val_loss: 0.3204\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8903 - loss: 0.3113 - val_accuracy: 0.8902 - val_loss: 0.3320\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.8906 - loss: 0.3009 - val_accuracy: 0.8902 - val_loss: 0.3382\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8863 - loss: 0.3255 - val_accuracy: 0.8902 - val_loss: 0.3318\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8965 - loss: 0.2907 - val_accuracy: 0.8902 - val_loss: 0.3308\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8992 - loss: 0.2955 - val_accuracy: 0.8902 - val_loss: 0.3320\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8840 - loss: 0.3113 - val_accuracy: 0.8902 - val_loss: 0.3342\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8975 - loss: 0.2791 - val_accuracy: 0.8902 - val_loss: 0.3354\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8913 - loss: 0.3023 - val_accuracy: 0.8902 - val_loss: 0.3359\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8916 - loss: 0.3063 - val_accuracy: 0.8902 - val_loss: 0.3308\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.8989 - loss: 0.2763 - val_accuracy: 0.8902 - val_loss: 0.3282\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8924 - loss: 0.3081 - val_accuracy: 0.8924 - val_loss: 0.2864\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8809 - loss: 0.3307 - val_accuracy: 0.8902 - val_loss: 0.2840\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8849 - loss: 0.3245 - val_accuracy: 0.8947 - val_loss: 0.2818\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.8998 - loss: 0.3052 - val_accuracy: 0.8970 - val_loss: 0.2905\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8894 - loss: 0.3199 - val_accuracy: 0.8947 - val_loss: 0.2879\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.8904 - loss: 0.3168 - val_accuracy: 0.8993 - val_loss: 0.2883\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8954 - loss: 0.2895 - val_accuracy: 0.8924 - val_loss: 0.2912\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.8855 - loss: 0.3111 - val_accuracy: 0.8970 - val_loss: 0.2837\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.8905 - loss: 0.3078 - val_accuracy: 0.8902 - val_loss: 0.2968\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8959 - loss: 0.2936 - val_accuracy: 0.9039 - val_loss: 0.2976\n",
      "Now running, pct_increase: 1.02; days out: 3; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.8942 - loss: 0.3084 - val_accuracy: 0.8970 - val_loss: 0.2635\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.9051 - loss: 0.2812 - val_accuracy: 0.9016 - val_loss: 0.2694\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9023 - loss: 0.2941 - val_accuracy: 0.9016 - val_loss: 0.2665\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9164 - loss: 0.2634 - val_accuracy: 0.9062 - val_loss: 0.2624\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9055 - loss: 0.2905 - val_accuracy: 0.9062 - val_loss: 0.2639\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.8777 - loss: 0.3289 - val_accuracy: 0.8993 - val_loss: 0.2809\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.8843 - loss: 0.3143 - val_accuracy: 0.9062 - val_loss: 0.2731\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.8868 - loss: 0.3157 - val_accuracy: 0.8993 - val_loss: 0.2820\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.9045 - loss: 0.2893 - val_accuracy: 0.8970 - val_loss: 0.2750\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9096 - loss: 0.2716 - val_accuracy: 0.8993 - val_loss: 0.2806\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.8427 - loss: 0.4823 - val_accuracy: 0.8333 - val_loss: 0.4301\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8293 - loss: 0.4393 - val_accuracy: 0.8333 - val_loss: 0.4267\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8364 - loss: 0.4388 - val_accuracy: 0.8333 - val_loss: 0.4273\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8482 - loss: 0.3977 - val_accuracy: 0.8333 - val_loss: 0.4291\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8257 - loss: 0.4405 - val_accuracy: 0.8333 - val_loss: 0.4274\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8384 - loss: 0.4257 - val_accuracy: 0.8333 - val_loss: 0.4419\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8248 - loss: 0.4401 - val_accuracy: 0.8333 - val_loss: 0.4305\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8371 - loss: 0.4254 - val_accuracy: 0.8333 - val_loss: 0.4303\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8287 - loss: 0.4393 - val_accuracy: 0.8311 - val_loss: 0.4262\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8345 - loss: 0.4249 - val_accuracy: 0.8333 - val_loss: 0.4368\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8383 - loss: 0.4211 - val_accuracy: 0.8398 - val_loss: 0.4267\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8481 - loss: 0.3990 - val_accuracy: 0.8375 - val_loss: 0.4205\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8358 - loss: 0.4212 - val_accuracy: 0.8398 - val_loss: 0.4119\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8311 - loss: 0.4269 - val_accuracy: 0.8398 - val_loss: 0.4220\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8137 - loss: 0.4461 - val_accuracy: 0.8375 - val_loss: 0.4180\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.8485 - loss: 0.3929 - val_accuracy: 0.8375 - val_loss: 0.4139\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8207 - loss: 0.4315 - val_accuracy: 0.8375 - val_loss: 0.4196\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8286 - loss: 0.4121 - val_accuracy: 0.8375 - val_loss: 0.4126\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8361 - loss: 0.3974 - val_accuracy: 0.8375 - val_loss: 0.4236\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8354 - loss: 0.4090 - val_accuracy: 0.8352 - val_loss: 0.4142\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8538 - loss: 0.3817 - val_accuracy: 0.8375 - val_loss: 0.4296\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8314 - loss: 0.4232 - val_accuracy: 0.8352 - val_loss: 0.4290\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8472 - loss: 0.3904 - val_accuracy: 0.8375 - val_loss: 0.4169\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.8346 - loss: 0.4020 - val_accuracy: 0.8375 - val_loss: 0.4219\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8419 - loss: 0.3924 - val_accuracy: 0.8101 - val_loss: 0.4394\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.8325 - loss: 0.4082 - val_accuracy: 0.8352 - val_loss: 0.4134\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8385 - loss: 0.4057 - val_accuracy: 0.8375 - val_loss: 0.4278\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8349 - loss: 0.4104 - val_accuracy: 0.8284 - val_loss: 0.4243\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8409 - loss: 0.3880 - val_accuracy: 0.8352 - val_loss: 0.4173\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.8481 - loss: 0.3927 - val_accuracy: 0.8261 - val_loss: 0.4297\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8320 - loss: 0.4242 - val_accuracy: 0.8444 - val_loss: 0.3728\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8439 - loss: 0.3930 - val_accuracy: 0.8513 - val_loss: 0.3672\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8577 - loss: 0.3728 - val_accuracy: 0.8490 - val_loss: 0.3748\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8478 - loss: 0.3953 - val_accuracy: 0.8535 - val_loss: 0.3767\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8530 - loss: 0.3654 - val_accuracy: 0.8444 - val_loss: 0.3840\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.8359 - loss: 0.4054 - val_accuracy: 0.8467 - val_loss: 0.3813\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.8481 - loss: 0.3849 - val_accuracy: 0.8513 - val_loss: 0.3919\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8382 - loss: 0.4072 - val_accuracy: 0.8444 - val_loss: 0.3764\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8444 - loss: 0.3981 - val_accuracy: 0.8467 - val_loss: 0.3849\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.8290 - loss: 0.4261 - val_accuracy: 0.8444 - val_loss: 0.4011\n",
      "Now running, pct_increase: 1.02; days out: 5; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8394 - loss: 0.4026 - val_accuracy: 0.8444 - val_loss: 0.3821\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.8383 - loss: 0.4016 - val_accuracy: 0.8490 - val_loss: 0.3757\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.8507 - loss: 0.3907 - val_accuracy: 0.8467 - val_loss: 0.3845\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.8559 - loss: 0.3545 - val_accuracy: 0.8513 - val_loss: 0.3908\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.8483 - loss: 0.3816 - val_accuracy: 0.8513 - val_loss: 0.3723\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8581 - loss: 0.3640 - val_accuracy: 0.8627 - val_loss: 0.3766\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8644 - loss: 0.3566 - val_accuracy: 0.8604 - val_loss: 0.3846\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.8392 - loss: 0.4244 - val_accuracy: 0.8513 - val_loss: 0.3759\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8554 - loss: 0.3572 - val_accuracy: 0.8467 - val_loss: 0.3861\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.8450 - loss: 0.3823 - val_accuracy: 0.8581 - val_loss: 0.3748\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - accuracy: 0.6856 - loss: 0.6356 - val_accuracy: 0.7323 - val_loss: 0.5729\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7426 - loss: 0.5660 - val_accuracy: 0.7323 - val_loss: 0.5691\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.7261 - loss: 0.5779 - val_accuracy: 0.7323 - val_loss: 0.5682\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7295 - loss: 0.5750 - val_accuracy: 0.7323 - val_loss: 0.5640\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7196 - loss: 0.5886 - val_accuracy: 0.7300 - val_loss: 0.5683\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7472 - loss: 0.5589 - val_accuracy: 0.7323 - val_loss: 0.5690\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7154 - loss: 0.5867 - val_accuracy: 0.7323 - val_loss: 0.5606\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7490 - loss: 0.5349 - val_accuracy: 0.7346 - val_loss: 0.5653\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7212 - loss: 0.5649 - val_accuracy: 0.7323 - val_loss: 0.5586\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.7443 - loss: 0.5437 - val_accuracy: 0.7391 - val_loss: 0.5660\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7495 - loss: 0.5364 - val_accuracy: 0.7529 - val_loss: 0.5438\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7229 - loss: 0.5627 - val_accuracy: 0.7460 - val_loss: 0.5442\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7232 - loss: 0.5613 - val_accuracy: 0.7414 - val_loss: 0.5583\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7392 - loss: 0.5585 - val_accuracy: 0.7551 - val_loss: 0.5465\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.7375 - loss: 0.5498 - val_accuracy: 0.7437 - val_loss: 0.5414\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7570 - loss: 0.5246 - val_accuracy: 0.7231 - val_loss: 0.5477\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7463 - loss: 0.5440 - val_accuracy: 0.7323 - val_loss: 0.5475\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7405 - loss: 0.5479 - val_accuracy: 0.7254 - val_loss: 0.5558\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7475 - loss: 0.5339 - val_accuracy: 0.7323 - val_loss: 0.5500\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7679 - loss: 0.5220 - val_accuracy: 0.7368 - val_loss: 0.5505\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.7504 - loss: 0.5346 - val_accuracy: 0.7666 - val_loss: 0.5028\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7736 - loss: 0.5060 - val_accuracy: 0.7620 - val_loss: 0.5111\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7763 - loss: 0.5073 - val_accuracy: 0.7666 - val_loss: 0.5014\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7605 - loss: 0.5219 - val_accuracy: 0.7689 - val_loss: 0.5088\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7554 - loss: 0.5181 - val_accuracy: 0.7666 - val_loss: 0.5041\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7714 - loss: 0.5072 - val_accuracy: 0.7574 - val_loss: 0.5245\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7782 - loss: 0.5079 - val_accuracy: 0.7460 - val_loss: 0.5321\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7736 - loss: 0.4973 - val_accuracy: 0.7597 - val_loss: 0.5023\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7830 - loss: 0.4897 - val_accuracy: 0.7529 - val_loss: 0.5184\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.7662 - loss: 0.5220 - val_accuracy: 0.7597 - val_loss: 0.5150\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7761 - loss: 0.5023 - val_accuracy: 0.7803 - val_loss: 0.4857\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.7652 - loss: 0.5068 - val_accuracy: 0.7849 - val_loss: 0.4913\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7796 - loss: 0.4975 - val_accuracy: 0.7986 - val_loss: 0.4788\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7723 - loss: 0.5020 - val_accuracy: 0.7574 - val_loss: 0.5196\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7740 - loss: 0.5055 - val_accuracy: 0.7780 - val_loss: 0.4823\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7696 - loss: 0.4980 - val_accuracy: 0.7574 - val_loss: 0.5082\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7691 - loss: 0.4998 - val_accuracy: 0.7712 - val_loss: 0.4975\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.7860 - loss: 0.4849 - val_accuracy: 0.7895 - val_loss: 0.4963\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.7784 - loss: 0.4779 - val_accuracy: 0.7757 - val_loss: 0.4975\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.7861 - loss: 0.4827 - val_accuracy: 0.7689 - val_loss: 0.4926\n",
      "Now running, pct_increase: 1.02; days out: 10; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.8000 - loss: 0.4595 - val_accuracy: 0.7574 - val_loss: 0.5160\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.7861 - loss: 0.4773 - val_accuracy: 0.7735 - val_loss: 0.4993\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.7809 - loss: 0.4782 - val_accuracy: 0.7712 - val_loss: 0.5085\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8177 - loss: 0.4300 - val_accuracy: 0.7597 - val_loss: 0.5137\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.7921 - loss: 0.4719 - val_accuracy: 0.7620 - val_loss: 0.5283\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.7950 - loss: 0.4420 - val_accuracy: 0.7735 - val_loss: 0.5513\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8264 - loss: 0.4024 - val_accuracy: 0.7483 - val_loss: 0.5458\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8040 - loss: 0.4595 - val_accuracy: 0.7597 - val_loss: 0.5451\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.7895 - loss: 0.4597 - val_accuracy: 0.7574 - val_loss: 0.5784\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 0.7911 - loss: 0.4581 - val_accuracy: 0.7689 - val_loss: 0.5548\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: independent_array15; K-fold: 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - accuracy: 0.6253 - loss: 0.6607 - val_accuracy: 0.6384 - val_loss: 0.6517\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.6276 - loss: 0.6496 - val_accuracy: 0.6293 - val_loss: 0.6449\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.6516 - loss: 0.6359 - val_accuracy: 0.6201 - val_loss: 0.6469\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.6398 - loss: 0.6461 - val_accuracy: 0.6339 - val_loss: 0.6533\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.6677 - loss: 0.6314 - val_accuracy: 0.6384 - val_loss: 0.6494\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.6525 - loss: 0.6318 - val_accuracy: 0.6247 - val_loss: 0.6463\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.6372 - loss: 0.6463 - val_accuracy: 0.6430 - val_loss: 0.6377\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6548 - loss: 0.6353 - val_accuracy: 0.6682 - val_loss: 0.6338\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6583 - loss: 0.6241 - val_accuracy: 0.6362 - val_loss: 0.6386\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6394 - loss: 0.6394 - val_accuracy: 0.6659 - val_loss: 0.6322\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: independent_array15; K-fold: 2\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6521 - loss: 0.6397 - val_accuracy: 0.6407 - val_loss: 0.6434\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.6702 - loss: 0.6193 - val_accuracy: 0.6201 - val_loss: 0.6522\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6250 - loss: 0.6476 - val_accuracy: 0.6590 - val_loss: 0.6383\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6677 - loss: 0.6284 - val_accuracy: 0.6751 - val_loss: 0.6147\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6560 - loss: 0.6189 - val_accuracy: 0.6888 - val_loss: 0.6062\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6472 - loss: 0.6354 - val_accuracy: 0.6911 - val_loss: 0.6101\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.6582 - loss: 0.6290 - val_accuracy: 0.6819 - val_loss: 0.6123\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6945 - loss: 0.5945 - val_accuracy: 0.6934 - val_loss: 0.6163\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6866 - loss: 0.5995 - val_accuracy: 0.6590 - val_loss: 0.6448\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6900 - loss: 0.5987 - val_accuracy: 0.6957 - val_loss: 0.6097\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: independent_array15; K-fold: 3\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7037 - loss: 0.6009 - val_accuracy: 0.6979 - val_loss: 0.5840\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6900 - loss: 0.6170 - val_accuracy: 0.6865 - val_loss: 0.5971\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7029 - loss: 0.5944 - val_accuracy: 0.6842 - val_loss: 0.6071\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7037 - loss: 0.5787 - val_accuracy: 0.7048 - val_loss: 0.5798\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7120 - loss: 0.5709 - val_accuracy: 0.7025 - val_loss: 0.5806\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7086 - loss: 0.5785 - val_accuracy: 0.6911 - val_loss: 0.5937\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.6988 - loss: 0.5892 - val_accuracy: 0.6888 - val_loss: 0.6055\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6873 - loss: 0.6092 - val_accuracy: 0.7048 - val_loss: 0.5904\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6835 - loss: 0.5910 - val_accuracy: 0.7002 - val_loss: 0.5778\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7307 - loss: 0.5539 - val_accuracy: 0.7162 - val_loss: 0.5742\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: independent_array15; K-fold: 4\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6871 - loss: 0.5917 - val_accuracy: 0.6888 - val_loss: 0.6001\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7019 - loss: 0.5978 - val_accuracy: 0.7048 - val_loss: 0.5915\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7070 - loss: 0.5768 - val_accuracy: 0.6934 - val_loss: 0.5851\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7224 - loss: 0.5662 - val_accuracy: 0.7162 - val_loss: 0.5893\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7144 - loss: 0.5574 - val_accuracy: 0.7025 - val_loss: 0.6003\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7094 - loss: 0.5617 - val_accuracy: 0.6682 - val_loss: 0.6495\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7321 - loss: 0.5538 - val_accuracy: 0.7025 - val_loss: 0.5868\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.7199 - loss: 0.5569 - val_accuracy: 0.7117 - val_loss: 0.5860\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.7188 - loss: 0.5622 - val_accuracy: 0.6957 - val_loss: 0.6012\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7281 - loss: 0.5508 - val_accuracy: 0.6819 - val_loss: 0.6221\n",
      "Now running, pct_increase: 1.02; days out: 15; independent_array: independent_array15; K-fold: 5\n",
      "Epoch 1/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7174 - loss: 0.5534 - val_accuracy: 0.6957 - val_loss: 0.5887\n",
      "Epoch 2/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7093 - loss: 0.5661 - val_accuracy: 0.7346 - val_loss: 0.5567\n",
      "Epoch 3/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.7444 - loss: 0.5319 - val_accuracy: 0.7048 - val_loss: 0.5701\n",
      "Epoch 4/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.7296 - loss: 0.5535 - val_accuracy: 0.6911 - val_loss: 0.5831\n",
      "Epoch 5/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.7223 - loss: 0.5451 - val_accuracy: 0.6773 - val_loss: 0.6037\n",
      "Epoch 6/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.7333 - loss: 0.5458 - val_accuracy: 0.7346 - val_loss: 0.5636\n",
      "Epoch 7/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7588 - loss: 0.5240 - val_accuracy: 0.6888 - val_loss: 0.6254\n",
      "Epoch 8/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7515 - loss: 0.5231 - val_accuracy: 0.7185 - val_loss: 0.5670\n",
      "Epoch 9/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7434 - loss: 0.5213 - val_accuracy: 0.7254 - val_loss: 0.5809\n",
      "Epoch 10/10\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.7547 - loss: 0.4993 - val_accuracy: 0.6957 - val_loss: 0.6050\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "### User inputs ###\n",
    "selected_pattern = \"Random\"   #choices: 'Random', 'Hammer', 'InvertedHammer'\n",
    "\n",
    "#How many days after the pattern is identified to use for the dependent variable\n",
    "days_out = [1, 3, 5, 10, 15]\n",
    "\n",
    "#What percent increase from the current price is considered a positive class. For example 1.01 = 1% increase; 100 * 1.01 = 101. So if original\n",
    "#price is $100, anything greater than $101 is considered a positive class.\n",
    "pct_increase = [1.00, 1.01, 1.02]\n",
    "\n",
    "######\n",
    "\n",
    "\n",
    "# Define the classification model\n",
    "def create_lstm_classification(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(128, activation='tanh', return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
    "    \n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))  # Final LSTM layer\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense output layer for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification (probability)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Binary cross-entropy for classification\n",
    "    return model\n",
    "\n",
    "    \n",
    "\n",
    "#Subset data frame for desired pattern\n",
    "if (selected_pattern == \"Random\"):\n",
    "    pattern_df = finance_df[finance_df['Random_Yes_No_2'] == \"Yes\"] #this time, will select the newly created column with more observations\n",
    "elif (selected_pattern == \"Hammer\"):\n",
    "    pattern_df = finance_df[finance_df['Hammer_pattern'] == \"Yes\"]\n",
    "else:\n",
    "    pattern_df = finance_df[finance_df['InvertedHammer_pattern'] == \"Yes\"]\n",
    "\n",
    "\n",
    "#initialize an empty DataFrame with column names\n",
    "accuracy_df = pd.DataFrame(columns=['ticker', 'pattern', 'independent_array', 'best_accuracy', 'avg_accuracy', 'days_out', 'Total_observations', \n",
    "                                   'Negative_observations', 'Positive_observations', 'Percent_increase_parameter'])\n",
    "\n",
    "\n",
    "for percent in pct_increase:\n",
    "\n",
    "    for day in days_out:\n",
    "        #Gather independent variables\n",
    "        independent_list1 = []\n",
    "        independent_list2 = []\n",
    "        independent_list3 = []\n",
    "        independent_list4 = []\n",
    "        independent_list5 = []\n",
    "        independent_list6 = []\n",
    "        independent_list7 = []\n",
    "        independent_list8 = []\n",
    "        independent_list9 = []\n",
    "        independent_list10 = []\n",
    "        independent_list11 = []\n",
    "        independent_list12 = []\n",
    "        independent_list13 = []\n",
    "        independent_list14 = []\n",
    "        independent_list15 = []\n",
    "        \n",
    "        #gather dependent variables\n",
    "        dependent_list = []\n",
    "\n",
    "        #these are the row indexes that have the identified patterns; loop through\n",
    "        pattern_index = list(pattern_df[\"Row_index\"])\n",
    "        for i in pattern_index:\n",
    "            #if (i == 62):\n",
    "            #    break\n",
    "            \n",
    "            #unable to get 30 days worth of data if index is less than 56, because previously removed first 26 observations\n",
    "            if (i < 56):\n",
    "                continue\n",
    "        \n",
    "            #get 30 days worth of data to gather data for indpendent variables\n",
    "            subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 29)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "            #subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 13)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "            \n",
    "            #Get day after data to gather closing price for dependent variable\n",
    "            dependent_df = finance_df[finance_df[\"Row_index\"] == (i)]\n",
    "            dependent2_df = finance_df[finance_df[\"Row_index\"] == (i + day)]\n",
    "            \n",
    "            temp_list1 = []\n",
    "            temp_list2 = []\n",
    "            temp_list3 = []\n",
    "            temp_list4 = []\n",
    "            temp_list5 = []\n",
    "            temp_list6 = []\n",
    "            temp_list7 = []\n",
    "            temp_list8 = []\n",
    "            temp_list9 = []\n",
    "            temp_list10 = []\n",
    "            temp_list11 = []\n",
    "            temp_list12 = []\n",
    "            temp_list13 = []\n",
    "            temp_list14 = []\n",
    "            temp_list15 = []\n",
    "        \n",
    "            #append temp_list to independent_list\n",
    "            if len(dependent2_df) > 0: #dependent2_df may have length of zero as it is a future date, data may not be available\n",
    "            \n",
    "        \n",
    "                for index, row in subset_df.iterrows():\n",
    "                        \n",
    "                        test_array1 = np.array([row['Open'], row['Close'], row['High'], row['Low']])\n",
    "                        test_array2 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low']])\n",
    "                        test_array3 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low']])\n",
    "                \n",
    "                        test_array4 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI']])\n",
    "                        test_array5 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI']])\n",
    "                        test_array6 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI']])\n",
    "                \n",
    "                        test_array7 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MFI']])\n",
    "                        test_array8 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MFI']])\n",
    "                        test_array9 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MFI']])\n",
    "                \n",
    "                        test_array10 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array11 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array12 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['MACD'], row['Signal_Line']])\n",
    "                \n",
    "                        test_array13 = np.array([row['Open'], row['Close'], row['High'], row['Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array14 = np.array([row['Log_Open'], row['Log_Close'], row['Log_High'], row['Log_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                        test_array15 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "                \n",
    "                \n",
    "                        temp_list1.append(test_array1)\n",
    "                        temp_list2.append(test_array2)\n",
    "                        temp_list3.append(test_array3)\n",
    "                        temp_list4.append(test_array4)\n",
    "                        temp_list5.append(test_array5)\n",
    "                        temp_list6.append(test_array6)\n",
    "                        temp_list7.append(test_array7)\n",
    "                        temp_list8.append(test_array8)\n",
    "                        temp_list9.append(test_array9)\n",
    "                        temp_list10.append(test_array10)\n",
    "                        temp_list11.append(test_array11)\n",
    "                        temp_list12.append(test_array12)\n",
    "                        temp_list13.append(test_array13)\n",
    "                        temp_list14.append(test_array14)\n",
    "                        temp_list15.append(test_array15)\n",
    "                        \n",
    "                independent_list1.append(temp_list1)\n",
    "                independent_list2.append(temp_list2)\n",
    "                independent_list3.append(temp_list3)\n",
    "                independent_list4.append(temp_list4)\n",
    "                independent_list5.append(temp_list5)\n",
    "                independent_list6.append(temp_list6)\n",
    "                independent_list7.append(temp_list7)\n",
    "                independent_list8.append(temp_list8)\n",
    "                independent_list9.append(temp_list9)\n",
    "                independent_list10.append(temp_list10)\n",
    "                independent_list11.append(temp_list11)\n",
    "                independent_list12.append(temp_list12)\n",
    "                independent_list13.append(temp_list13)\n",
    "                independent_list14.append(temp_list14)\n",
    "                independent_list15.append(temp_list15)\n",
    "            \n",
    "                if (dependent2_df['Close'].iloc[0] > dependent_df['Close'].iloc[0] * percent):\n",
    "                    dependent_list.append(1)\n",
    "                else:\n",
    "                    dependent_list.append(0)\n",
    "        \n",
    "        independent_array1 = np.array(independent_list1)\n",
    "        independent_array2 = np.array(independent_list2)\n",
    "        independent_array3 = np.array(independent_list3)\n",
    "        independent_array4 = np.array(independent_list4)\n",
    "        independent_array5 = np.array(independent_list5)\n",
    "        independent_array6 = np.array(independent_list6)\n",
    "        independent_array7 = np.array(independent_list7)\n",
    "        independent_array8= np.array(independent_list8)\n",
    "        independent_array9 = np.array(independent_list9)\n",
    "        independent_array10 = np.array(independent_list10)\n",
    "        independent_array11 = np.array(independent_list11)\n",
    "        independent_array12 = np.array(independent_list12)\n",
    "        independent_array13 = np.array(independent_list13)\n",
    "        independent_array14 = np.array(independent_list14)\n",
    "        independent_array15 = np.array(independent_list15)\n",
    "        dependent_array = np.array(dependent_list)\n",
    "    \n",
    "    \n",
    "        y = dependent_array\n",
    "        independent_array = []\n",
    "        best_accuracy = []\n",
    "        avg_accuracy = []\n",
    "        counter_independentarray = 0\n",
    "        for i in range(1, 16):\n",
    "            if i != 15: #testing what seems is the most well performing model\n",
    "                continue\n",
    "            \n",
    "            # Select which independent_array to use\n",
    "            if i == 1:\n",
    "                X = independent_array1  # Shape: (890, 30, 4)\n",
    "                independent_array.append(\"independent_array1\")\n",
    "            if i == 2:\n",
    "                X = independent_array2  # Shape: (890, 30, 4)\n",
    "                independent_array.append(\"independent_array2\")\n",
    "            if i == 3:\n",
    "                X = independent_array3  # Shape: (890, 30, 4)\n",
    "                independent_array.append(\"independent_array3\")\n",
    "            if i == 4:\n",
    "                X = independent_array4  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array4\")\n",
    "            if i == 5:\n",
    "                X = independent_array5  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array5\")\n",
    "            if i == 6:\n",
    "                X = independent_array6  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array6\")\n",
    "            if i == 7:\n",
    "                X = independent_array7  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array7\")\n",
    "            if i == 8:\n",
    "                X = independent_array8  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array8\")\n",
    "            if i == 9:\n",
    "                X = independent_array9  # Shape: (890, 30, 5)\n",
    "                independent_array.append(\"independent_array9\")\n",
    "            if i == 10:\n",
    "                X = independent_array10  # Shape: (890, 30, 6)\n",
    "                independent_array.append(\"independent_array10\")\n",
    "            if i == 11:\n",
    "                X = independent_array11  # Shape: (890, 30, 6)\n",
    "                independent_array.append(\"independent_array11\")\n",
    "            if i == 12:\n",
    "                X = independent_array12  # Shape: (890, 30, 6)\n",
    "                independent_array.append(\"independent_array12\")\n",
    "            if i == 13:\n",
    "                X = independent_array13  # Shape: (890, 30, 8)\n",
    "                independent_array.append(\"independent_array13\")\n",
    "            if i == 14:\n",
    "                X = independent_array14  # Shape: (890, 30, 8)\n",
    "                independent_array.append(\"independent_array14\")\n",
    "            if i == 15:\n",
    "                X = independent_array15  # Shape: (890, 30, 8)\n",
    "                independent_array.append(\"independent_array15\")\n",
    "        \n",
    "            #counter_independentarray = counter_independentarray + 1\n",
    "            \n",
    "            # Define the input shape based on the number of features\n",
    "            input_shape = (30, X.shape[2])  # 30 time-steps and `X.shape[2]` features per time-step\n",
    "            \n",
    "            # Create the LSTM model\n",
    "            classification_model = create_lstm_classification(input_shape)\n",
    "            \n",
    "            # Initialize k-fold cross-validation\n",
    "            #kf = KFold(n_splits=5, shuffle=True, random_state=6)  #regular 5-fold cross-validation w/out stratification\n",
    "            kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=6)  # 5-fold cross-validation with stratification\n",
    "\n",
    "            #initialize to gather all the accuracy scores at each epoch for all 5 folds\n",
    "            fold_accuracies = []\n",
    "            \n",
    "            #stratified K-fold Cross-Validation\n",
    "            counter_kfold = 0\n",
    "            for train_index, val_index in kf.split(X, y): #used for stratified k-fold\n",
    "            #for train_index, val_index in kf.split(X): #used for regular k-fold\n",
    "                \n",
    "                counter_kfold = counter_kfold + 1\n",
    "                print(f\"Now running, pct_increase: {percent}; days out: {day}; independent_array: {independent_array[(len(independent_array) - 1)]}; K-fold: {counter_kfold}\")\n",
    "                \n",
    "                X_train, X_val = X[train_index], X[val_index]\n",
    "                y_train, y_val = y[train_index], y[val_index]\n",
    "                \n",
    "                # Train the classification model and store the history; verbose = 0 to hide epoch running info in cell output\n",
    "                history = classification_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "                \n",
    "                # Get the validation accuracies for this fold. What this does is that an accuracy score is calculated at each epoch,\n",
    "                #and in this list I am getting all the accuracy scores from all five folds\n",
    "                val_accuracy = history.history['val_accuracy']\n",
    "                fold_accuracies.append(val_accuracy)\n",
    "        \n",
    "        \n",
    "            \n",
    "            # Calculate the best and average validation accuracy across all folds\n",
    "            best_val_accuracy = np.max(fold_accuracies) #get the max accuracy across all epochs across all five folds\n",
    "            avg_val_accuracy = np.mean(fold_accuracies) #get the mean accuracy across all epochs across all five folds\n",
    "            best_accuracy.append(best_val_accuracy)\n",
    "            avg_accuracy.append(avg_val_accuracy)\n",
    "        \n",
    "        \n",
    "        # Example of new data to add\n",
    "        df_new = pd.DataFrame({\n",
    "            'ticker': ticker_symbol,\n",
    "            'pattern': selected_pattern,\n",
    "            'independent_array': independent_array,\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'avg_accuracy': avg_accuracy,\n",
    "            'days_out': day,\n",
    "            'Total_observations': sum(np.unique(dependent_array, return_counts=True)[1]),\n",
    "            'Negative_observations': np.unique(dependent_array, return_counts=True)[1][0],\n",
    "            'Positive_observations': np.unique(dependent_array, return_counts=True)[1][1],\n",
    "            'Percent_increase_parameter': percent\n",
    "        })\n",
    "    \n",
    "        # Concatenate the new data to the empty DataFrame\n",
    "        accuracy_df = pd.concat([accuracy_df, df_new], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d4ca4428-0b62-4d10-b997-4479cc7e54ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will output one CSV files with training results for classification model\n",
    "accuracy_df.to_csv(f'{ticker_symbol}_{selected_pattern}_classification_2200_Observations_output.csv', index=False)  # `index=False` avoids writing the index column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c94c9-e690-4894-8a9a-d417ad519b31",
   "metadata": {},
   "source": [
    "#### Final LSTM Classification Model with: Increased Observations, Stratified K-fold Cross Validation, Ensemble Learning Approach\n",
    "\n",
    "To build off from the previous code, I will now implement ensemble methods. Below, I am going to create and train 9 models, all of which have the same architecture and train them all on my best performing set of independent variables, independent array #15.  Each of these 9 models will undergo Stratified 5-fold cross validation as we did previously, and I will save the best weights for each model during training using a ModelCheckpoint callback - the epoch with the highest validation accuracy across all five folds will have its model weights saved. \n",
    "\n",
    "After the models have been trained and their best weights saved, I will load these models and combine their predictions using an ensemble approach. Specifically, I will take each model and output its predictions; I will use a voting-based system where if any 5 of the 9 models (the majority) predict the class as a positive class, then its final prediction will be classified as positive, and if less than 5 models predict it as positive, it will be classified as negative. This approach ensures that the final decision is based on the collective judgment of the majority of the models, reducing the likelihood of errors from individual models. \n",
    "\n",
    "Lastly, the accuracy of the ensemble model will be evaluated on a separate test dataset to assess the effectiveness of this combined approach. This ensemble method aims to leverage the strengths of each individual model and provide a more robust prediction.\n",
    "\n",
    "For this example below, I will just set the 'days_out' parameter to 10 and the 'pct_increase' parameter to 1.01. I am currently choosing this parameter combination because when analyzing the model results from the last step, there appeared to be a noticeable increase in the accuracy score from my model (67.3%) when compared to always guessing the majority class (55.3%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "93d6607c-77a8-45c6-877a-352f121a2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset data frame for desired pattern\n",
    "pattern_df = finance_df[finance_df['Random_Yes_No_2'] == \"Yes\"]\n",
    "\n",
    "#How many days after the pattern is identified to use for the dependent variable\n",
    "days_out = 10\n",
    "\n",
    "#What percent increase from the current price is considered a positive class. For example 1.01 = 1% increase; 100 * 1.01 = 101. So if original\n",
    "#price is $100, anything greater than $101 is considered a positive class.\n",
    "pct_increase = 1.01\n",
    "\n",
    "#Gather independent variables\n",
    "independent_list15 = []\n",
    "\n",
    "#gather dependent variables\n",
    "dependent_list = []\n",
    "\n",
    "pattern_index = list(pattern_df[\"Row_index\"])\n",
    "#pattern_index = [60, 62]\n",
    "for i in pattern_index:\n",
    "    #if (i == 62):\n",
    "    #    break\n",
    "    \n",
    "    #unable to get 30 days worth of data if index is less than 56, because previously removed first 26 observations\n",
    "    if (i < 56):\n",
    "        continue\n",
    "\n",
    "    #get 30 days worth of data to gather data for indpendent variables\n",
    "    subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 29)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "    #subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 13)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "    \n",
    "    #Get day after data to gather closing price for dependent variable\n",
    "    dependent_df = finance_df[finance_df[\"Row_index\"] == (i)]\n",
    "    dependent2_df = finance_df[finance_df[\"Row_index\"] == (i + days_out)]\n",
    "    \n",
    "    temp_list15 = []\n",
    "\n",
    "    #append temp_list to independent_list\n",
    "    if len(dependent2_df) > 0: #dependent2_df may have length of zero as it is a future date, data may not be available\n",
    "    \n",
    "\n",
    "        for index, row in subset_df.iterrows():\n",
    "                \n",
    "                test_array15 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "            \n",
    "                temp_list15.append(test_array15)\n",
    "                \n",
    "        independent_list15.append(temp_list15)\n",
    "    \n",
    "        if (dependent2_df['Close'].iloc[0] > dependent_df['Close'].iloc[0] * pct_increase):\n",
    "            dependent_list.append(1)\n",
    "        else:\n",
    "            dependent_list.append(0)\n",
    "\n",
    "independent_array15 = np.array(independent_list15)\n",
    "dependent_array = np.array(dependent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92bea2c-9dd1-48b9-84aa-fb73eeb08ab5",
   "metadata": {},
   "source": [
    "The resulting shape of the independent variable dataset is: 30 time-steps and 8 features per time-step; with a total of 2185 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2f4bd8f5-2479-466a-9d0d-83cd3252a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2185, 30, 8)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(independent_array15)) # 30 time-steps and 8 features per time-step; with a total of 2185 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277a31b-bfa6-4b9d-898d-a870f532c27b",
   "metadata": {},
   "source": [
    "Now, after my independent variables associated with independent array #15 has been gathered above and my dependent array has also been gathered above, I will train 9 models with the same architecture on the data, applying 5-fold stratified cross-validation to each model. For each of the 9 models, the epoch with the best performance (highest validation accuracy) will have its weights saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b550720a-4acd-4969-a9e6-7cd35f7849da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/9...\n",
      "Model: 1; K-fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55149, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.55149\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.55149 to 0.55378, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.55378 to 0.56293, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.56293\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.56293\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.56293 to 0.56979, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.56979 to 0.57895, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.57895\n",
      "Model: 1; K-fold: 2\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.57895 to 0.60870, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.60870\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.60870\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.60870\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.60870\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.60870\n",
      "Model: 1; K-fold: 3\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.60870\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.60870\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.60870\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.60870 to 0.61556, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.61556 to 0.62700, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.62700\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.62700\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.62700\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.62700\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.62700 to 0.63387, saving model to model_1_best_weights.keras\n",
      "Model: 1; K-fold: 4\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.63387 to 0.67048, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.67048 to 0.67506, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.67506 to 0.68192, saving model to model_1_best_weights.keras\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.68192\n",
      "Model: 1; K-fold: 5\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.68192\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.68192\n",
      "Training model 2/9...\n",
      "Model: 2; K-fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55835, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.55835\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.55835\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.55835 to 0.56979, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.56979\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.56979\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.56979\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.56979\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.56979\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.56979\n",
      "Model: 2; K-fold: 2\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.56979 to 0.57895, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.57895 to 0.59954, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.59954\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.59954\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.59954\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.59954\n",
      "Model: 2; K-fold: 3\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.59954 to 0.60183, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.60183\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.60183 to 0.60412, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.60412\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.60412\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.60412\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.60412\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.60412 to 0.60870, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.60870 to 0.61098, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.61098\n",
      "Model: 2; K-fold: 4\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.61098\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.61098\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.61098\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.61098\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.61098\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.61098\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.61098\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.61098 to 0.61785, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.61785\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.61785\n",
      "Model: 2; K-fold: 5\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.61785\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.61785\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.61785\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.61785\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.61785 to 0.62243, saving model to model_2_best_weights.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.62243\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.62243\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.62243\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.62243\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.62243\n",
      "Training model 3/9...\n",
      "Model: 3; K-fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46453, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.46453 to 0.55378, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.55378\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.55378\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.55378\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.55378\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.55378\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.55378\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.55378 to 0.55606, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.55606\n",
      "Model: 3; K-fold: 2\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.55606 to 0.58352, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.58352 to 0.59039, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.59039 to 0.59725, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.59725 to 0.61556, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.61556\n",
      "Model: 3; K-fold: 3\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.61556\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.61556\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.61556\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.61556\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.61556\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.61556\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.61556\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.61556\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.61556\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.61556\n",
      "Model: 3; K-fold: 4\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.61556 to 0.66590, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.66590\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.66590\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.66590\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.66590\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.66590\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.66590\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.66590\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.66590\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.66590\n",
      "Model: 3; K-fold: 5\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.66590 to 0.68192, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.68192 to 0.68879, saving model to model_3_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.68879\n",
      "Training model 4/9...\n",
      "Model: 4; K-fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57437, saving model to model_4_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.57437\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.57437\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.57437 to 0.58810, saving model to model_4_best_weights.keras\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.58810\n",
      "Model: 4; K-fold: 2\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.58810 to 0.60641, saving model to model_4_best_weights.keras\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.60641\n",
      "Model: 4; K-fold: 3\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.60641\n",
      "Model: 4; K-fold: 4\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.60641 to 0.61327, saving model to model_4_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.61327 to 0.62014, saving model to model_4_best_weights.keras\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.62014\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.62014\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.62014\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.62014\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.62014\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.62014\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.62014\n",
      "Model: 4; K-fold: 5\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.62014\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.62014 to 0.66133, saving model to model_4_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.66133\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.66133\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.66133\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.66133\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.66133\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.66133\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.66133\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.66133\n",
      "Training model 5/9...\n",
      "Model: 5; K-fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56751, saving model to model_5_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.56751\n",
      "Model: 5; K-fold: 2\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.56751\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.56751\n",
      "Model: 5; K-fold: 3\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.56751 to 0.57666, saving model to model_5_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.57666 to 0.57895, saving model to model_5_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.57895 to 0.58352, saving model to model_5_best_weights.keras\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.58352 to 0.59497, saving model to model_5_best_weights.keras\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.59497\n",
      "Model: 5; K-fold: 4\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.59497\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.59497\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.59497\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.59497\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.59497\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.59497\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.59497 to 0.60183, saving model to model_5_best_weights.keras\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.60183 to 0.61098, saving model to model_5_best_weights.keras\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.61098\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.61098\n",
      "Model: 5; K-fold: 5\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.61098\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.61098 to 0.63158, saving model to model_5_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.63158\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.63158\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.63158 to 0.63616, saving model to model_5_best_weights.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.63616\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.63616\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.63616\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.63616\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.63616\n",
      "Training model 6/9...\n",
      "Model: 6; K-fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50114, saving model to model_6_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.50114 to 0.54233, saving model to model_6_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.54233\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.54233\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.54233\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.54233\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.54233\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.54233\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.54233\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.54233\n",
      "Model: 6; K-fold: 2\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.54233 to 0.60412, saving model to model_6_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.60412\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.60412\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.60412\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.60412\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.60412 to 0.60870, saving model to model_6_best_weights.keras\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.60870 to 0.62014, saving model to model_6_best_weights.keras\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.62014 to 0.62471, saving model to model_6_best_weights.keras\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.62471\n",
      "Model: 6; K-fold: 3\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.62471\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.62471\n",
      "Model: 6; K-fold: 4\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.62471 to 0.62929, saving model to model_6_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.62929 to 0.65675, saving model to model_6_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.65675\n",
      "Model: 6; K-fold: 5\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.65675\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.65675\n",
      "Training model 7/9...\n",
      "Model: 7; K-fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54920, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.54920 to 0.55378, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.55378 to 0.57895, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.57895\n",
      "Model: 7; K-fold: 2\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.57895 to 0.58810, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.58810\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.58810 to 0.59039, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.59039\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.59039 to 0.59954, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.59954\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.59954\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.59954\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.59954\n",
      "Model: 7; K-fold: 3\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.59954\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.59954 to 0.64073, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.64073\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.64073\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.64073\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.64073\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.64073\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.64073\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.64073\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.64073\n",
      "Model: 7; K-fold: 4\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.64073 to 0.64531, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.64531\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.64531\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.64531 to 0.65446, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.65446 to 0.66133, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.66133\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.66133 to 0.67048, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.67048\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.67048\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.67048\n",
      "Model: 7; K-fold: 5\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.67048\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.67048 to 0.68879, saving model to model_7_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.68879\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.68879\n",
      "Training model 8/9...\n",
      "Model: 8; K-fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53547, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.53547 to 0.54233, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.54233\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.54233 to 0.55835, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.55835 to 0.58352, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.58352\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.58352\n",
      "Model: 8; K-fold: 2\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.58352 to 0.59725, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.59725\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.59725 to 0.60641, saving model to model_8_best_weights.keras\n",
      "Model: 8; K-fold: 3\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.60641\n",
      "Model: 8; K-fold: 4\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.60641 to 0.62014, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.62014 to 0.63616, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.63616 to 0.63844, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.63844\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.63844\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.63844 to 0.64073, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.64073 to 0.66362, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.66362\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.66362\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.66362 to 0.66819, saving model to model_8_best_weights.keras\n",
      "Model: 8; K-fold: 5\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.66819 to 0.68650, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.68650 to 0.69108, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.69108\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.69108 to 0.69565, saving model to model_8_best_weights.keras\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.69565\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.69565\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.69565\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.69565\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.69565\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.69565\n",
      "Training model 9/9...\n",
      "Model: 9; K-fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55606, saving model to model_9_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.55606 to 0.57437, saving model to model_9_best_weights.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.57437\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.57437\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.57437\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.57437\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.57437\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.57437\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.57437 to 0.57895, saving model to model_9_best_weights.keras\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.57895\n",
      "Model: 9; K-fold: 2\n",
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.57895\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.57895\n",
      "Model: 9; K-fold: 3\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.57895 to 0.60641, saving model to model_9_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.60641\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.60641 to 0.61098, saving model to model_9_best_weights.keras\n",
      "Model: 9; K-fold: 4\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.61098 to 0.62243, saving model to model_9_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.62243\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.62243\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.62243\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.62243\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.62243\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.62243 to 0.62700, saving model to model_9_best_weights.keras\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.62700\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.62700\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.62700\n",
      "Model: 9; K-fold: 5\n",
      "\n",
      "Epoch 1: val_accuracy improved from 0.62700 to 0.72540, saving model to model_9_best_weights.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.72540\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.72540\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.72540\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.72540\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.72540\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.72540\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.72540\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.72540\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.72540\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the LSTM classification model\n",
    "def create_lstm_classification(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(128, activation='tanh', return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
    "    \n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))  # Final LSTM layer\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense output layer for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification (probability)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Binary cross-entropy for classification\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define independent and dependent variables\n",
    "X = independent_array15  # Shape: (890, 30, [4, 5, 6, or 8]) \n",
    "y = dependent_array  # Shape: (890,) (binary labels, 0 or 1)\n",
    "\n",
    "# Initialize list to hold models and their weights\n",
    "models = []\n",
    "\n",
    "# Loop for training 9 identical models\n",
    "for model_num in range(9):\n",
    "    print(f\"Training model {model_num + 1}/9...\")\n",
    "\n",
    "    # Initialize the KFold\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=(model_num+1))\n",
    "\n",
    "    # Create and compile the model once per model_num (outside of the KFold loop)\n",
    "    # This model will be reused for each fold\n",
    "    input_shape = (30, X.shape[2])  # Define input shape based on your data\n",
    "    model = create_lstm_classification(input_shape)\n",
    "\n",
    "    # Initialize an empty list for storing fold accuracies\n",
    "    fold_accuracies = []\n",
    "\n",
    "    # Set up a ModelCheckpoint callback to save the model's weights when validation accuracy is improved\n",
    "    checkpoint = ModelCheckpoint(f'model_{model_num + 1}_best_weights.keras', \n",
    "                                 save_best_only=True, \n",
    "                                 monitor='val_accuracy', \n",
    "                                 mode='max', \n",
    "                                 verbose=1)\n",
    "\n",
    "    K_fold_counter = 0\n",
    "    # Perform stratified K-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X, y):\n",
    "        print(f'Model: {model_num + 1}; K-fold: {(K_fold_counter + 1)}')\n",
    "        K_fold_counter = K_fold_counter + 1\n",
    "        \n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=0, callbacks=[checkpoint])\n",
    "\n",
    "    \n",
    "    # After training all folds, load the best weights into the model\n",
    "    #best_model = create_lstm_classification(input_shape)\n",
    "    #best_model.load_weights(f'model_{model_num + 1}_best_weights.keras')\n",
    "\n",
    "    # Append the model to the list of trained models\n",
    "    #models.append(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab6cb1-2cc2-4bff-9ea5-935f9d794d03",
   "metadata": {},
   "source": [
    "Now that I have trained my 9 models of the same architecture, using the best performing set of independent variables (independent array #15), I will now evaluate the accuracy of the ensemble model on a separate test dataset to assess the effectiveness of this combined approach. This ensemble method aims to leverage the strengths of each individual model and provide a more robust prediction.\n",
    "\n",
    "I am going to create a test dataset by creating a list of new random values to evaluate the ensemble model on. I will do this by changing the random seed. Previously it was 6, now it is 7. What this does is ensure that the new dataset is generated deterministically with a different sequence of random numbers, providing a new set of test data. This change in the random seed helps evaluate how the ensemble model performs on different variations of the test data, enabling better validation of its generalization capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f89c6bd5-d68d-42f6-9faa-781d1f673ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of \"Yes\" values you want, may show up as less during training due to location of the \"Yes\" value, as need at least 30 days\n",
    "#of data for the 30-day sequence, or if the future closing price is not available (only have data to 2/14)\n",
    "num_yes = 2200\n",
    "\n",
    "# Create a list of \"Yes\" and \"No\" values\n",
    "yes_no_list = [\"Yes\"] * num_yes + [\"No\"] * (len(finance_df) - num_yes)\n",
    "\n",
    "#set seed for reproducibility; previously this seed was set to 6, so it is going to create an entirely new list of random \"Yes\" and \"No\" values\n",
    "np.random.seed(7) \n",
    "\n",
    "# Shuffle the list to randomize the order\n",
    "np.random.shuffle(yes_no_list)\n",
    "\n",
    "# Create a new column in the dataframe; we already have a column 'Random_Yes_No_2' which was used to train the occurence of a random pattern\n",
    "finance_df['Random_Yes_No_3'] = yes_no_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfa5a777-c54a-44ab-bc34-0ea8725738d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset data frame for desired pattern\n",
    "pattern_df = finance_df[finance_df['Random_Yes_No_3'] == \"Yes\"]\n",
    "\n",
    "#How many days after the pattern is identified to use for the dependent variable\n",
    "days_out = 10\n",
    "\n",
    "#What percent increase from the current price is considered a positive class. For example 1.01 = 1% increase; 100 * 1.01 = 101. So if original\n",
    "#price is $100, anything greater than $101 is considered a positive class.\n",
    "pct_increase = 1.01\n",
    "\n",
    "#Gather independent variables\n",
    "independent_list15 = []\n",
    "\n",
    "#gather dependent variables\n",
    "dependent_list = []\n",
    "\n",
    "pattern_index = list(pattern_df[\"Row_index\"])\n",
    "#pattern_index = [60, 62]\n",
    "for i in pattern_index:\n",
    "    #if (i == 62):\n",
    "    #    break\n",
    "    \n",
    "    #unable to get 30 days worth of data if index is less than 56, because previously removed first 26 observations\n",
    "    if (i < 56):\n",
    "        continue\n",
    "\n",
    "    #get 30 days worth of data to gather data for indpendent variables\n",
    "    subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 29)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "    #subset_df = finance_df[(finance_df[\"Row_index\"] >= (i - 13)) & (finance_df[\"Row_index\"] <= (i))]\n",
    "    \n",
    "    #Get day after data to gather closing price for dependent variable\n",
    "    dependent_df = finance_df[finance_df[\"Row_index\"] == (i)]\n",
    "    dependent2_df = finance_df[finance_df[\"Row_index\"] == (i + days_out)]\n",
    "    \n",
    "    temp_list15 = []\n",
    "\n",
    "    #append temp_list to independent_list\n",
    "    if len(dependent2_df) > 0: #dependent2_df may have length of zero as it is a future date, data may not be available\n",
    "    \n",
    "\n",
    "        for index, row in subset_df.iterrows():\n",
    "                \n",
    "                test_array15 = np.array([row['Normalized_Open'], row['Normalized_Close'], row['Normalized_High'], row['Normalized_Low'], row['RSI'], row['MFI'], row['MACD'], row['Signal_Line']])\n",
    "            \n",
    "                temp_list15.append(test_array15)\n",
    "                \n",
    "        independent_list15.append(temp_list15)\n",
    "    \n",
    "        if (dependent2_df['Close'].iloc[0] > dependent_df['Close'].iloc[0] * pct_increase):\n",
    "            dependent_list.append(1)\n",
    "        else:\n",
    "            dependent_list.append(0)\n",
    "\n",
    "independent_array15 = np.array(independent_list15)\n",
    "dependent_array = np.array(dependent_list)\n",
    "X = independent_array15\n",
    "y = dependent_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ff11c-d86b-4a72-8997-f02f2494250e",
   "metadata": {},
   "source": [
    "After collecting my new set of independent and dependent variables above based on the new random split, I am ready to load my previously trained models and perform ensemble learning using those 9 models as coded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d9ebc27-9cd9-410d-bb6d-96afddff2181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\james\\Python Environments\\myflaskenv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step \n",
      "Number of total observations in entire dependent array dataset: 2188\n",
      "Number of actual false labels in entire dependent array dataset: 1230\n",
      "Number of actual true labels in entire dependent array dataset: 958\n",
      "Number of total observations in test dataset: 438\n",
      "Number of incorrect predictions on test dataset: 137\n",
      "Number of correct predictions on test dataset: 301\n",
      "Prediction accuracy on test dataset: 0.6872146118721462\n",
      "Number of actual false labels in test dataset: 256\n",
      "Number of actual true labels test dataset: 182\n",
      "Majority class label percent in test dataset: 0.5844748858447488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Assuming you already have your trained models and their weights\n",
    "models = []\n",
    "\n",
    "#Define the LSTM classification model; already defined it previously, so don't have to but for testing purposes if I skip chunks, I will include it here\n",
    "def create_lstm_classification(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(128, activation='tanh', return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
    "    \n",
    "    model.add(LSTM(64, activation='tanh', return_sequences=False))  # Final LSTM layer\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense output layer for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification (probability)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Binary cross-entropy for classification\n",
    "    \n",
    "    return model\n",
    "\n",
    "#Specify input shape\n",
    "input_shape = (30, X.shape[2]) \n",
    "\n",
    "# Load models and weights (adjust the range to include all your models)\n",
    "for model_num in range(0, 9):  # Change this range to include more models if necessary\n",
    "    best_model = create_lstm_classification(input_shape)\n",
    "    best_model.load_weights(f'model_{model_num + 1}_best_weights.keras')\n",
    "    models.append(best_model)\n",
    "\n",
    "# Split data for final training/testing; only using X_test_final for predicting and y_test_final for comparing my predictions\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(X, y, test_size=0.2, random_state=8)\n",
    "\n",
    "# Initialize a list to store binary predictions from each model\n",
    "ensemble_predictions = []\n",
    "\n",
    "#initialize to get votes from each model\n",
    "votes = np.zeros(len(X_test_final), dtype=int)\n",
    "\n",
    "# Generate predictions from each model\n",
    "for model in models:\n",
    "    # Get the predictions from the model (probabilities)\n",
    "    predictions = model.predict(X_test_final)\n",
    "    \n",
    "    # Convert predictions to binary (0 or 1)\n",
    "    binary_predictions = (predictions > 0.5).astype(int)  # Convert to 0 or 1\n",
    "\n",
    "    counter = 0\n",
    "    for value in binary_predictions: #for each value in the model's predictions, if the value is predicted 0, then no votes added, if 1, then add 1 vote\n",
    "        if (value == 0):\n",
    "            votes[counter] = votes[counter] + 0\n",
    "        else:\n",
    "            votes[counter] = votes[counter] + 1\n",
    "        counter = counter + 1\n",
    "\n",
    "#because there are 9 different models, if the vote is greater than 5, then it is a positive class\n",
    "results = []\n",
    "for vote in votes:\n",
    "    if (vote >= 5):\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "# Create a pandas Series for comparison\n",
    "comparison = pd.Series(results == y_test_final)\n",
    "\n",
    "# Use value_counts() to count True/False occurrences\n",
    "counts = comparison.value_counts()\n",
    "num_true = counts.get(True, 0)  # 0 if True is not found\n",
    "num_false = counts.get(False, 0)  # 0 if False is not found\n",
    "\n",
    "#Get total amount of observations in training/validation dataset\n",
    "counts_2 = pd.Series(dependent_array).value_counts()\n",
    "total_true_labels = counts_2.get(1, 0)  # Will return 0 if no '1' exists\n",
    "total_false_labels = counts_2.get(0, 0)  # Will return 0 if no '0' exists\n",
    "\n",
    "# Convert results and y_test_final to numpy arrays for easier handling if they aren't already\n",
    "results = np.array(results)\n",
    "y_test_final = np.array(y_test_final)\n",
    "\n",
    "# Count the number of true (1) and false (0) labels\n",
    "label_counts = pd.Series(y_test_final).value_counts()\n",
    "\n",
    "# Get counts of True (1) and False (0) specifically for the test set\n",
    "total_true_labels_test = label_counts.get(1, 0)  # Will return 0 if no '1' exists\n",
    "total_false_labels_test = label_counts.get(0, 0)  # Will return 0 if no '0' exists\n",
    "\n",
    "#compute accuracy and most_frequent_class_test_pct\n",
    "accuracy = float(num_true) / (len(y_test_final))\n",
    "if (total_true_labels_test > total_false_labels_test):\n",
    "    most_frequent_class_test_pct = float(total_true_labels_test) / float(len(y_test_final))\n",
    "else:\n",
    "    most_frequent_class_test_pct = float(total_false_labels_test) / float(len(y_test_final))\n",
    "\n",
    "\n",
    "#print out final results statements\n",
    "print(f'Number of total observations in entire dependent array dataset: {len(dependent_array)}')\n",
    "\n",
    "print(f'Number of actual false labels in entire dependent array dataset: {total_false_labels}')\n",
    "print(f'Number of actual true labels in entire dependent array dataset: {total_true_labels}')\n",
    "\n",
    "print(f'Number of total observations in test dataset: {len(y_test_final)}')\n",
    "print(f'Number of incorrect predictions on test dataset: {num_false}')\n",
    "print(f'Number of correct predictions on test dataset: {num_true}')\n",
    "print(f'Prediction accuracy on test dataset: {accuracy}')\n",
    "\n",
    "print(f'Number of actual false labels in test dataset: {total_false_labels_test}')\n",
    "print(f'Number of actual true labels test dataset: {total_true_labels_test}')\n",
    "print(f'Majority class label percent in test dataset: {most_frequent_class_test_pct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f40d5-1c7f-4aed-98d1-6fa40dfca689",
   "metadata": {},
   "source": [
    "The results of using ensemble methods are significant as we can see the accuracy scores. Based on this data sample, if we always predicted that the future closing price would be false, we would be correct 1230 out of 2188 times or 56.22% of the time. However, our model performs better, as our model has 301 correct predictions out of 438 observations or a correct prediction rate of 68.72%. Also, when looking at the actual false labels in the test dataset, which is the majority class, we see 256 observations; 256 out of 438 is 58.45%. Our model clearly performs better when compared against the actual labels in the entire dataset and when compared against the actual labels in the test dataset.\n",
    "\n",
    "The results are significant, as we can outperform the expected market outcome (which assumes predicting the future price as false) by around 10% with this parameter combination when comparing against the actual values of the test set labels. This demonstrates the effectiveness of the model in identifying patterns and making predictions that exceed a baseline strategy of predicting no price increase of greater than 1% over the next ten days (which was the parameter combination I used for this ensemble model (pct_increase=1.01)).\n",
    "\n",
    "I have demonstrated the implementation of the ensemble learning method (with stratified 5-fold cross-validation used to train these models) using the following parameters: The dependent variable represents the closing price 10 days in the future. The label for the dependent variable is assigned as 0 (false) if the future closing price is less than or equal to a 1% increase from the closing price of the last identified candle. It is labeled as 1 (true) if the future closing price is greater than a 1% increase from the closing price of the last identified candle.\n",
    "\n",
    "I will run this implementation multiple times through multiple parameter combinations using independent array #15 as mentioned before, I found it to be the best performing combination of independent variables. I will run this separately outside of this document, for the submission for the next part of this project. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8679d2e2-3626-40aa-8b66-789288024684",
   "metadata": {},
   "source": [
    "# Reporting - *E*\n",
    "\n",
    "To restate my research question:\n",
    "\n",
    "_Using historical market stock prices and technical indicators (RSI, MACD, MFI), how accurately can a neural network model, specifically an LSTM-based Recurrent Neural Network, predict stock price movements after the occurrence of a bullish candlestick pattern (e.g., 1 day, 3 days, 5 days, 10 days, and 15 days afterwards)? Additionally, how does the performance differ when using binary classification versus regression for price prediction?_\n",
    "\n",
    "To directly answer the first question, my LSTM-based Recurrent Neural Network can accurately predict stock price movements following the occurrence of a bullish candlestick pattern. Specifically, it performs about 9-10% better in predicting the outcome compared to when a random occurrence is used. By \"random occurrence,\" I mean a randomly generated set of 30-day sequences that do not depend on the presence of a candlestick pattern on the 30th day of the sequence.\n",
    "\n",
    "To directly answer the second question, the performance is more consistent and predictable while using a classification model in predicting price fluctuations.\n",
    "\n",
    "Below, I will answer in high detail the first and second part of the research question and how I came to each conclusion.\n",
    "\n",
    "\n",
    "#### Answering the second part of my research question\n",
    "\n",
    "To answer the second part of my research question, I conclude that the LSTM classification model was the better model overall for my purposes of this research project. The reason for this is as follows:\n",
    "\n",
    "When comparing the results from the classification and regression models, it’s easier to identify the most effective independent variables for the classification model. It seems that the top-performing independent variables for the regression models were somewhat random. This is because, for the classification model, independent array #15 yielded the best results, showing the highest average and maximum accuracy scores across different combinations of model parameters.\n",
    "\n",
    "These model parameters were used to define the dependent variable. Specifically, I had two key parameters when training the models: the number of days ahead from the last closing price in the 30-day sequence that I am predicting, and the percentage change from the last closing price of the 30-day sequence (e.g., whether the closing price on the specified future day is greater than, 1% higher than, or 2% higher than the last closing price on the 30th day of the sequence).\n",
    "\n",
    "The classification results indicate that when the candlestick pattern is set to \"Random\" (**I am using the \"Random\" pattern because the actual candlestick patterns have too small a data size**) — meaning that random 30-day sequences are generated without relying on a specific candlestick pattern — independent array #15 produces the best outcomes, achieving the top spot 7 times. Independent array #14 follows closely in second place, with 6 occurrences at the top for yielding the highest average of maximum and average accuracy scores. I selected the candlestick pattern to \"Random\" because I wanted to analyze a larger sample size. Both arrays use all available independent variables (open, close, low, high, RSI, MFI, MACD, Signal Line), but there is a difference in how they process the data. Independent array #14 applies a log transformation to the open, close, low, and high prices, while independent array #15 uses Sklearn’s scaler function to normalize these prices. The classification results are as shown below:\n",
    "\n",
    "* The classification results table is self-explanatory, but to clarify:\n",
    "    + \"Most Frequent Class\": This represents the class (negative or positive) that occurs more frequently within the entire dependent variable dataset.\n",
    "    + \"Highest Frequency\": This is calculated as the ratio of the \"Most Frequent Class\" frequency to the \"Total Observations\" (i.e., Most Frequent Class / Total Observations). This metric is used to evaluate whether the model's accuracy scores are better than simply predicting the most frequent class.\n",
    "    + \"Weighted Score\": The weighted score is calculated as the average of the \"Best Accuracy\" and \"Avg Accuracy\" (i.e., (Best Accuracy + Avg Accuracy) / 2). The purpose of this metric is to account for the possibility that the \"Best Accuracy\" might be an outlier or lucky result, and by combining it with the \"Avg Accuracy,\" we get a more balanced measure.\n",
    "\n",
    "| Ticker | Pattern | Independent Array | Best Accuracy | Avg Accuracy | Days Out | Total Observations | Negative Observations | Positive Observations | Percent Increase Parameter | Most Frequent Class | Highest Frequency | Weighted Score |\n",
    "|--------|---------|-------------------|---------------|--------------|----------|--------------------|-----------------------|------------------------|---------------------------|---------------------|-------------------|----------------|\n",
    "| SPY    | Random  | independent_array12 | 0.850000024   | 0.586346157  | 1        | 199                | 89                    | 110                    | 1                         | 110                 | 0.552763819       | 0.71817309     |\n",
    "| SPY    | Random  | independent_array15 | 0.899999976   | 0.832910252  | 1        | 199                | 165                   | 34                     | 1.01                      | 165                 | 0.829145729       | 0.866455114    |\n",
    "| SPY    | Random  | independent_array1  | 0.974358976   | 0.954871786  | 1        | 199                | 190                   | 9                      | 1.02                      | 190                 | 0.954773869       | 0.964615381    |\n",
    "| SPY    | Random  | independent_array14 | 0.824999988   | 0.614487181  | 3        | 199                | 89                    | 110                    | 1                         | 110                 | 0.552763819       | 0.719743585    |\n",
    "| SPY    | Random  | independent_array14 | 0.820512831   | 0.699025648  | 3        | 199                | 138                   | 61                     | 1.01                      | 138                 | 0.693467337       | 0.759769239    |\n",
    "| SPY    | Random  | independent_array15 | 0.925000012   | 0.890512816  | 3        | 199                | 176                   | 23                     | 1.02                      | 176                 | 0.884422111       | 0.907756414    |\n",
    "| SPY    | Random  | independent_array15 | 0.824999988   | 0.647256423  | 5        | 199                | 76                    | 123                    | 1                         | 123                 | 0.618090452       | 0.736128206    |\n",
    "| SPY    | Random  | independent_array15 | 0.794871807   | 0.651641024  | 5        | 199                | 122                   | 77                     | 1.01                      | 122                 | 0.613065327       | 0.723256416    |\n",
    "| SPY    | Random  | independent_array14 | 0.948717952   | 0.852961555  | 5        | 199                | 169                   | 30                     | 1.02                      | 169                 | 0.849246231       | 0.900839753    |\n",
    "| SPY    | Random  | independent_array15 | 0.850000024   | 0.662666665  | 10       | 199                | 71                    | 128                    | 1                         | 128                 | 0.64321608        | 0.756333345    |\n",
    "| SPY    | Random  | independent_array14 | 0.800000012   | 0.632756413  | 10       | 199                | 105                   | 94                     | 1.01                      | 105                 | 0.527638191       | 0.716378213    |\n",
    "| SPY    | Random  | independent_array15 | 0.820512831   | 0.739974356  | 10       | 199                | 138                   | 61                     | 1.02                      | 138                 | 0.693467337       | 0.780243593    |\n",
    "| SPY    | Random  | independent_array15 | 0.820512831   | 0.64825641   | 15       | 199                | 73                    | 126                    | 1                         | 126                 | 0.633165829       | 0.734384621    |\n",
    "| SPY    | Random  | independent_array14 | 0.800000012   | 0.613717952  | 15       | 199                | 100                   | 99                     | 1.01                      | 100                 | 0.502512563       | 0.706858982    |\n",
    "| SPY    | Random  | independent_array14 | 0.846153855   | 0.680448722  | 15       | 199                | 127                   | 72                     | 1.02                      | 127                 | 0.638190955       | 0.763301288    |\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "The regression results indicate that when the candlestick pattern is set to \"Random\" — meaning that random 30-day sequences are generated without relying on a specific candlestick pattern — independent array #1 produces the best outcomes, achieving the top spot 5 times. This is interesting because independent array #1 solely includes price action (open, close, high, low) independent variables. These variables are also not normalized. The classification results are as shown below:\n",
    "\n",
    "* The regression results table is as follows:\n",
    "\n",
    "| Ticker | Pattern | Independent Array   | Best Accuracy | Avg Accuracy | Days Out | Total Observations | Negative Observations | Positive Observations | Percent Increase Parameter | Most Frequent Class | Highest Frequency | Weighted Score |\n",
    "|--------|---------|----------------------|---------------|--------------|----------|--------------------|-----------------------|------------------------|----------------------------|---------------------|-------------------|----------------|\n",
    "| SPY    | Random  | independent_array15   | 0.846153846   | 0.619230769  | 1        | 199                | 89                    | 110                    | 1                          | 110                 | 0.552763819       | 0.732692308    |\n",
    "| SPY    | Random  | independent_array1    | 0.925         | 0.828461538  | 1        | 199                | 165                   | 34                     | 1.01                       | 165                 | 0.829145729       | 0.876730769    |\n",
    "| SPY    | Random  | independent_array1    | 1.0           | 0.954487179  | 1        | 199                | 190                   | 9                      | 1.02                       | 190                 | 0.954773869       | 0.97724359     |\n",
    "| SPY    | Random  | independent_array3    | 0.675         | 0.542564103  | 3        | 199                | 89                    | 110                    | 1                          | 110                 | 0.552763819       | 0.608782051    |\n",
    "| SPY    | Random  | independent_array11   | 0.923076923   | 0.709615385  | 3        | 199                | 138                   | 61                     | 1.01                       | 138                 | 0.693467337       | 0.816346154    |\n",
    "| SPY    | Random  | independent_array1    | 0.95          | 0.884102564  | 3        | 199                | 176                   | 23                     | 1.02                       | 176                 | 0.884422111       | 0.917051282    |\n",
    "| SPY    | Random  | independent_array6    | 0.775         | 0.582692308  | 5        | 199                | 76                    | 123                    | 1                          | 123                 | 0.618090452       | 0.678846154    |\n",
    "| SPY    | Random  | independent_array1    | 0.7           | 0.613076923  | 5        | 199                | 122                   | 77                     | 1.01                       | 122                 | 0.613065327       | 0.656538462    |\n",
    "| SPY    | Random  | independent_array1    | 0.925         | 0.849102564  | 5        | 199                | 169                   | 30                     | 1.02                       | 169                 | 0.849246231       | 0.887051282    |\n",
    "| SPY    | Random  | independent_array3    | 0.7           | 0.607948718  | 10       | 199                | 71                    | 128                    | 1                          | 128                 | 0.64321608        | 0.653974359    |\n",
    "| SPY    | Random  | independent_array14   | 0.775         | 0.558461538  | 10       | 199                | 105                   | 94                     | 1.01                       | 105                 | 0.527638191       | 0.666730769    |\n",
    "| SPY    | Random  | independent_array2    | 0.948717949   | 0.74474359   | 10       | 199                | 138                   | 61                     | 1.02                       | 138                 | 0.693467337       | 0.846730769    |\n",
    "| SPY    | Random  | independent_array6    | 0.675         | 0.573205128  | 15       | 199                | 73                    | 126                    | 1                          | 126                 | 0.633165829       | 0.624102564    |\n",
    "| SPY    | Random  | independent_array2    | 0.95          | 0.643846154  | 15       | 199                | 100                   | 99                     | 1.01                       | 100                 | 0.502512563       | 0.796923077    |\n",
    "| SPY    | Random  | independent_array11   | 0.95          | 0.794487179  | 15       | 199                | 127                   | 72                     | 1.02                       | 127                 | 0.638190955       | 0.87224359     |\n",
    "\n",
    "<br>\n",
    "\n",
    "Looking at the results, it seems that both the classification and regression models outperform simply predicting the most frequently occurring class. To determine which model performs better—classification or regression—I will calculate the difference between the 'Weighted Score' and 'Highest Frequency' for each entry in the table, and then sum these differences across all observations. The model with the highest total of these differences will be considered the best performing, as it indicates that the model is yielding a greater improvement over the baseline of predicting the most frequent class, effectively demonstrating stronger overall performance.\n",
    "\n",
    "| Classification_Highest_frequency | Classification_Weighted_score | Classification_Differences |\n",
    "|----------------------------------|-------------------------------|----------------------------|\n",
    "| 0.552763819                      | 0.71817309                    | 0.165409271                |\n",
    "| 0.829145729                      | 0.866455114                   | 0.037309385                |\n",
    "| 0.954773869                      | 0.964615381                   | 0.009841511                |\n",
    "| 0.552763819                      | 0.719743585                   | 0.166979766                |\n",
    "| 0.693467337                      | 0.759769239                   | 0.066301903                |\n",
    "| 0.884422111                      | 0.907756414                   | 0.023334303                |\n",
    "| 0.618090452                      | 0.736128206                   | 0.118037753                |\n",
    "| 0.613065327                      | 0.723256416                   | 0.110191089                |\n",
    "| 0.849246231                      | 0.900839753                   | 0.051593522                |\n",
    "| 0.64321608                       | 0.756333345                   | 0.113117264                |\n",
    "| 0.527638191                      | 0.716378213                   | 0.188740022                |\n",
    "| 0.693467337                      | 0.780243593                   | 0.086776257                |\n",
    "| 0.633165829                      | 0.734384621                   | 0.101218792                |\n",
    "| 0.502512563                      | 0.706858982                   | 0.204346419                |\n",
    "| 0.638190955                      | 0.763301288                   | 0.125110334                |\n",
    "\n",
    "* The resulting sum of the differences for the classification table is: 1.568307591\n",
    "<br>\n",
    "\n",
    "| Regression_Highest_frequency | Regression_Weighted_score | Regression_Differences |\n",
    "|------------------------------|---------------------------|------------------------|\n",
    "| 0.552763819                   | 0.732692308               | 0.179928489            |\n",
    "| 0.829145729                   | 0.876730769               | 0.047585041            |\n",
    "| 0.954773869                   | 0.97724359                | 0.02246972             |\n",
    "| 0.552763819                   | 0.608782051               | 0.056018232            |\n",
    "| 0.693467337                   | 0.816346154               | 0.122878817            |\n",
    "| 0.884422111                   | 0.917051282               | 0.032629171            |\n",
    "| 0.618090452                   | 0.678846154               | 0.060755702            |\n",
    "| 0.613065327                   | 0.656538462               | 0.043473135            |\n",
    "| 0.849246231                   | 0.887051282               | 0.037805051            |\n",
    "| 0.64321608                    | 0.653974359               | 0.010758279            |\n",
    "| 0.527638191                   | 0.666730769               | 0.139092578            |\n",
    "| 0.693467337                   | 0.846730769               | 0.153263433            |\n",
    "| 0.633165829                   | 0.624102564               | -0.009063265           |\n",
    "| 0.502512563                   | 0.796923077               | 0.294410514            |\n",
    "| 0.638190955                   | 0.87224359                | 0.234052635            |\n",
    "\n",
    "* The resulting sum of the differences for the regression table is: 1.426057531\n",
    "<br>\n",
    "\n",
    "To conclude, the classification model emerged as the best performing model overall. However, it is important to acknowledge that the regression model outperformed the classification model in several specific parameter combinations. Despite this, I believe the classification model is the superior choice for this task due to its greater consistency. The best performing independent variables for the classification model consistently yield high accuracy scores (independent array #15), regardless of the parameter combinations (e.g., days out and percent increase). \n",
    "\n",
    "In contrast, it is more challenging to identify which independent variables in the regression model contribute to its accuracy, as the performance tends to fluctuate more significantly based on different parameter settings. This variability in the regression model’s performance makes it less predictable and harder to interpret, whereas the classification model’s stability provides a more reliable foundation for decision-making.\n",
    "\n",
    "**Lastly, and perhaps most importantly, while we are not analyzing a specific candlestick pattern here, but instead working with a randomly generated occurrence that simulates the presence of random 30-day sequences, we can clearly observe that our trained models—whether for classification or regression—outperform the \"Highest Frequency\" column. This metric is used to evaluate the accuracy of predicting the most frequent class. When compared to the \"Weighted Score\" column—representing the accuracy score produced by our model—we consistently find that the \"Weighted Score\" is higher in nearly all cases (and sometimes a lot more), regardless of the parameter combinations used. This shows us the efficacy of our model.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Answering the first part of my research question\n",
    "\n",
    "Since I have decided that classification was the better performing model with independent array #15 being the best combination of indepdendent variables, I am going to use that model with that set of independent variables to answer this question. I have decided to not use the bullish engulfing, bullish harami, and three white soldiers patterns for this analysis because of their small sample size. Although the hammer and inverted patterns had small sample sizes as well, they were a bit larger of a sample size than the other three.\n",
    "\n",
    "\n",
    "Below I am going to compare all three results: for a randomly generated occurrence, the hammer pattern occurrence, and the inverted hammer occurrence.\n",
    "\n",
    "* Random Occurrence\n",
    "\n",
    "| Ticker | Pattern | Independent Array    | Best Accuracy | Avg Accuracy  | Days Out | Total Observations | Negative Observations | Positive Observations | Percent Increase Parameter | Most Frequent Class | Classification Highest Frequency | Classification Weighted Score |\n",
    "|--------|---------|----------------------|---------------|---------------|----------|--------------------|-----------------------|-----------------------|----------------------------|---------------------|---------------------------------|------------------------------|\n",
    "| SPY    | Random  | independent_array15   | 0.75          | 0.569756417   | 1        | 199                | 89                    | 110                   | 1                          | 110                 | 0.552763819                      | 0.659878208                 |\n",
    "| SPY    | Random  | independent_array15   | 0.794871807   | 0.59938462    | 3        | 199                | 89                    | 110                   | 1                          | 110                 | 0.552763819                      | 0.697128213                 |\n",
    "| SPY    | Random  | independent_array15   | 0.824999988   | 0.647256423   | 5        | 199                | 76                    | 123                   | 1                          | 123                 | 0.618090452                      | 0.736128206                 |\n",
    "| SPY    | Random  | independent_array15   | 0.850000024   | 0.662666665   | 10       | 199                | 71                    | 128                   | 1                          | 128                 | 0.64321608                       | 0.756333345                 |\n",
    "| SPY    | Random  | independent_array15   | 0.820512831   | 0.64825641    | 15       | 199                | 73                    | 126                   | 1                          | 126                 | 0.633165829                      | 0.734384621                 |\n",
    "| SPY    | Random  | independent_array15   | 0.899999976   | 0.832910252   | 1        | 199                | 165                   | 34                    | 1.01                       | 165                 | 0.829145729                      | 0.866455114                 |\n",
    "| SPY    | Random  | independent_array15   | 0.794871807   | 0.708025651   | 3        | 199                | 138                   | 61                    | 1.01                       | 138                 | 0.693467337                      | 0.751448729                 |\n",
    "| SPY    | Random  | independent_array15   | 0.794871807   | 0.651641024   | 5        | 199                | 122                   | 77                    | 1.01                       | 122                 | 0.613065327                      | 0.723256416                 |\n",
    "| SPY    | Random  | independent_array15   | 0.774999976   | 0.635089748   | 10       | 199                | 105                   | 94                    | 1.01                       | 105                 | 0.527638191                      | 0.705044862                 |\n",
    "| SPY    | Random  | independent_array15   | 0.800000012   | 0.604820516   | 15       | 199                | 100                   | 99                    | 1.01                       | 100                 | 0.502512563                      | 0.702410264                 |\n",
    "| SPY    | Random  | independent_array15   | 0.974358976   | 0.954371786   | 1        | 199                | 190                   | 9                     | 1.02                       | 190                 | 0.954773869                      | 0.964365381                 |\n",
    "| SPY    | Random  | independent_array15   | 0.925000012   | 0.890512816   | 3        | 199                | 176                   | 23                    | 1.02                       | 176                 | 0.884422111                      | 0.907756414                 |\n",
    "| SPY    | Random  | independent_array15   | 0.899999976   | 0.859897449   | 5        | 199                | 169                   | 30                    | 1.02                       | 169                 | 0.849246231                      | 0.879948713                 |\n",
    "| SPY    | Random  | independent_array15   | 0.820512831   | 0.739974356   | 10       | 199                | 138                   | 61                    | 1.02                       | 138                 | 0.693467337                      | 0.780243593                 |\n",
    "| SPY    | Random  | independent_array15   | 0.794871807   | 0.670179485   | 15       | 199                | 127                   | 72                    | 1.02                       | 127                 | 0.638190955                      | 0.732525646                 |\n",
    "\n",
    "\n",
    "* Hammer Pattern Occurrence\n",
    "\n",
    "| Ticker | Pattern | Independent Array    | Best Accuracy | Avg Accuracy   | Days Out | Total Observations | Negative Observations | Positive Observations | Percent Increase Parameter | Most Frequent Class | Classification Highest Frequency | Classification Weighted Score |\n",
    "|--------|---------|----------------------|---------------|----------------|----------|--------------------|-----------------------|-----------------------|----------------------------|---------------------|---------------------------------|------------------------------|\n",
    "| SPY    | Hammer  | independent_array15   | 1             | 0.733736265    | 1        | 69                 | 37                    | 32                    | 1                          | 37                  | 0.536231884                      | 0.866868132                 |\n",
    "| SPY    | Hammer  | independent_array15   | 0.923076928   | 0.659780228    | 3        | 69                 | 25                    | 44                    | 1                          | 44                  | 0.637681159                      | 0.791428578                 |\n",
    "| SPY    | Hammer  | independent_array15   | 0.928571403   | 0.742307696    | 5        | 69                 | 25                    | 44                    | 1                          | 44                  | 0.637681159                      | 0.83543955                  |\n",
    "| SPY    | Hammer  | independent_array15   | 0.923076928   | 0.685164844    | 10       | 68                 | 27                    | 41                    | 1                          | 41                  | 0.602941176                      | 0.804120886                 |\n",
    "| SPY    | Hammer  | independent_array15   | 0.857142866   | 0.707362645    | 15       | 68                 | 31                    | 37                    | 1                          | 37                  | 0.544117647                      | 0.782252755                 |\n",
    "| SPY    | Hammer  | independent_array15   | 1             | 0.868571429    | 1        | 69                 | 57                    | 12                    | 1.01                       | 57                  | 0.826086957                      | 0.934285715                 |\n",
    "| SPY    | Hammer  | independent_array15   | 0.785714269   | 0.669450558    | 3        | 69                 | 43                    | 26                    | 1.01                       | 43                  | 0.623188406                      | 0.727582414                 |\n",
    "| SPY    | Hammer  | independent_array15   | 1             | 0.640659345    | 5        | 69                 | 37                    | 32                    | 1.01                       | 37                  | 0.536231884                      | 0.820329673                 |\n",
    "| SPY    | Hammer  | independent_array15   | 0.928571403   | 0.700769237    | 10       | 68                 | 35                    | 33                    | 1.01                       | 35                  | 0.514705882                      | 0.81467032                  |\n",
    "| SPY    | Hammer  | independent_array15   | 1             | 0.742417589    | 15       | 68                 | 36                    | 32                    | 1.01                       | 36                  | 0.529411765                      | 0.871208794                 |\n",
    "| SPY    | Hammer  | independent_array15   | 1             | 0.957142842    | 1        | 69                 | 66                    | 3                     | 1.02                       | 66                  | 0.956521739                      | 0.978571421                 |\n",
    "| SPY    | Hammer  | independent_array15   | 1             | 0.858351647    | 3        | 69                 | 58                    | 11                    | 1.02                       | 58                  | 0.84057971                       | 0.929175823                 |\n",
    "| SPY    | Hammer  | independent_array15   | 0.785714269   | 0.728021987    | 5        | 69                 | 51                    | 18                    | 1.02                       | 51                  | 0.739130435                      | 0.756868128                 |\n",
    "| SPY    | Hammer  | independent_array15   | 1             | 0.736593409    | 10       | 68                 | 46                    | 22                    | 1.02                       | 46                  | 0.676470588                      | 0.868296704                 |\n",
    "| SPY    | Hammer  | independent_array15   | 1             | 0.67626375     | 15       | 68                 | 41                    | 27                    | 1.02                       | 41                  | 0.602941176                      | 0.838131875                 |\n",
    "\n",
    "\n",
    "* Inverted Hammer Occurrence\n",
    "\n",
    "| Ticker | Pattern       | Independent Array   | Best Accuracy | Avg Accuracy   | Days Out | Total Observations | Negative Observations | Positive Observations | Percent Increase Parameter | Most Frequent Class | Classification Highest Frequency | Classification Weighted Score |\n",
    "|--------|---------------|---------------------|---------------|----------------|----------|--------------------|-----------------------|-----------------------|----------------------------|---------------------|---------------------------------|------------------------------|\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.818181813   | 0.656545464    | 1        | 52                 | 22                    | 30                    | 1                          | 30                  | 0.576923077                      | 0.737363639                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.899999976   | 0.705818185    | 3        | 52                 | 19                    | 33                    | 1                          | 33                  | 0.634615385                      | 0.802909081                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.899999976   | 0.707454543    | 5        | 52                 | 18                    | 34                    | 1                          | 34                  | 0.653846154                      | 0.803727259                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.899999976   | 0.672545449    | 10       | 52                 | 18                    | 34                    | 1                          | 34                  | 0.653846154                      | 0.786272712                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.800000012   | 0.69054545     | 15       | 52                 | 19                    | 33                    | 1                          | 33                  | 0.634615385                      | 0.745272731                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 1             | 0.850181819    | 1        | 52                 | 40                    | 12                    | 1.01                       | 40                  | 0.769230769                      | 0.92509091                  |\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.899999976   | 0.656181821    | 3        | 52                 | 28                    | 24                    | 1.01                       | 28                  | 0.538461538                      | 0.778090898                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.899999976   | 0.688181824    | 5        | 52                 | 26                    | 26                    | 1.01                       | 26                  | 0.5                             | 0.7940909                   |\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.899999976   | 0.618181826    | 10       | 52                 | 21                    | 31                    | 1.01                       | 31                  | 0.596153846                      | 0.759090901                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.899999976   | 0.649636369    | 15       | 52                 | 22                    | 30                    | 1.01                       | 30                  | 0.576923077                      | 0.774818172                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 1             | 0.941818187    | 1        | 52                 | 47                    | 5                     | 1.02                       | 47                  | 0.903846154                      | 0.970909094                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 1             | 0.75036364     | 3        | 52                 | 39                    | 13                    | 1.02                       | 39                  | 0.75                            | 0.87518182                  |\n",
    "| SPY    | InvertedHammer| independent_array15  | 1             | 0.726363633    | 5        | 52                 | 35                    | 17                    | 1.02                       | 35                  | 0.673076923                      | 0.863181816                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 0.899999976   | 0.605454546    | 10       | 52                 | 26                    | 26                    | 1.02                       | 26                  | 0.5                             | 0.752727261                 |\n",
    "| SPY    | InvertedHammer| independent_array15  | 1             | 0.677272734    | 15       | 52                 | 26                    | 26                    | 1.02                       | 26                  | 0.5                             | 0.838636367                 |\n",
    "\n",
    "\n",
    "\n",
    "Based on the tables above, it appears that the model returns higher accuracy scores when trained on candlestick patterns. For example, for each table if you take the sum of the \"Classification Highest Frequency\" and the \"Classification Weighted Score\" columns and subtract them this will give us the distance of our weighted accuracy to predicting the majority class. For each of these tables, the values are as follows:\n",
    "\n",
    "* Random Occurrence: SUM(Classification_Weighted_score) - SUM(Classification_Highest_frequency) = 1.411378076\n",
    "* Hammer Occurrence: SUM(Classification_Weighted_score) - SUM(Classification_Highest_frequency) = 2.815309199\n",
    "* Inverted Hammer Occurrence: SUM(Classification_Weighted_score) - SUM(Classification_Highest_frequency) = 2.7458251\n",
    "\n",
    "Now, if I take each of these values and divide them by 15 (which is the total number of parameter combinations), I get the average weighted average accuracy scores across all 15 parameter combinations.\n",
    "\n",
    "* Random Occurrence: 1.411378076 / 15 = 0.09409187173\n",
    "* Hammer Occurrence: 2.815309199 / 15 = 0.18768727993\n",
    "* Inverted Hammer Occurrence: 2.7458251 / 15 = 0.18305500666\n",
    "\n",
    "**This shows that, for each parameter combination where a true candlestick pattern is present, the model performs approximately 9-10% better in predicting the outcome compared to when a random occurrence is used.**\n",
    "\n",
    "It is possible that because the total number of observations for random occurrences was set higher than for the hammer and inverted hammer patterns (which are fixed values), the model may have struggled to learn the patterns effectively due to the larger data set for random occurrences. However, upon reviewing the results, it seems that when a true candlestick pattern is present, the model is able to predict the future closing price with significantly higher accuracy compared to when a candlestick pattern is not present or not likely to be present (which represents the randomly generated occurrence).\n",
    "\n",
    "\n",
    "\n",
    "#### Building off my research question\n",
    "\n",
    "Because there was a small sample size for my true candlestick patterns, I was a little disappointed. The reason being is that I wanted to deploy my model for real-world scenarios, especially for swing trading, where accurate predictions based on candlestick patterns could lead to more informed and timely trading decisions. However, as I have shown although I have received high accuracy scores, the frequency for these patterns are quite rare, occurring once every hundred days, or about a 1% occurrence. \n",
    "\n",
    "Later in this document, I increased the number of randomly generated sequences in order to make my model more adaptable for use on any given day. The goal was to train the model on over 2,000 randomly generated sequences, hoping that even when a true candlestick pattern is not present, the model could still make reliable predictions for future closing prices.\n",
    "\n",
    "Through this approach, I found that by increasing the sample size for training, using stratified 5-fold cross-validation, and incorporating ensemble learning methods, my model was able to deliver reliable results. These results were significantly more accurate than simply predicting the majority class. For these predictions, I used a single parameter combination: the closing price 10 days out, with a price increase greater than 1% on that day to be considered a positive class. I used independent array #15 as the basis for my independent variables which has 8 different features (Normalized_close, Normalized_open, Normalized_low, Normalized_high, RSI, MFI, MACD, Signal Line).\n",
    "\n",
    "The results were as follows:\n",
    "\n",
    "* Number of total observations in entire dependent array dataset: 2188\n",
    "* Number of actual false labels in entire dependent array dataset: 1230\n",
    "* Number of actual true labels in entire dependent array dataset: 958\n",
    "* Number of total observations in test dataset: 438\n",
    "* Number of incorrect predictions on test dataset: 137\n",
    "* Number of correct predictions on test dataset: 301\n",
    "* Prediction accuracy on test dataset: 68.72%\n",
    "* Number of actual false labels in test dataset: 256\n",
    "* Number of actual true labels test dataset: 182\n",
    "* Majority class label percent in test dataset: 58.45%\n",
    "\n",
    "The results of using ensemble methods are significant as we can see the accuracy scores. Based on this data sample, if we always predicted that the future closing price would be false, we would be correct 1230 out of 2188 times or 56.22% of the time. However, our model performs better, as our model has 301 correct predictions out of 438 observations or a correct prediction rate of 68.72%. Also, when looking at the actual false labels in the test dataset, which is the majority class, we see 256 observations; 256 out of 438 is 58.45%. Our model clearly performs better when compared against the actual labels in the entire dependent array (dataset used for training/validation) dataset and when compared against the actual labels in the test dataset.\n",
    "\n",
    "The results are significant, as we can outperform the expected market outcome (which assumes predicting the future price as false) by around 10% with this parameter combination when comparing against the actual values of the test set labels. This demonstrates the effectiveness of the model in identifying patterns and making predictions that exceed a baseline strategy of predicting no price increase of greater than 1% over the next ten days (which was the parameter combination I used for this ensemble model (pct_increase=1.01)).\n",
    "\n",
    "I have demonstrated the implementation of the ensemble learning method (with stratified 5-fold cross-validation used to train these models) using the following parameters: The dependent variable represents the closing price 10 days in the future. The label for the dependent variable is assigned as 0 (false) if the future closing price is less than or equal to a 1% increase from the closing price of the last identified candle. It is labeled as 1 (true) if the future closing price is greater than a 1% increase from the closing price of the last identified candle.\n",
    "\n",
    "I will run this implementation multiple times through multiple parameter combinations using independent array #15 as mentioned before, I found it to be the best performing combination of independent variables. I will run this separately outside of this document, for the submission for the next part of this project. Specifically, I will build a web application which will allow a user to easily implement this ensemble model, using the same independent variables as found on independent array #15.\n",
    "\n",
    "So, to answer the last part on the WGU grading rubric in which I am to propose a directions or approach for future study of the data set. The main thing I want to do is train an ensemble model for other stock tickers rather than just 'SPY' as shown in this project, and run those models on different parameter combinations as well to test the results. Again, this will be accomplished by creating a web application which allows me and any user to easily implement a trained model to predict stock price, for any stock ticker, for any parameter combination that is requested.\n",
    "\n",
    "\n",
    "# Sources\n",
    "\n",
    "Fidelity. (n.d.). RSI: Relative strength index. Fidelity. Retrieved December 26, 2024, from https://www.fidelity.com/learning-center/trading-investing/technical-analysis/technical-indicator-guide/RSI\n",
    "\n",
    "Wilder, J. W. (1978). New concepts in technical trading systems. Trend Research.\n",
    "\n",
    "Fidelity. (n.d.). Money Flow Index (MFI). Fidelity. Retrieved December 26, 2024, from https://www.fidelity.com/learning-center/trading-investing/technical-analysis/technical-indicator-guide/mfi\n",
    "\n",
    "Fidelity. (n.d.). MACD: Moving average convergence divergence. Fidelity. Retrieved December 26, 2024, from https://www.fidelity.com/learning-center/trading-investing/technical-analysis/technical-indicator-guide/macd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09705f84-a759-4bc9-bbb1-c84a6493f0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
